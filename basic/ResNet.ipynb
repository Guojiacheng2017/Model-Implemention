{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-20T00:48:02.307267Z",
     "end_time": "2023-04-20T00:48:09.839945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bling/opt/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/bling/opt/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <DDABACEB-F2EA-368C-80DD-40745DFB96F8> /Users/bling/opt/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <C06D85DA-0769-3311-A69C-B6FBFB1FAC59> /Users/bling/opt/anaconda3/envs/cv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_six'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMNIST\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mToTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m test_data \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mMNIST(\n\u001B[1;32m     11\u001B[0m     root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     12\u001B[0m     train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     13\u001B[0m     transform\u001B[38;5;241m=\u001B[39mToTensor()\n\u001B[1;32m     14\u001B[0m )\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_data)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/datasets/mnist.py:91\u001B[0m, in \u001B[0;36mMNIST.__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     85\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     89\u001B[0m     download: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     90\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 91\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain \u001B[38;5;241m=\u001B[39m train  \u001B[38;5;66;03m# training set or test set\u001B[39;00m\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_legacy_exist():\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/datasets/vision.py:39\u001B[0m, in \u001B[0;36mVisionDataset.__init__\u001B[0;34m(self, root, transforms, transform, target_transform)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     33\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     target_transform: Optional[Callable] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     37\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m     _log_api_usage_once(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(root, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_six\u001B[49m\u001B[38;5;241m.\u001B[39mstring_classes):\n\u001B[1;32m     40\u001B[0m         root \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexpanduser(root)\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot \u001B[38;5;241m=\u001B[39m root\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute '_six'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "print(train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m      2\u001B[0m loaders \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m: torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(\u001B[43mtrain_data\u001B[49m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m: torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(test_data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      5\u001B[0m }\n\u001B[1;32m      7\u001B[0m loaders\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'test': torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)\n",
    "}\n",
    "\n",
    "loaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import ResNet, Basicblock, Bottleneck\n",
    "from torch import optim\n",
    "\n",
    "# model = ResNet(Basicblock, 1, [1, 1, 1, 1], 10)\n",
    "model = ResNet(Bottleneck, 1, [1, 1, 1, 1], 10)\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optim_sgd = optim.SGD(model.parameters(), lr=0.1, momentum=0.05)\n",
    "optim = optim_sgd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "def train(num_epochs, model, loaders, optimizer, loss_arr):\n",
    "    print('* Start Training *...')\n",
    "    model.train()\n",
    "    total_steps = len(loaders['train'])\n",
    "    loss_per_100 = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            X = images.to(device)\n",
    "            y = labels.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            criterion = loss_func(pred, y)\n",
    "\n",
    "            pred_label = torch.max(pred, 1)[1].data.squeeze() # labels are from 1 to 10, minimum value is 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            criterion.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_per_100.append(criterion.detach().numpy())\n",
    "            if (i + 1) % 100 == 0:\n",
    "                loss = sum(loss_per_100) / len(loss_per_100)\n",
    "                loss_arr.append(loss)\n",
    "                loss_per_100 = []\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: [{}/{}]'\n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_steps, criterion, (pred_label == labels).sum(), len(pred))) # len(pred) == 100\n",
    "            pass\n",
    "        pass\n",
    "    pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(num_epochs, model, loaders, optim, loss_array)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "30"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_array)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<function matplotlib.pyplot.legend(*args, **kwargs)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_range = np.linspace(start=1, stop=30, num=30)\n",
    "plt.figure()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('errors')\n",
    "plt.plot(x_range, loss_array, color = 'blue')\n",
    "# plt.plot(x_range, loss_arr_2, color = 'red')\n",
    "plt.legend"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
