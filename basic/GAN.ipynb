{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.makedirs('../out_img/GAN_MNIST', exist_ok=True)  # exist_ok means that create the directory only the directory is not exist\n",
    "config = {\"n_epochs\": 30, \"batch_size\": 64, \"lr\" : 0.0001, \"b1\": 0.5, \"b2\": 0.999, \"n_cpu\": 8, \"latent_dim\": 100, \"channels\": 1, \"img_size\": 28, \"sample_interval\": 400}\n",
    "\n",
    "img_shape = (config.get(\"channels\"), config.get(\"img_size\"), config.get(\"img_size\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img_shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=MNIST('./data/MNIST', train=True,\n",
    "        download=False,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(config.get('img_size')), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size = config.get('batch_size'),\n",
    "    shuffle = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Construct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from model import Discriminator, Generator\n",
    "model_gen = Generator(img_shape, latent_dim=config.get(\"latent_dim\")).to(device)\n",
    "model_dis = Discriminator(img_shape).to(device)\n",
    "\n",
    "ad_loss = nn.BCELoss().to(device)\n",
    "\n",
    "# since adadelta have a good performance in comparison on MNIST classification\n",
    "# optim.Adadelta(model_dis.parameters(), lr=1.0, rho=0.9, eps=1e-06)\n",
    "# optimizer_G = optim.Adadelta(model_gen.parameters(), lr=1.0, rho=0.9, eps=1e-06)\n",
    "# optimizer_D = optim.Adadelta(model_dis.parameters(), lr=1.0, rho=0.9, eps=1e-06)\n",
    "\n",
    "optimizer_G = optim.Adam(model_gen.parameters(), lr=config.get(\"lr\"), betas=(config.get(\"b1\"), config.get(\"b2\")))\n",
    "optimizer_D = optim.Adam(model_dis.parameters(), lr=config.get(\"lr\"), betas=(config.get(\"b1\"), config.get(\"b2\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if device == 'cuda' else torch.FloatTensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/30] [Batch 0/938] [D loss: 0.741871] [G loss: 0.707292]\n",
      "[Epoch 0/30] [Batch 1/938] [D loss: 0.693320] [G loss: 0.705763]\n",
      "[Epoch 0/30] [Batch 2/938] [D loss: 0.654969] [G loss: 0.704276]\n",
      "[Epoch 0/30] [Batch 3/938] [D loss: 0.617747] [G loss: 0.702961]\n",
      "[Epoch 0/30] [Batch 4/938] [D loss: 0.581673] [G loss: 0.701743]\n",
      "[Epoch 0/30] [Batch 5/938] [D loss: 0.551511] [G loss: 0.700296]\n",
      "[Epoch 0/30] [Batch 6/938] [D loss: 0.524657] [G loss: 0.698943]\n",
      "[Epoch 0/30] [Batch 7/938] [D loss: 0.500298] [G loss: 0.697460]\n",
      "[Epoch 0/30] [Batch 8/938] [D loss: 0.476328] [G loss: 0.695684]\n",
      "[Epoch 0/30] [Batch 9/938] [D loss: 0.455547] [G loss: 0.693554]\n",
      "[Epoch 0/30] [Batch 10/938] [D loss: 0.441888] [G loss: 0.691391]\n",
      "[Epoch 0/30] [Batch 11/938] [D loss: 0.425480] [G loss: 0.688777]\n",
      "[Epoch 0/30] [Batch 12/938] [D loss: 0.411928] [G loss: 0.685855]\n",
      "[Epoch 0/30] [Batch 13/938] [D loss: 0.403105] [G loss: 0.682338]\n",
      "[Epoch 0/30] [Batch 14/938] [D loss: 0.397918] [G loss: 0.678784]\n",
      "[Epoch 0/30] [Batch 15/938] [D loss: 0.391368] [G loss: 0.675419]\n",
      "[Epoch 0/30] [Batch 16/938] [D loss: 0.387505] [G loss: 0.671382]\n",
      "[Epoch 0/30] [Batch 17/938] [D loss: 0.387867] [G loss: 0.664689]\n",
      "[Epoch 0/30] [Batch 18/938] [D loss: 0.388042] [G loss: 0.661131]\n",
      "[Epoch 0/30] [Batch 19/938] [D loss: 0.387354] [G loss: 0.656208]\n",
      "[Epoch 0/30] [Batch 20/938] [D loss: 0.387728] [G loss: 0.650089]\n",
      "[Epoch 0/30] [Batch 21/938] [D loss: 0.389541] [G loss: 0.644143]\n",
      "[Epoch 0/30] [Batch 22/938] [D loss: 0.392966] [G loss: 0.638684]\n",
      "[Epoch 0/30] [Batch 23/938] [D loss: 0.393770] [G loss: 0.630719]\n",
      "[Epoch 0/30] [Batch 24/938] [D loss: 0.396638] [G loss: 0.628627]\n",
      "[Epoch 0/30] [Batch 25/938] [D loss: 0.402529] [G loss: 0.617235]\n",
      "[Epoch 0/30] [Batch 26/938] [D loss: 0.403741] [G loss: 0.615550]\n",
      "[Epoch 0/30] [Batch 27/938] [D loss: 0.407401] [G loss: 0.609307]\n",
      "[Epoch 0/30] [Batch 28/938] [D loss: 0.410709] [G loss: 0.603733]\n",
      "[Epoch 0/30] [Batch 29/938] [D loss: 0.412867] [G loss: 0.602613]\n",
      "[Epoch 0/30] [Batch 30/938] [D loss: 0.416591] [G loss: 0.595812]\n",
      "[Epoch 0/30] [Batch 31/938] [D loss: 0.416939] [G loss: 0.596578]\n",
      "[Epoch 0/30] [Batch 32/938] [D loss: 0.417223] [G loss: 0.598382]\n",
      "[Epoch 0/30] [Batch 33/938] [D loss: 0.418255] [G loss: 0.601734]\n",
      "[Epoch 0/30] [Batch 34/938] [D loss: 0.420977] [G loss: 0.598279]\n",
      "[Epoch 0/30] [Batch 35/938] [D loss: 0.424572] [G loss: 0.597231]\n",
      "[Epoch 0/30] [Batch 36/938] [D loss: 0.419397] [G loss: 0.606859]\n",
      "[Epoch 0/30] [Batch 37/938] [D loss: 0.425582] [G loss: 0.601201]\n",
      "[Epoch 0/30] [Batch 38/938] [D loss: 0.423334] [G loss: 0.607562]\n",
      "[Epoch 0/30] [Batch 39/938] [D loss: 0.428015] [G loss: 0.607282]\n",
      "[Epoch 0/30] [Batch 40/938] [D loss: 0.424528] [G loss: 0.614761]\n",
      "[Epoch 0/30] [Batch 41/938] [D loss: 0.428069] [G loss: 0.610714]\n",
      "[Epoch 0/30] [Batch 42/938] [D loss: 0.433400] [G loss: 0.606934]\n",
      "[Epoch 0/30] [Batch 43/938] [D loss: 0.431832] [G loss: 0.615307]\n",
      "[Epoch 0/30] [Batch 44/938] [D loss: 0.430952] [G loss: 0.617218]\n",
      "[Epoch 0/30] [Batch 45/938] [D loss: 0.437759] [G loss: 0.612352]\n",
      "[Epoch 0/30] [Batch 46/938] [D loss: 0.438576] [G loss: 0.610796]\n",
      "[Epoch 0/30] [Batch 47/938] [D loss: 0.444717] [G loss: 0.605493]\n",
      "[Epoch 0/30] [Batch 48/938] [D loss: 0.448947] [G loss: 0.602233]\n",
      "[Epoch 0/30] [Batch 49/938] [D loss: 0.450103] [G loss: 0.609508]\n",
      "[Epoch 0/30] [Batch 50/938] [D loss: 0.457225] [G loss: 0.601849]\n",
      "[Epoch 0/30] [Batch 51/938] [D loss: 0.464989] [G loss: 0.598114]\n",
      "[Epoch 0/30] [Batch 52/938] [D loss: 0.467069] [G loss: 0.599506]\n",
      "[Epoch 0/30] [Batch 53/938] [D loss: 0.472206] [G loss: 0.590203]\n",
      "[Epoch 0/30] [Batch 54/938] [D loss: 0.480637] [G loss: 0.574973]\n",
      "[Epoch 0/30] [Batch 55/938] [D loss: 0.475975] [G loss: 0.600944]\n",
      "[Epoch 0/30] [Batch 56/938] [D loss: 0.486076] [G loss: 0.579452]\n",
      "[Epoch 0/30] [Batch 57/938] [D loss: 0.490267] [G loss: 0.585383]\n",
      "[Epoch 0/30] [Batch 58/938] [D loss: 0.489042] [G loss: 0.594721]\n",
      "[Epoch 0/30] [Batch 59/938] [D loss: 0.499313] [G loss: 0.585186]\n",
      "[Epoch 0/30] [Batch 60/938] [D loss: 0.510220] [G loss: 0.558254]\n",
      "[Epoch 0/30] [Batch 61/938] [D loss: 0.510550] [G loss: 0.581869]\n",
      "[Epoch 0/30] [Batch 62/938] [D loss: 0.510722] [G loss: 0.586071]\n",
      "[Epoch 0/30] [Batch 63/938] [D loss: 0.517197] [G loss: 0.575942]\n",
      "[Epoch 0/30] [Batch 64/938] [D loss: 0.528163] [G loss: 0.562573]\n",
      "[Epoch 0/30] [Batch 65/938] [D loss: 0.516730] [G loss: 0.596879]\n",
      "[Epoch 0/30] [Batch 66/938] [D loss: 0.519587] [G loss: 0.581378]\n",
      "[Epoch 0/30] [Batch 67/938] [D loss: 0.538734] [G loss: 0.548712]\n",
      "[Epoch 0/30] [Batch 68/938] [D loss: 0.540513] [G loss: 0.583970]\n",
      "[Epoch 0/30] [Batch 69/938] [D loss: 0.526852] [G loss: 0.608116]\n",
      "[Epoch 0/30] [Batch 70/938] [D loss: 0.548124] [G loss: 0.538332]\n",
      "[Epoch 0/30] [Batch 71/938] [D loss: 0.560721] [G loss: 0.548038]\n",
      "[Epoch 0/30] [Batch 72/938] [D loss: 0.568072] [G loss: 0.585570]\n",
      "[Epoch 0/30] [Batch 73/938] [D loss: 0.565913] [G loss: 0.568897]\n",
      "[Epoch 0/30] [Batch 74/938] [D loss: 0.582571] [G loss: 0.516103]\n",
      "[Epoch 0/30] [Batch 75/938] [D loss: 0.591996] [G loss: 0.529770]\n",
      "[Epoch 0/30] [Batch 76/938] [D loss: 0.573330] [G loss: 0.606163]\n",
      "[Epoch 0/30] [Batch 77/938] [D loss: 0.583159] [G loss: 0.534344]\n",
      "[Epoch 0/30] [Batch 78/938] [D loss: 0.573046] [G loss: 0.551411]\n",
      "[Epoch 0/30] [Batch 79/938] [D loss: 0.602261] [G loss: 0.520872]\n",
      "[Epoch 0/30] [Batch 80/938] [D loss: 0.587609] [G loss: 0.581124]\n",
      "[Epoch 0/30] [Batch 81/938] [D loss: 0.625884] [G loss: 0.502327]\n",
      "[Epoch 0/30] [Batch 82/938] [D loss: 0.604262] [G loss: 0.587042]\n",
      "[Epoch 0/30] [Batch 83/938] [D loss: 0.595793] [G loss: 0.590092]\n",
      "[Epoch 0/30] [Batch 84/938] [D loss: 0.592528] [G loss: 0.530694]\n",
      "[Epoch 0/30] [Batch 85/938] [D loss: 0.581776] [G loss: 0.576122]\n",
      "[Epoch 0/30] [Batch 86/938] [D loss: 0.596259] [G loss: 0.566563]\n",
      "[Epoch 0/30] [Batch 87/938] [D loss: 0.571331] [G loss: 0.615586]\n",
      "[Epoch 0/30] [Batch 88/938] [D loss: 0.578639] [G loss: 0.588487]\n",
      "[Epoch 0/30] [Batch 89/938] [D loss: 0.568288] [G loss: 0.588901]\n",
      "[Epoch 0/30] [Batch 90/938] [D loss: 0.570562] [G loss: 0.623897]\n",
      "[Epoch 0/30] [Batch 91/938] [D loss: 0.572762] [G loss: 0.586638]\n",
      "[Epoch 0/30] [Batch 92/938] [D loss: 0.573323] [G loss: 0.676462]\n",
      "[Epoch 0/30] [Batch 93/938] [D loss: 0.566427] [G loss: 0.644696]\n",
      "[Epoch 0/30] [Batch 94/938] [D loss: 0.566268] [G loss: 0.598703]\n",
      "[Epoch 0/30] [Batch 95/938] [D loss: 0.551539] [G loss: 0.678563]\n",
      "[Epoch 0/30] [Batch 96/938] [D loss: 0.556078] [G loss: 0.652355]\n",
      "[Epoch 0/30] [Batch 97/938] [D loss: 0.567752] [G loss: 0.598906]\n",
      "[Epoch 0/30] [Batch 98/938] [D loss: 0.569038] [G loss: 0.686814]\n",
      "[Epoch 0/30] [Batch 99/938] [D loss: 0.560345] [G loss: 0.660338]\n",
      "[Epoch 0/30] [Batch 100/938] [D loss: 0.585529] [G loss: 0.589899]\n",
      "[Epoch 0/30] [Batch 101/938] [D loss: 0.569604] [G loss: 0.694212]\n",
      "[Epoch 0/30] [Batch 102/938] [D loss: 0.585873] [G loss: 0.646912]\n",
      "[Epoch 0/30] [Batch 103/938] [D loss: 0.602773] [G loss: 0.613964]\n",
      "[Epoch 0/30] [Batch 104/938] [D loss: 0.586548] [G loss: 0.626130]\n",
      "[Epoch 0/30] [Batch 105/938] [D loss: 0.611868] [G loss: 0.633565]\n",
      "[Epoch 0/30] [Batch 106/938] [D loss: 0.600396] [G loss: 0.603359]\n",
      "[Epoch 0/30] [Batch 107/938] [D loss: 0.612776] [G loss: 0.590273]\n",
      "[Epoch 0/30] [Batch 108/938] [D loss: 0.606502] [G loss: 0.693791]\n",
      "[Epoch 0/30] [Batch 109/938] [D loss: 0.599520] [G loss: 0.640661]\n",
      "[Epoch 0/30] [Batch 110/938] [D loss: 0.600674] [G loss: 0.565801]\n",
      "[Epoch 0/30] [Batch 111/938] [D loss: 0.599686] [G loss: 0.710560]\n",
      "[Epoch 0/30] [Batch 112/938] [D loss: 0.590851] [G loss: 0.623810]\n",
      "[Epoch 0/30] [Batch 113/938] [D loss: 0.573107] [G loss: 0.641708]\n",
      "[Epoch 0/30] [Batch 114/938] [D loss: 0.574644] [G loss: 0.711974]\n",
      "[Epoch 0/30] [Batch 115/938] [D loss: 0.577062] [G loss: 0.691401]\n",
      "[Epoch 0/30] [Batch 116/938] [D loss: 0.580548] [G loss: 0.675767]\n",
      "[Epoch 0/30] [Batch 117/938] [D loss: 0.573043] [G loss: 0.675286]\n",
      "[Epoch 0/30] [Batch 118/938] [D loss: 0.562194] [G loss: 0.693056]\n",
      "[Epoch 0/30] [Batch 119/938] [D loss: 0.546007] [G loss: 0.677207]\n",
      "[Epoch 0/30] [Batch 120/938] [D loss: 0.538909] [G loss: 0.760496]\n",
      "[Epoch 0/30] [Batch 121/938] [D loss: 0.536600] [G loss: 0.685136]\n",
      "[Epoch 0/30] [Batch 122/938] [D loss: 0.548094] [G loss: 0.704484]\n",
      "[Epoch 0/30] [Batch 123/938] [D loss: 0.550740] [G loss: 0.764041]\n",
      "[Epoch 0/30] [Batch 124/938] [D loss: 0.550032] [G loss: 0.665968]\n",
      "[Epoch 0/30] [Batch 125/938] [D loss: 0.551015] [G loss: 0.708560]\n",
      "[Epoch 0/30] [Batch 126/938] [D loss: 0.543831] [G loss: 0.727744]\n",
      "[Epoch 0/30] [Batch 127/938] [D loss: 0.527434] [G loss: 0.690668]\n",
      "[Epoch 0/30] [Batch 128/938] [D loss: 0.519814] [G loss: 0.796111]\n",
      "[Epoch 0/30] [Batch 129/938] [D loss: 0.527691] [G loss: 0.731081]\n",
      "[Epoch 0/30] [Batch 130/938] [D loss: 0.538112] [G loss: 0.706360]\n",
      "[Epoch 0/30] [Batch 131/938] [D loss: 0.523232] [G loss: 0.733363]\n",
      "[Epoch 0/30] [Batch 132/938] [D loss: 0.513281] [G loss: 0.723939]\n",
      "[Epoch 0/30] [Batch 133/938] [D loss: 0.516021] [G loss: 0.802434]\n",
      "[Epoch 0/30] [Batch 134/938] [D loss: 0.518507] [G loss: 0.695898]\n",
      "[Epoch 0/30] [Batch 135/938] [D loss: 0.512718] [G loss: 0.739556]\n",
      "[Epoch 0/30] [Batch 136/938] [D loss: 0.538022] [G loss: 0.816436]\n",
      "[Epoch 0/30] [Batch 137/938] [D loss: 0.546467] [G loss: 0.645033]\n",
      "[Epoch 0/30] [Batch 138/938] [D loss: 0.533525] [G loss: 0.746144]\n",
      "[Epoch 0/30] [Batch 139/938] [D loss: 0.525294] [G loss: 0.729577]\n",
      "[Epoch 0/30] [Batch 140/938] [D loss: 0.551692] [G loss: 0.703111]\n",
      "[Epoch 0/30] [Batch 141/938] [D loss: 0.543714] [G loss: 0.715340]\n",
      "[Epoch 0/30] [Batch 142/938] [D loss: 0.534618] [G loss: 0.664677]\n",
      "[Epoch 0/30] [Batch 143/938] [D loss: 0.540796] [G loss: 0.776119]\n",
      "[Epoch 0/30] [Batch 144/938] [D loss: 0.539714] [G loss: 0.618103]\n",
      "[Epoch 0/30] [Batch 145/938] [D loss: 0.519314] [G loss: 0.784030]\n",
      "[Epoch 0/30] [Batch 146/938] [D loss: 0.534118] [G loss: 0.721689]\n",
      "[Epoch 0/30] [Batch 147/938] [D loss: 0.541189] [G loss: 0.672509]\n",
      "[Epoch 0/30] [Batch 148/938] [D loss: 0.548831] [G loss: 0.800477]\n",
      "[Epoch 0/30] [Batch 149/938] [D loss: 0.554219] [G loss: 0.622582]\n",
      "[Epoch 0/30] [Batch 150/938] [D loss: 0.537937] [G loss: 0.752719]\n",
      "[Epoch 0/30] [Batch 151/938] [D loss: 0.525993] [G loss: 0.723400]\n",
      "[Epoch 0/30] [Batch 152/938] [D loss: 0.502780] [G loss: 0.708640]\n",
      "[Epoch 0/30] [Batch 153/938] [D loss: 0.522503] [G loss: 0.832738]\n",
      "[Epoch 0/30] [Batch 154/938] [D loss: 0.510189] [G loss: 0.687886]\n",
      "[Epoch 0/30] [Batch 155/938] [D loss: 0.500892] [G loss: 0.798597]\n",
      "[Epoch 0/30] [Batch 156/938] [D loss: 0.505502] [G loss: 0.829205]\n",
      "[Epoch 0/30] [Batch 157/938] [D loss: 0.499088] [G loss: 0.725913]\n",
      "[Epoch 0/30] [Batch 158/938] [D loss: 0.483679] [G loss: 0.812253]\n",
      "[Epoch 0/30] [Batch 159/938] [D loss: 0.484751] [G loss: 0.781949]\n",
      "[Epoch 0/30] [Batch 160/938] [D loss: 0.485140] [G loss: 0.759856]\n",
      "[Epoch 0/30] [Batch 161/938] [D loss: 0.482750] [G loss: 0.839569]\n",
      "[Epoch 0/30] [Batch 162/938] [D loss: 0.480466] [G loss: 0.781746]\n",
      "[Epoch 0/30] [Batch 163/938] [D loss: 0.473869] [G loss: 0.816238]\n",
      "[Epoch 0/30] [Batch 164/938] [D loss: 0.482833] [G loss: 0.821196]\n",
      "[Epoch 0/30] [Batch 165/938] [D loss: 0.482835] [G loss: 0.712273]\n",
      "[Epoch 0/30] [Batch 166/938] [D loss: 0.488674] [G loss: 0.875216]\n",
      "[Epoch 0/30] [Batch 167/938] [D loss: 0.505053] [G loss: 0.726491]\n",
      "[Epoch 0/30] [Batch 168/938] [D loss: 0.501989] [G loss: 0.778713]\n",
      "[Epoch 0/30] [Batch 169/938] [D loss: 0.495265] [G loss: 0.789820]\n",
      "[Epoch 0/30] [Batch 170/938] [D loss: 0.486754] [G loss: 0.780698]\n",
      "[Epoch 0/30] [Batch 171/938] [D loss: 0.527647] [G loss: 0.750789]\n",
      "[Epoch 0/30] [Batch 172/938] [D loss: 0.513016] [G loss: 0.767709]\n",
      "[Epoch 0/30] [Batch 173/938] [D loss: 0.492801] [G loss: 0.776678]\n",
      "[Epoch 0/30] [Batch 174/938] [D loss: 0.494415] [G loss: 0.785603]\n",
      "[Epoch 0/30] [Batch 175/938] [D loss: 0.509393] [G loss: 0.856114]\n",
      "[Epoch 0/30] [Batch 176/938] [D loss: 0.527590] [G loss: 0.678311]\n",
      "[Epoch 0/30] [Batch 177/938] [D loss: 0.515287] [G loss: 0.905670]\n",
      "[Epoch 0/30] [Batch 178/938] [D loss: 0.525253] [G loss: 0.694908]\n",
      "[Epoch 0/30] [Batch 179/938] [D loss: 0.530434] [G loss: 0.828586]\n",
      "[Epoch 0/30] [Batch 180/938] [D loss: 0.534714] [G loss: 0.692927]\n",
      "[Epoch 0/30] [Batch 181/938] [D loss: 0.541762] [G loss: 0.880220]\n",
      "[Epoch 0/30] [Batch 182/938] [D loss: 0.536842] [G loss: 0.662930]\n",
      "[Epoch 0/30] [Batch 183/938] [D loss: 0.542142] [G loss: 0.879510]\n",
      "[Epoch 0/30] [Batch 184/938] [D loss: 0.532656] [G loss: 0.690850]\n",
      "[Epoch 0/30] [Batch 185/938] [D loss: 0.547352] [G loss: 0.894984]\n",
      "[Epoch 0/30] [Batch 186/938] [D loss: 0.548159] [G loss: 0.611708]\n",
      "[Epoch 0/30] [Batch 187/938] [D loss: 0.512646] [G loss: 0.854032]\n",
      "[Epoch 0/30] [Batch 188/938] [D loss: 0.519570] [G loss: 0.783734]\n",
      "[Epoch 0/30] [Batch 189/938] [D loss: 0.507685] [G loss: 0.718767]\n",
      "[Epoch 0/30] [Batch 190/938] [D loss: 0.525914] [G loss: 0.850886]\n",
      "[Epoch 0/30] [Batch 191/938] [D loss: 0.522981] [G loss: 0.690079]\n",
      "[Epoch 0/30] [Batch 192/938] [D loss: 0.529443] [G loss: 0.874940]\n",
      "[Epoch 0/30] [Batch 193/938] [D loss: 0.526131] [G loss: 0.708030]\n",
      "[Epoch 0/30] [Batch 194/938] [D loss: 0.498246] [G loss: 0.854894]\n",
      "[Epoch 0/30] [Batch 195/938] [D loss: 0.501934] [G loss: 0.751658]\n",
      "[Epoch 0/30] [Batch 196/938] [D loss: 0.519114] [G loss: 0.749213]\n",
      "[Epoch 0/30] [Batch 197/938] [D loss: 0.517409] [G loss: 0.785834]\n",
      "[Epoch 0/30] [Batch 198/938] [D loss: 0.512285] [G loss: 0.745174]\n",
      "[Epoch 0/30] [Batch 199/938] [D loss: 0.524964] [G loss: 0.764206]\n",
      "[Epoch 0/30] [Batch 200/938] [D loss: 0.536593] [G loss: 0.704603]\n",
      "[Epoch 0/30] [Batch 201/938] [D loss: 0.493130] [G loss: 0.883291]\n",
      "[Epoch 0/30] [Batch 202/938] [D loss: 0.537544] [G loss: 0.679429]\n",
      "[Epoch 0/30] [Batch 203/938] [D loss: 0.450809] [G loss: 0.964063]\n",
      "[Epoch 0/30] [Batch 204/938] [D loss: 0.485590] [G loss: 0.789824]\n",
      "[Epoch 0/30] [Batch 205/938] [D loss: 0.474634] [G loss: 0.869622]\n",
      "[Epoch 0/30] [Batch 206/938] [D loss: 0.449961] [G loss: 0.822182]\n",
      "[Epoch 0/30] [Batch 207/938] [D loss: 0.427919] [G loss: 1.108826]\n",
      "[Epoch 0/30] [Batch 208/938] [D loss: 0.452278] [G loss: 0.828811]\n",
      "[Epoch 0/30] [Batch 209/938] [D loss: 0.395182] [G loss: 1.163318]\n",
      "[Epoch 0/30] [Batch 210/938] [D loss: 0.430377] [G loss: 0.924667]\n",
      "[Epoch 0/30] [Batch 211/938] [D loss: 0.422103] [G loss: 1.027090]\n",
      "[Epoch 0/30] [Batch 212/938] [D loss: 0.417290] [G loss: 1.005098]\n",
      "[Epoch 0/30] [Batch 213/938] [D loss: 0.459515] [G loss: 1.054223]\n",
      "[Epoch 0/30] [Batch 214/938] [D loss: 0.478116] [G loss: 0.866134]\n",
      "[Epoch 0/30] [Batch 215/938] [D loss: 0.549764] [G loss: 1.182409]\n",
      "[Epoch 0/30] [Batch 216/938] [D loss: 0.554796] [G loss: 0.766894]\n",
      "[Epoch 0/30] [Batch 217/938] [D loss: 0.484775] [G loss: 0.939773]\n",
      "[Epoch 0/30] [Batch 218/938] [D loss: 0.490636] [G loss: 1.029759]\n",
      "[Epoch 0/30] [Batch 219/938] [D loss: 0.508170] [G loss: 0.744120]\n",
      "[Epoch 0/30] [Batch 220/938] [D loss: 0.511631] [G loss: 0.879981]\n",
      "[Epoch 0/30] [Batch 221/938] [D loss: 0.512112] [G loss: 0.739131]\n",
      "[Epoch 0/30] [Batch 222/938] [D loss: 0.539331] [G loss: 0.713139]\n",
      "[Epoch 0/30] [Batch 223/938] [D loss: 0.563954] [G loss: 0.660086]\n",
      "[Epoch 0/30] [Batch 224/938] [D loss: 0.521021] [G loss: 0.708850]\n",
      "[Epoch 0/30] [Batch 225/938] [D loss: 0.504821] [G loss: 0.683226]\n",
      "[Epoch 0/30] [Batch 226/938] [D loss: 0.526107] [G loss: 0.826247]\n",
      "[Epoch 0/30] [Batch 227/938] [D loss: 0.531368] [G loss: 0.600706]\n",
      "[Epoch 0/30] [Batch 228/938] [D loss: 0.524552] [G loss: 0.741709]\n",
      "[Epoch 0/30] [Batch 229/938] [D loss: 0.493846] [G loss: 0.792212]\n",
      "[Epoch 0/30] [Batch 230/938] [D loss: 0.530091] [G loss: 0.642194]\n",
      "[Epoch 0/30] [Batch 231/938] [D loss: 0.542115] [G loss: 0.746131]\n",
      "[Epoch 0/30] [Batch 232/938] [D loss: 0.535015] [G loss: 0.715464]\n",
      "[Epoch 0/30] [Batch 233/938] [D loss: 0.554641] [G loss: 0.696162]\n",
      "[Epoch 0/30] [Batch 234/938] [D loss: 0.513729] [G loss: 0.802986]\n",
      "[Epoch 0/30] [Batch 235/938] [D loss: 0.561133] [G loss: 0.663171]\n",
      "[Epoch 0/30] [Batch 236/938] [D loss: 0.588632] [G loss: 0.890906]\n",
      "[Epoch 0/30] [Batch 237/938] [D loss: 0.630237] [G loss: 0.542910]\n",
      "[Epoch 0/30] [Batch 238/938] [D loss: 0.563145] [G loss: 0.852443]\n",
      "[Epoch 0/30] [Batch 239/938] [D loss: 0.647162] [G loss: 0.645791]\n",
      "[Epoch 0/30] [Batch 240/938] [D loss: 0.596528] [G loss: 0.677042]\n",
      "[Epoch 0/30] [Batch 241/938] [D loss: 0.643778] [G loss: 0.796666]\n",
      "[Epoch 0/30] [Batch 242/938] [D loss: 0.630397] [G loss: 0.626864]\n",
      "[Epoch 0/30] [Batch 243/938] [D loss: 0.683701] [G loss: 0.853454]\n",
      "[Epoch 0/30] [Batch 244/938] [D loss: 0.623473] [G loss: 0.560722]\n",
      "[Epoch 0/30] [Batch 245/938] [D loss: 0.605977] [G loss: 0.770639]\n",
      "[Epoch 0/30] [Batch 246/938] [D loss: 0.605797] [G loss: 0.821599]\n",
      "[Epoch 0/30] [Batch 247/938] [D loss: 0.599941] [G loss: 0.685115]\n",
      "[Epoch 0/30] [Batch 248/938] [D loss: 0.545354] [G loss: 0.770964]\n",
      "[Epoch 0/30] [Batch 249/938] [D loss: 0.532518] [G loss: 0.812043]\n",
      "[Epoch 0/30] [Batch 250/938] [D loss: 0.536961] [G loss: 0.864114]\n",
      "[Epoch 0/30] [Batch 251/938] [D loss: 0.539065] [G loss: 0.799261]\n",
      "[Epoch 0/30] [Batch 252/938] [D loss: 0.515179] [G loss: 0.857702]\n",
      "[Epoch 0/30] [Batch 253/938] [D loss: 0.518449] [G loss: 0.907146]\n",
      "[Epoch 0/30] [Batch 254/938] [D loss: 0.500168] [G loss: 0.888894]\n",
      "[Epoch 0/30] [Batch 255/938] [D loss: 0.462373] [G loss: 0.891586]\n",
      "[Epoch 0/30] [Batch 256/938] [D loss: 0.472569] [G loss: 0.985213]\n",
      "[Epoch 0/30] [Batch 257/938] [D loss: 0.456991] [G loss: 0.927721]\n",
      "[Epoch 0/30] [Batch 258/938] [D loss: 0.465159] [G loss: 0.889056]\n",
      "[Epoch 0/30] [Batch 259/938] [D loss: 0.459744] [G loss: 1.014823]\n",
      "[Epoch 0/30] [Batch 260/938] [D loss: 0.466951] [G loss: 0.970580]\n",
      "[Epoch 0/30] [Batch 261/938] [D loss: 0.459249] [G loss: 0.877591]\n",
      "[Epoch 0/30] [Batch 262/938] [D loss: 0.445197] [G loss: 1.000516]\n",
      "[Epoch 0/30] [Batch 263/938] [D loss: 0.451860] [G loss: 0.949120]\n",
      "[Epoch 0/30] [Batch 264/938] [D loss: 0.447297] [G loss: 0.910687]\n",
      "[Epoch 0/30] [Batch 265/938] [D loss: 0.458287] [G loss: 0.851017]\n",
      "[Epoch 0/30] [Batch 266/938] [D loss: 0.472952] [G loss: 0.901626]\n",
      "[Epoch 0/30] [Batch 267/938] [D loss: 0.467133] [G loss: 0.938495]\n",
      "[Epoch 0/30] [Batch 268/938] [D loss: 0.461927] [G loss: 0.861685]\n",
      "[Epoch 0/30] [Batch 269/938] [D loss: 0.479995] [G loss: 0.887575]\n",
      "[Epoch 0/30] [Batch 270/938] [D loss: 0.490040] [G loss: 0.803096]\n",
      "[Epoch 0/30] [Batch 271/938] [D loss: 0.475418] [G loss: 0.893448]\n",
      "[Epoch 0/30] [Batch 272/938] [D loss: 0.502483] [G loss: 0.790241]\n",
      "[Epoch 0/30] [Batch 273/938] [D loss: 0.512281] [G loss: 0.753497]\n",
      "[Epoch 0/30] [Batch 274/938] [D loss: 0.502799] [G loss: 0.874720]\n",
      "[Epoch 0/30] [Batch 275/938] [D loss: 0.508462] [G loss: 0.804313]\n",
      "[Epoch 0/30] [Batch 276/938] [D loss: 0.483467] [G loss: 0.797576]\n",
      "[Epoch 0/30] [Batch 277/938] [D loss: 0.492016] [G loss: 0.824405]\n",
      "[Epoch 0/30] [Batch 278/938] [D loss: 0.488886] [G loss: 0.854214]\n",
      "[Epoch 0/30] [Batch 279/938] [D loss: 0.493054] [G loss: 0.777651]\n",
      "[Epoch 0/30] [Batch 280/938] [D loss: 0.501205] [G loss: 0.866913]\n",
      "[Epoch 0/30] [Batch 281/938] [D loss: 0.503168] [G loss: 0.818351]\n",
      "[Epoch 0/30] [Batch 282/938] [D loss: 0.502626] [G loss: 0.692891]\n",
      "[Epoch 0/30] [Batch 283/938] [D loss: 0.508323] [G loss: 0.917690]\n",
      "[Epoch 0/30] [Batch 284/938] [D loss: 0.504123] [G loss: 0.762784]\n",
      "[Epoch 0/30] [Batch 285/938] [D loss: 0.508602] [G loss: 0.788902]\n",
      "[Epoch 0/30] [Batch 286/938] [D loss: 0.496722] [G loss: 0.817723]\n",
      "[Epoch 0/30] [Batch 287/938] [D loss: 0.489248] [G loss: 0.763554]\n",
      "[Epoch 0/30] [Batch 288/938] [D loss: 0.499751] [G loss: 0.848224]\n",
      "[Epoch 0/30] [Batch 289/938] [D loss: 0.502162] [G loss: 0.782018]\n",
      "[Epoch 0/30] [Batch 290/938] [D loss: 0.481590] [G loss: 0.800111]\n",
      "[Epoch 0/30] [Batch 291/938] [D loss: 0.476596] [G loss: 0.865297]\n",
      "[Epoch 0/30] [Batch 292/938] [D loss: 0.479955] [G loss: 0.792581]\n",
      "[Epoch 0/30] [Batch 293/938] [D loss: 0.485538] [G loss: 0.820345]\n",
      "[Epoch 0/30] [Batch 294/938] [D loss: 0.485478] [G loss: 0.829452]\n",
      "[Epoch 0/30] [Batch 295/938] [D loss: 0.480973] [G loss: 0.766180]\n",
      "[Epoch 0/30] [Batch 296/938] [D loss: 0.486975] [G loss: 0.819758]\n",
      "[Epoch 0/30] [Batch 297/938] [D loss: 0.476354] [G loss: 0.812134]\n",
      "[Epoch 0/30] [Batch 298/938] [D loss: 0.495891] [G loss: 0.812625]\n",
      "[Epoch 0/30] [Batch 299/938] [D loss: 0.495762] [G loss: 0.758673]\n",
      "[Epoch 0/30] [Batch 300/938] [D loss: 0.518593] [G loss: 0.825756]\n",
      "[Epoch 0/30] [Batch 301/938] [D loss: 0.513980] [G loss: 0.693236]\n",
      "[Epoch 0/30] [Batch 302/938] [D loss: 0.529144] [G loss: 0.863310]\n",
      "[Epoch 0/30] [Batch 303/938] [D loss: 0.527873] [G loss: 0.675114]\n",
      "[Epoch 0/30] [Batch 304/938] [D loss: 0.529290] [G loss: 0.746918]\n",
      "[Epoch 0/30] [Batch 305/938] [D loss: 0.542968] [G loss: 0.766855]\n",
      "[Epoch 0/30] [Batch 306/938] [D loss: 0.548632] [G loss: 0.658255]\n",
      "[Epoch 0/30] [Batch 307/938] [D loss: 0.544649] [G loss: 0.800083]\n",
      "[Epoch 0/30] [Batch 308/938] [D loss: 0.547364] [G loss: 0.671340]\n",
      "[Epoch 0/30] [Batch 309/938] [D loss: 0.537680] [G loss: 0.806619]\n",
      "[Epoch 0/30] [Batch 310/938] [D loss: 0.548912] [G loss: 0.694175]\n",
      "[Epoch 0/30] [Batch 311/938] [D loss: 0.541091] [G loss: 0.770448]\n",
      "[Epoch 0/30] [Batch 312/938] [D loss: 0.541821] [G loss: 0.704282]\n",
      "[Epoch 0/30] [Batch 313/938] [D loss: 0.530527] [G loss: 0.817852]\n",
      "[Epoch 0/30] [Batch 314/938] [D loss: 0.536807] [G loss: 0.719462]\n",
      "[Epoch 0/30] [Batch 315/938] [D loss: 0.527575] [G loss: 0.728864]\n",
      "[Epoch 0/30] [Batch 316/938] [D loss: 0.512883] [G loss: 0.854568]\n",
      "[Epoch 0/30] [Batch 317/938] [D loss: 0.515556] [G loss: 0.738133]\n",
      "[Epoch 0/30] [Batch 318/938] [D loss: 0.505603] [G loss: 0.855531]\n",
      "[Epoch 0/30] [Batch 319/938] [D loss: 0.528675] [G loss: 0.750677]\n",
      "[Epoch 0/30] [Batch 320/938] [D loss: 0.529500] [G loss: 0.740737]\n",
      "[Epoch 0/30] [Batch 321/938] [D loss: 0.542325] [G loss: 0.848086]\n",
      "[Epoch 0/30] [Batch 322/938] [D loss: 0.532319] [G loss: 0.704244]\n",
      "[Epoch 0/30] [Batch 323/938] [D loss: 0.545305] [G loss: 0.766268]\n",
      "[Epoch 0/30] [Batch 324/938] [D loss: 0.561400] [G loss: 0.773122]\n",
      "[Epoch 0/30] [Batch 325/938] [D loss: 0.565991] [G loss: 0.682895]\n",
      "[Epoch 0/30] [Batch 326/938] [D loss: 0.552620] [G loss: 0.794021]\n",
      "[Epoch 0/30] [Batch 327/938] [D loss: 0.555465] [G loss: 0.690230]\n",
      "[Epoch 0/30] [Batch 328/938] [D loss: 0.546008] [G loss: 0.815216]\n",
      "[Epoch 0/30] [Batch 329/938] [D loss: 0.536779] [G loss: 0.749172]\n",
      "[Epoch 0/30] [Batch 330/938] [D loss: 0.529913] [G loss: 0.796054]\n",
      "[Epoch 0/30] [Batch 331/938] [D loss: 0.528355] [G loss: 0.813133]\n",
      "[Epoch 0/30] [Batch 332/938] [D loss: 0.518172] [G loss: 0.734419]\n",
      "[Epoch 0/30] [Batch 333/938] [D loss: 0.527353] [G loss: 0.921183]\n",
      "[Epoch 0/30] [Batch 334/938] [D loss: 0.545364] [G loss: 0.611897]\n",
      "[Epoch 0/30] [Batch 335/938] [D loss: 0.554558] [G loss: 1.051256]\n",
      "[Epoch 0/30] [Batch 336/938] [D loss: 0.567416] [G loss: 0.543803]\n",
      "[Epoch 0/30] [Batch 337/938] [D loss: 0.549557] [G loss: 1.064800]\n",
      "[Epoch 0/30] [Batch 338/938] [D loss: 0.563894] [G loss: 0.573734]\n",
      "[Epoch 0/30] [Batch 339/938] [D loss: 0.520448] [G loss: 1.049105]\n",
      "[Epoch 0/30] [Batch 340/938] [D loss: 0.539974] [G loss: 0.675068]\n",
      "[Epoch 0/30] [Batch 341/938] [D loss: 0.529854] [G loss: 0.748833]\n",
      "[Epoch 0/30] [Batch 342/938] [D loss: 0.540772] [G loss: 0.958186]\n",
      "[Epoch 0/30] [Batch 343/938] [D loss: 0.571077] [G loss: 0.612198]\n",
      "[Epoch 0/30] [Batch 344/938] [D loss: 0.537289] [G loss: 1.012180]\n",
      "[Epoch 0/30] [Batch 345/938] [D loss: 0.555286] [G loss: 0.663667]\n",
      "[Epoch 0/30] [Batch 346/938] [D loss: 0.523983] [G loss: 0.804834]\n",
      "[Epoch 0/30] [Batch 347/938] [D loss: 0.530243] [G loss: 0.883125]\n",
      "[Epoch 0/30] [Batch 348/938] [D loss: 0.526440] [G loss: 0.671135]\n",
      "[Epoch 0/30] [Batch 349/938] [D loss: 0.519864] [G loss: 1.030013]\n",
      "[Epoch 0/30] [Batch 350/938] [D loss: 0.532892] [G loss: 0.628741]\n",
      "[Epoch 0/30] [Batch 351/938] [D loss: 0.508868] [G loss: 1.021302]\n",
      "[Epoch 0/30] [Batch 352/938] [D loss: 0.526149] [G loss: 0.671644]\n",
      "[Epoch 0/30] [Batch 353/938] [D loss: 0.522863] [G loss: 0.948751]\n",
      "[Epoch 0/30] [Batch 354/938] [D loss: 0.530631] [G loss: 0.680777]\n",
      "[Epoch 0/30] [Batch 355/938] [D loss: 0.511286] [G loss: 0.935508]\n",
      "[Epoch 0/30] [Batch 356/938] [D loss: 0.530250] [G loss: 0.759372]\n",
      "[Epoch 0/30] [Batch 357/938] [D loss: 0.541083] [G loss: 0.768745]\n",
      "[Epoch 0/30] [Batch 358/938] [D loss: 0.558855] [G loss: 0.788336]\n",
      "[Epoch 0/30] [Batch 359/938] [D loss: 0.545120] [G loss: 0.763102]\n",
      "[Epoch 0/30] [Batch 360/938] [D loss: 0.517269] [G loss: 0.782468]\n",
      "[Epoch 0/30] [Batch 361/938] [D loss: 0.535935] [G loss: 0.873276]\n",
      "[Epoch 0/30] [Batch 362/938] [D loss: 0.504394] [G loss: 0.741423]\n",
      "[Epoch 0/30] [Batch 363/938] [D loss: 0.496558] [G loss: 0.954140]\n",
      "[Epoch 0/30] [Batch 364/938] [D loss: 0.489844] [G loss: 0.745925]\n",
      "[Epoch 0/30] [Batch 365/938] [D loss: 0.490246] [G loss: 0.888653]\n",
      "[Epoch 0/30] [Batch 366/938] [D loss: 0.483205] [G loss: 0.868505]\n",
      "[Epoch 0/30] [Batch 367/938] [D loss: 0.467466] [G loss: 0.805260]\n",
      "[Epoch 0/30] [Batch 368/938] [D loss: 0.496416] [G loss: 1.081656]\n",
      "[Epoch 0/30] [Batch 369/938] [D loss: 0.585717] [G loss: 0.512774]\n",
      "[Epoch 0/30] [Batch 370/938] [D loss: 0.490533] [G loss: 1.264473]\n",
      "[Epoch 0/30] [Batch 371/938] [D loss: 0.496223] [G loss: 0.635712]\n",
      "[Epoch 0/30] [Batch 372/938] [D loss: 0.470222] [G loss: 0.946361]\n",
      "[Epoch 0/30] [Batch 373/938] [D loss: 0.455212] [G loss: 0.839202]\n",
      "[Epoch 0/30] [Batch 374/938] [D loss: 0.453382] [G loss: 0.869750]\n",
      "[Epoch 0/30] [Batch 375/938] [D loss: 0.459375] [G loss: 0.901229]\n",
      "[Epoch 0/30] [Batch 376/938] [D loss: 0.478609] [G loss: 0.701622]\n",
      "[Epoch 0/30] [Batch 377/938] [D loss: 0.434526] [G loss: 0.983329]\n",
      "[Epoch 0/30] [Batch 378/938] [D loss: 0.432402] [G loss: 0.879556]\n",
      "[Epoch 0/30] [Batch 379/938] [D loss: 0.452901] [G loss: 0.826225]\n",
      "[Epoch 0/30] [Batch 380/938] [D loss: 0.477544] [G loss: 0.848105]\n",
      "[Epoch 0/30] [Batch 381/938] [D loss: 0.473363] [G loss: 0.799836]\n",
      "[Epoch 0/30] [Batch 382/938] [D loss: 0.482825] [G loss: 0.798128]\n",
      "[Epoch 0/30] [Batch 383/938] [D loss: 0.476339] [G loss: 0.821815]\n",
      "[Epoch 0/30] [Batch 384/938] [D loss: 0.463639] [G loss: 0.875528]\n",
      "[Epoch 0/30] [Batch 385/938] [D loss: 0.467849] [G loss: 0.760905]\n",
      "[Epoch 0/30] [Batch 386/938] [D loss: 0.467414] [G loss: 0.896593]\n",
      "[Epoch 0/30] [Batch 387/938] [D loss: 0.477667] [G loss: 0.762021]\n",
      "[Epoch 0/30] [Batch 388/938] [D loss: 0.456742] [G loss: 0.819386]\n",
      "[Epoch 0/30] [Batch 389/938] [D loss: 0.491948] [G loss: 0.919610]\n",
      "[Epoch 0/30] [Batch 390/938] [D loss: 0.476199] [G loss: 0.643493]\n",
      "[Epoch 0/30] [Batch 391/938] [D loss: 0.504757] [G loss: 1.233695]\n",
      "[Epoch 0/30] [Batch 392/938] [D loss: 0.506495] [G loss: 0.562978]\n",
      "[Epoch 0/30] [Batch 393/938] [D loss: 0.454608] [G loss: 1.110519]\n",
      "[Epoch 0/30] [Batch 394/938] [D loss: 0.440275] [G loss: 0.777683]\n",
      "[Epoch 0/30] [Batch 395/938] [D loss: 0.421642] [G loss: 0.882255]\n",
      "[Epoch 0/30] [Batch 396/938] [D loss: 0.407723] [G loss: 1.012468]\n",
      "[Epoch 0/30] [Batch 397/938] [D loss: 0.415929] [G loss: 0.830318]\n",
      "[Epoch 0/30] [Batch 398/938] [D loss: 0.416908] [G loss: 0.974016]\n",
      "[Epoch 0/30] [Batch 399/938] [D loss: 0.425205] [G loss: 0.895311]\n",
      "[Epoch 0/30] [Batch 400/938] [D loss: 0.412801] [G loss: 0.873447]\n",
      "[Epoch 0/30] [Batch 401/938] [D loss: 0.425516] [G loss: 0.993101]\n",
      "[Epoch 0/30] [Batch 402/938] [D loss: 0.439273] [G loss: 0.763743]\n",
      "[Epoch 0/30] [Batch 403/938] [D loss: 0.404921] [G loss: 1.121073]\n",
      "[Epoch 0/30] [Batch 404/938] [D loss: 0.410247] [G loss: 0.823798]\n",
      "[Epoch 0/30] [Batch 405/938] [D loss: 0.410376] [G loss: 1.078302]\n",
      "[Epoch 0/30] [Batch 406/938] [D loss: 0.412994] [G loss: 0.820839]\n",
      "[Epoch 0/30] [Batch 407/938] [D loss: 0.405077] [G loss: 1.165275]\n",
      "[Epoch 0/30] [Batch 408/938] [D loss: 0.417301] [G loss: 0.771830]\n",
      "[Epoch 0/30] [Batch 409/938] [D loss: 0.407082] [G loss: 1.120001]\n",
      "[Epoch 0/30] [Batch 410/938] [D loss: 0.399457] [G loss: 0.825765]\n",
      "[Epoch 0/30] [Batch 411/938] [D loss: 0.411542] [G loss: 1.095680]\n",
      "[Epoch 0/30] [Batch 412/938] [D loss: 0.416160] [G loss: 0.828506]\n",
      "[Epoch 0/30] [Batch 413/938] [D loss: 0.397072] [G loss: 1.070136]\n",
      "[Epoch 0/30] [Batch 414/938] [D loss: 0.397839] [G loss: 0.949523]\n",
      "[Epoch 0/30] [Batch 415/938] [D loss: 0.421257] [G loss: 0.936300]\n",
      "[Epoch 0/30] [Batch 416/938] [D loss: 0.405766] [G loss: 0.897084]\n",
      "[Epoch 0/30] [Batch 417/938] [D loss: 0.412209] [G loss: 1.077685]\n",
      "[Epoch 0/30] [Batch 418/938] [D loss: 0.436908] [G loss: 0.753280]\n",
      "[Epoch 0/30] [Batch 419/938] [D loss: 0.489124] [G loss: 1.180391]\n",
      "[Epoch 0/30] [Batch 420/938] [D loss: 0.501112] [G loss: 0.562278]\n",
      "[Epoch 0/30] [Batch 421/938] [D loss: 0.471141] [G loss: 1.446972]\n",
      "[Epoch 0/30] [Batch 422/938] [D loss: 0.470491] [G loss: 0.637185]\n",
      "[Epoch 0/30] [Batch 423/938] [D loss: 0.415902] [G loss: 1.228121]\n",
      "[Epoch 0/30] [Batch 424/938] [D loss: 0.407502] [G loss: 0.893437]\n",
      "[Epoch 0/30] [Batch 425/938] [D loss: 0.398203] [G loss: 0.986049]\n",
      "[Epoch 0/30] [Batch 426/938] [D loss: 0.417339] [G loss: 1.068025]\n",
      "[Epoch 0/30] [Batch 427/938] [D loss: 0.441769] [G loss: 0.881330]\n",
      "[Epoch 0/30] [Batch 428/938] [D loss: 0.411425] [G loss: 0.979977]\n",
      "[Epoch 0/30] [Batch 429/938] [D loss: 0.426313] [G loss: 1.056895]\n",
      "[Epoch 0/30] [Batch 430/938] [D loss: 0.435502] [G loss: 0.824081]\n",
      "[Epoch 0/30] [Batch 431/938] [D loss: 0.407969] [G loss: 1.156792]\n",
      "[Epoch 0/30] [Batch 432/938] [D loss: 0.415912] [G loss: 0.848663]\n",
      "[Epoch 0/30] [Batch 433/938] [D loss: 0.402009] [G loss: 1.200466]\n",
      "[Epoch 0/30] [Batch 434/938] [D loss: 0.423547] [G loss: 0.862541]\n",
      "[Epoch 0/30] [Batch 435/938] [D loss: 0.443904] [G loss: 1.184033]\n",
      "[Epoch 0/30] [Batch 436/938] [D loss: 0.485700] [G loss: 0.690342]\n",
      "[Epoch 0/30] [Batch 437/938] [D loss: 0.419314] [G loss: 1.268793]\n",
      "[Epoch 0/30] [Batch 438/938] [D loss: 0.419091] [G loss: 0.810720]\n",
      "[Epoch 0/30] [Batch 439/938] [D loss: 0.415142] [G loss: 1.167986]\n",
      "[Epoch 0/30] [Batch 440/938] [D loss: 0.440347] [G loss: 0.868704]\n",
      "[Epoch 0/30] [Batch 441/938] [D loss: 0.415502] [G loss: 0.989534]\n",
      "[Epoch 0/30] [Batch 442/938] [D loss: 0.406458] [G loss: 0.969783]\n",
      "[Epoch 0/30] [Batch 443/938] [D loss: 0.405380] [G loss: 1.075895]\n",
      "[Epoch 0/30] [Batch 444/938] [D loss: 0.427823] [G loss: 0.880901]\n",
      "[Epoch 0/30] [Batch 445/938] [D loss: 0.417032] [G loss: 1.115586]\n",
      "[Epoch 0/30] [Batch 446/938] [D loss: 0.435144] [G loss: 0.844395]\n",
      "[Epoch 0/30] [Batch 447/938] [D loss: 0.408002] [G loss: 1.141473]\n",
      "[Epoch 0/30] [Batch 448/938] [D loss: 0.421546] [G loss: 0.889346]\n",
      "[Epoch 0/30] [Batch 449/938] [D loss: 0.420420] [G loss: 1.124494]\n",
      "[Epoch 0/30] [Batch 450/938] [D loss: 0.424204] [G loss: 0.819401]\n",
      "[Epoch 0/30] [Batch 451/938] [D loss: 0.411646] [G loss: 1.377894]\n",
      "[Epoch 0/30] [Batch 452/938] [D loss: 0.449489] [G loss: 0.671580]\n",
      "[Epoch 0/30] [Batch 453/938] [D loss: 0.445509] [G loss: 1.677893]\n",
      "[Epoch 0/30] [Batch 454/938] [D loss: 0.488667] [G loss: 0.587582]\n",
      "[Epoch 0/30] [Batch 455/938] [D loss: 0.401150] [G loss: 1.510249]\n",
      "[Epoch 0/30] [Batch 456/938] [D loss: 0.406359] [G loss: 0.898933]\n",
      "[Epoch 0/30] [Batch 457/938] [D loss: 0.402509] [G loss: 1.176455]\n",
      "[Epoch 0/30] [Batch 458/938] [D loss: 0.396062] [G loss: 0.959967]\n",
      "[Epoch 0/30] [Batch 459/938] [D loss: 0.347848] [G loss: 1.129026]\n",
      "[Epoch 0/30] [Batch 460/938] [D loss: 0.369936] [G loss: 1.266891]\n",
      "[Epoch 0/30] [Batch 461/938] [D loss: 0.389291] [G loss: 0.877029]\n",
      "[Epoch 0/30] [Batch 462/938] [D loss: 0.404757] [G loss: 1.366282]\n",
      "[Epoch 0/30] [Batch 463/938] [D loss: 0.447351] [G loss: 0.703529]\n",
      "[Epoch 0/30] [Batch 464/938] [D loss: 0.491872] [G loss: 1.450618]\n",
      "[Epoch 0/30] [Batch 465/938] [D loss: 0.535953] [G loss: 0.501066]\n",
      "[Epoch 0/30] [Batch 466/938] [D loss: 0.454866] [G loss: 1.792391]\n",
      "[Epoch 0/30] [Batch 467/938] [D loss: 0.429075] [G loss: 0.706346]\n",
      "[Epoch 0/30] [Batch 468/938] [D loss: 0.373011] [G loss: 1.299921]\n",
      "[Epoch 0/30] [Batch 469/938] [D loss: 0.379002] [G loss: 1.052389]\n",
      "[Epoch 0/30] [Batch 470/938] [D loss: 0.379407] [G loss: 1.000793]\n",
      "[Epoch 0/30] [Batch 471/938] [D loss: 0.389419] [G loss: 1.094181]\n",
      "[Epoch 0/30] [Batch 472/938] [D loss: 0.403760] [G loss: 1.002101]\n",
      "[Epoch 0/30] [Batch 473/938] [D loss: 0.427479] [G loss: 1.005327]\n",
      "[Epoch 0/30] [Batch 474/938] [D loss: 0.411595] [G loss: 0.926565]\n",
      "[Epoch 0/30] [Batch 475/938] [D loss: 0.429309] [G loss: 1.153597]\n",
      "[Epoch 0/30] [Batch 476/938] [D loss: 0.452025] [G loss: 0.783938]\n",
      "[Epoch 0/30] [Batch 477/938] [D loss: 0.459928] [G loss: 1.244788]\n",
      "[Epoch 0/30] [Batch 478/938] [D loss: 0.519273] [G loss: 0.601419]\n",
      "[Epoch 0/30] [Batch 479/938] [D loss: 0.454388] [G loss: 1.462693]\n",
      "[Epoch 0/30] [Batch 480/938] [D loss: 0.491486] [G loss: 0.603936]\n",
      "[Epoch 0/30] [Batch 481/938] [D loss: 0.493525] [G loss: 1.414385]\n",
      "[Epoch 0/30] [Batch 482/938] [D loss: 0.509767] [G loss: 0.548212]\n",
      "[Epoch 0/30] [Batch 483/938] [D loss: 0.450067] [G loss: 1.388212]\n",
      "[Epoch 0/30] [Batch 484/938] [D loss: 0.464155] [G loss: 0.689230]\n",
      "[Epoch 0/30] [Batch 485/938] [D loss: 0.399382] [G loss: 1.115758]\n",
      "[Epoch 0/30] [Batch 486/938] [D loss: 0.398822] [G loss: 1.020351]\n",
      "[Epoch 0/30] [Batch 487/938] [D loss: 0.439581] [G loss: 0.836803]\n",
      "[Epoch 0/30] [Batch 488/938] [D loss: 0.393431] [G loss: 1.135750]\n",
      "[Epoch 0/30] [Batch 489/938] [D loss: 0.416941] [G loss: 0.889302]\n",
      "[Epoch 0/30] [Batch 490/938] [D loss: 0.400172] [G loss: 1.042876]\n",
      "[Epoch 0/30] [Batch 491/938] [D loss: 0.397154] [G loss: 0.917928]\n",
      "[Epoch 0/30] [Batch 492/938] [D loss: 0.415195] [G loss: 1.036688]\n",
      "[Epoch 0/30] [Batch 493/938] [D loss: 0.427794] [G loss: 0.881365]\n",
      "[Epoch 0/30] [Batch 494/938] [D loss: 0.404296] [G loss: 1.035067]\n",
      "[Epoch 0/30] [Batch 495/938] [D loss: 0.431274] [G loss: 0.913040]\n",
      "[Epoch 0/30] [Batch 496/938] [D loss: 0.394594] [G loss: 0.979060]\n",
      "[Epoch 0/30] [Batch 497/938] [D loss: 0.396522] [G loss: 1.161542]\n",
      "[Epoch 0/30] [Batch 498/938] [D loss: 0.401046] [G loss: 0.787655]\n",
      "[Epoch 0/30] [Batch 499/938] [D loss: 0.426989] [G loss: 1.429271]\n",
      "[Epoch 0/30] [Batch 500/938] [D loss: 0.472675] [G loss: 0.619929]\n",
      "[Epoch 0/30] [Batch 501/938] [D loss: 0.410809] [G loss: 1.323241]\n",
      "[Epoch 0/30] [Batch 502/938] [D loss: 0.390910] [G loss: 0.918400]\n",
      "[Epoch 0/30] [Batch 503/938] [D loss: 0.383370] [G loss: 0.952843]\n",
      "[Epoch 0/30] [Batch 504/938] [D loss: 0.422152] [G loss: 1.183067]\n",
      "[Epoch 0/30] [Batch 505/938] [D loss: 0.451721] [G loss: 0.722732]\n",
      "[Epoch 0/30] [Batch 506/938] [D loss: 0.476504] [G loss: 1.198127]\n",
      "[Epoch 0/30] [Batch 507/938] [D loss: 0.515305] [G loss: 0.622157]\n",
      "[Epoch 0/30] [Batch 508/938] [D loss: 0.447180] [G loss: 1.101387]\n",
      "[Epoch 0/30] [Batch 509/938] [D loss: 0.415222] [G loss: 0.902739]\n",
      "[Epoch 0/30] [Batch 510/938] [D loss: 0.452189] [G loss: 0.947303]\n",
      "[Epoch 0/30] [Batch 511/938] [D loss: 0.420081] [G loss: 0.847131]\n",
      "[Epoch 0/30] [Batch 512/938] [D loss: 0.376430] [G loss: 1.100594]\n",
      "[Epoch 0/30] [Batch 513/938] [D loss: 0.393366] [G loss: 0.940211]\n",
      "[Epoch 0/30] [Batch 514/938] [D loss: 0.400357] [G loss: 1.062746]\n",
      "[Epoch 0/30] [Batch 515/938] [D loss: 0.428064] [G loss: 0.793993]\n",
      "[Epoch 0/30] [Batch 516/938] [D loss: 0.412232] [G loss: 1.199793]\n",
      "[Epoch 0/30] [Batch 517/938] [D loss: 0.452917] [G loss: 0.748862]\n",
      "[Epoch 0/30] [Batch 518/938] [D loss: 0.430071] [G loss: 1.051961]\n",
      "[Epoch 0/30] [Batch 519/938] [D loss: 0.449986] [G loss: 0.910694]\n",
      "[Epoch 0/30] [Batch 520/938] [D loss: 0.443594] [G loss: 0.798275]\n",
      "[Epoch 0/30] [Batch 521/938] [D loss: 0.417277] [G loss: 1.125810]\n",
      "[Epoch 0/30] [Batch 522/938] [D loss: 0.421599] [G loss: 0.856042]\n",
      "[Epoch 0/30] [Batch 523/938] [D loss: 0.373162] [G loss: 1.075787]\n",
      "[Epoch 0/30] [Batch 524/938] [D loss: 0.371339] [G loss: 1.071301]\n",
      "[Epoch 0/30] [Batch 525/938] [D loss: 0.361806] [G loss: 0.970981]\n",
      "[Epoch 0/30] [Batch 526/938] [D loss: 0.357971] [G loss: 1.176587]\n",
      "[Epoch 0/30] [Batch 527/938] [D loss: 0.356087] [G loss: 0.979937]\n",
      "[Epoch 0/30] [Batch 528/938] [D loss: 0.407831] [G loss: 1.192235]\n",
      "[Epoch 0/30] [Batch 529/938] [D loss: 0.403985] [G loss: 0.735886]\n",
      "[Epoch 0/30] [Batch 530/938] [D loss: 0.400221] [G loss: 1.548865]\n",
      "[Epoch 0/30] [Batch 531/938] [D loss: 0.403086] [G loss: 0.738620]\n",
      "[Epoch 0/30] [Batch 532/938] [D loss: 0.373824] [G loss: 1.405652]\n",
      "[Epoch 0/30] [Batch 533/938] [D loss: 0.386416] [G loss: 0.833737]\n",
      "[Epoch 0/30] [Batch 534/938] [D loss: 0.358041] [G loss: 1.193875]\n",
      "[Epoch 0/30] [Batch 535/938] [D loss: 0.364146] [G loss: 1.044741]\n",
      "[Epoch 0/30] [Batch 536/938] [D loss: 0.383266] [G loss: 1.004449]\n",
      "[Epoch 0/30] [Batch 537/938] [D loss: 0.355453] [G loss: 1.110851]\n",
      "[Epoch 0/30] [Batch 538/938] [D loss: 0.389389] [G loss: 0.979855]\n",
      "[Epoch 0/30] [Batch 539/938] [D loss: 0.373894] [G loss: 1.078471]\n",
      "[Epoch 0/30] [Batch 540/938] [D loss: 0.384303] [G loss: 0.921616]\n",
      "[Epoch 0/30] [Batch 541/938] [D loss: 0.385417] [G loss: 1.242833]\n",
      "[Epoch 0/30] [Batch 542/938] [D loss: 0.407895] [G loss: 0.804929]\n",
      "[Epoch 0/30] [Batch 543/938] [D loss: 0.407121] [G loss: 1.257186]\n",
      "[Epoch 0/30] [Batch 544/938] [D loss: 0.423537] [G loss: 0.784524]\n",
      "[Epoch 0/30] [Batch 545/938] [D loss: 0.401102] [G loss: 1.141825]\n",
      "[Epoch 0/30] [Batch 546/938] [D loss: 0.431454] [G loss: 0.846646]\n",
      "[Epoch 0/30] [Batch 547/938] [D loss: 0.396897] [G loss: 1.171882]\n",
      "[Epoch 0/30] [Batch 548/938] [D loss: 0.399765] [G loss: 0.835804]\n",
      "[Epoch 0/30] [Batch 549/938] [D loss: 0.371090] [G loss: 1.207211]\n",
      "[Epoch 0/30] [Batch 550/938] [D loss: 0.380230] [G loss: 1.001392]\n",
      "[Epoch 0/30] [Batch 551/938] [D loss: 0.372641] [G loss: 1.032722]\n",
      "[Epoch 0/30] [Batch 552/938] [D loss: 0.396131] [G loss: 1.056804]\n",
      "[Epoch 0/30] [Batch 553/938] [D loss: 0.382832] [G loss: 0.944080]\n",
      "[Epoch 0/30] [Batch 554/938] [D loss: 0.377365] [G loss: 1.195427]\n",
      "[Epoch 0/30] [Batch 555/938] [D loss: 0.355723] [G loss: 0.906939]\n",
      "[Epoch 0/30] [Batch 556/938] [D loss: 0.358464] [G loss: 1.480337]\n",
      "[Epoch 0/30] [Batch 557/938] [D loss: 0.385047] [G loss: 0.757834]\n",
      "[Epoch 0/30] [Batch 558/938] [D loss: 0.355898] [G loss: 1.584448]\n",
      "[Epoch 0/30] [Batch 559/938] [D loss: 0.353162] [G loss: 0.921393]\n",
      "[Epoch 0/30] [Batch 560/938] [D loss: 0.321938] [G loss: 1.193557]\n",
      "[Epoch 0/30] [Batch 561/938] [D loss: 0.329992] [G loss: 1.213810]\n",
      "[Epoch 0/30] [Batch 562/938] [D loss: 0.329639] [G loss: 1.053503]\n",
      "[Epoch 0/30] [Batch 563/938] [D loss: 0.343427] [G loss: 1.398660]\n",
      "[Epoch 0/30] [Batch 564/938] [D loss: 0.413993] [G loss: 0.718072]\n",
      "[Epoch 0/30] [Batch 565/938] [D loss: 0.368741] [G loss: 1.739542]\n",
      "[Epoch 0/30] [Batch 566/938] [D loss: 0.399285] [G loss: 0.748864]\n",
      "[Epoch 0/30] [Batch 567/938] [D loss: 0.332110] [G loss: 1.448048]\n",
      "[Epoch 0/30] [Batch 568/938] [D loss: 0.329031] [G loss: 1.037890]\n",
      "[Epoch 0/30] [Batch 569/938] [D loss: 0.331725] [G loss: 1.260738]\n",
      "[Epoch 0/30] [Batch 570/938] [D loss: 0.374198] [G loss: 1.006391]\n",
      "[Epoch 0/30] [Batch 571/938] [D loss: 0.374452] [G loss: 1.127192]\n",
      "[Epoch 0/30] [Batch 572/938] [D loss: 0.393552] [G loss: 1.022777]\n",
      "[Epoch 0/30] [Batch 573/938] [D loss: 0.371074] [G loss: 0.960347]\n",
      "[Epoch 0/30] [Batch 574/938] [D loss: 0.435435] [G loss: 1.384513]\n",
      "[Epoch 0/30] [Batch 575/938] [D loss: 0.541134] [G loss: 0.491546]\n",
      "[Epoch 0/30] [Batch 576/938] [D loss: 0.532748] [G loss: 2.016954]\n",
      "[Epoch 0/30] [Batch 577/938] [D loss: 0.581329] [G loss: 0.443337]\n",
      "[Epoch 0/30] [Batch 578/938] [D loss: 0.346904] [G loss: 1.538601]\n",
      "[Epoch 0/30] [Batch 579/938] [D loss: 0.313784] [G loss: 1.336113]\n",
      "[Epoch 0/30] [Batch 580/938] [D loss: 0.364973] [G loss: 0.916851]\n",
      "[Epoch 0/30] [Batch 581/938] [D loss: 0.360062] [G loss: 1.371757]\n",
      "[Epoch 0/30] [Batch 582/938] [D loss: 0.360714] [G loss: 0.943337]\n",
      "[Epoch 0/30] [Batch 583/938] [D loss: 0.383908] [G loss: 1.333612]\n",
      "[Epoch 0/30] [Batch 584/938] [D loss: 0.362712] [G loss: 0.868139]\n",
      "[Epoch 0/30] [Batch 585/938] [D loss: 0.371914] [G loss: 1.559464]\n",
      "[Epoch 0/30] [Batch 586/938] [D loss: 0.408017] [G loss: 0.736193]\n",
      "[Epoch 0/30] [Batch 587/938] [D loss: 0.416086] [G loss: 1.669629]\n",
      "[Epoch 0/30] [Batch 588/938] [D loss: 0.435162] [G loss: 0.647444]\n",
      "[Epoch 0/30] [Batch 589/938] [D loss: 0.404735] [G loss: 1.813000]\n",
      "[Epoch 0/30] [Batch 590/938] [D loss: 0.400830] [G loss: 0.723282]\n",
      "[Epoch 0/30] [Batch 591/938] [D loss: 0.324093] [G loss: 1.513539]\n",
      "[Epoch 0/30] [Batch 592/938] [D loss: 0.310713] [G loss: 1.135334]\n",
      "[Epoch 0/30] [Batch 593/938] [D loss: 0.327366] [G loss: 1.181557]\n",
      "[Epoch 0/30] [Batch 594/938] [D loss: 0.332316] [G loss: 1.176527]\n",
      "[Epoch 0/30] [Batch 595/938] [D loss: 0.345674] [G loss: 1.195567]\n",
      "[Epoch 0/30] [Batch 596/938] [D loss: 0.346550] [G loss: 1.055300]\n",
      "[Epoch 0/30] [Batch 597/938] [D loss: 0.342074] [G loss: 1.301036]\n",
      "[Epoch 0/30] [Batch 598/938] [D loss: 0.394295] [G loss: 0.963261]\n",
      "[Epoch 0/30] [Batch 599/938] [D loss: 0.380693] [G loss: 1.221230]\n",
      "[Epoch 0/30] [Batch 600/938] [D loss: 0.384568] [G loss: 0.920041]\n",
      "[Epoch 0/30] [Batch 601/938] [D loss: 0.392646] [G loss: 1.349951]\n",
      "[Epoch 0/30] [Batch 602/938] [D loss: 0.442810] [G loss: 0.682539]\n",
      "[Epoch 0/30] [Batch 603/938] [D loss: 0.502677] [G loss: 1.975778]\n",
      "[Epoch 0/30] [Batch 604/938] [D loss: 0.626799] [G loss: 0.378994]\n",
      "[Epoch 0/30] [Batch 605/938] [D loss: 0.400195] [G loss: 1.935776]\n",
      "[Epoch 0/30] [Batch 606/938] [D loss: 0.316691] [G loss: 1.001112]\n",
      "[Epoch 0/30] [Batch 607/938] [D loss: 0.316278] [G loss: 1.225778]\n",
      "[Epoch 0/30] [Batch 608/938] [D loss: 0.293167] [G loss: 1.356075]\n",
      "[Epoch 0/30] [Batch 609/938] [D loss: 0.329015] [G loss: 1.210758]\n",
      "[Epoch 0/30] [Batch 610/938] [D loss: 0.361443] [G loss: 1.007210]\n",
      "[Epoch 0/30] [Batch 611/938] [D loss: 0.390439] [G loss: 1.225527]\n",
      "[Epoch 0/30] [Batch 612/938] [D loss: 0.409950] [G loss: 0.790571]\n",
      "[Epoch 0/30] [Batch 613/938] [D loss: 0.471531] [G loss: 1.620573]\n",
      "[Epoch 0/30] [Batch 614/938] [D loss: 0.604400] [G loss: 0.417526]\n",
      "[Epoch 0/30] [Batch 615/938] [D loss: 0.502063] [G loss: 1.961644]\n",
      "[Epoch 0/30] [Batch 616/938] [D loss: 0.512453] [G loss: 0.556189]\n",
      "[Epoch 0/30] [Batch 617/938] [D loss: 0.442211] [G loss: 1.444151]\n",
      "[Epoch 0/30] [Batch 618/938] [D loss: 0.444094] [G loss: 0.707158]\n",
      "[Epoch 0/30] [Batch 619/938] [D loss: 0.424376] [G loss: 1.478236]\n",
      "[Epoch 0/30] [Batch 620/938] [D loss: 0.438691] [G loss: 0.676752]\n",
      "[Epoch 0/30] [Batch 621/938] [D loss: 0.386701] [G loss: 1.587610]\n",
      "[Epoch 0/30] [Batch 622/938] [D loss: 0.396312] [G loss: 0.824887]\n",
      "[Epoch 0/30] [Batch 623/938] [D loss: 0.373035] [G loss: 1.333278]\n",
      "[Epoch 0/30] [Batch 624/938] [D loss: 0.384908] [G loss: 0.962928]\n",
      "[Epoch 0/30] [Batch 625/938] [D loss: 0.378617] [G loss: 1.180306]\n",
      "[Epoch 0/30] [Batch 626/938] [D loss: 0.407422] [G loss: 1.015187]\n",
      "[Epoch 0/30] [Batch 627/938] [D loss: 0.418648] [G loss: 1.034296]\n",
      "[Epoch 0/30] [Batch 628/938] [D loss: 0.382856] [G loss: 1.022704]\n",
      "[Epoch 0/30] [Batch 629/938] [D loss: 0.425708] [G loss: 1.329083]\n",
      "[Epoch 0/30] [Batch 630/938] [D loss: 0.475088] [G loss: 0.642720]\n",
      "[Epoch 0/30] [Batch 631/938] [D loss: 0.409474] [G loss: 1.736027]\n",
      "[Epoch 0/30] [Batch 632/938] [D loss: 0.437367] [G loss: 0.698510]\n",
      "[Epoch 0/30] [Batch 633/938] [D loss: 0.359041] [G loss: 1.629538]\n",
      "[Epoch 0/30] [Batch 634/938] [D loss: 0.339667] [G loss: 0.999897]\n",
      "[Epoch 0/30] [Batch 635/938] [D loss: 0.330616] [G loss: 1.308960]\n",
      "[Epoch 0/30] [Batch 636/938] [D loss: 0.363988] [G loss: 1.220683]\n",
      "[Epoch 0/30] [Batch 637/938] [D loss: 0.385244] [G loss: 0.886303]\n",
      "[Epoch 0/30] [Batch 638/938] [D loss: 0.420488] [G loss: 1.695988]\n",
      "[Epoch 0/30] [Batch 639/938] [D loss: 0.481471] [G loss: 0.574734]\n",
      "[Epoch 0/30] [Batch 640/938] [D loss: 0.449848] [G loss: 1.972824]\n",
      "[Epoch 0/30] [Batch 641/938] [D loss: 0.452722] [G loss: 0.650434]\n",
      "[Epoch 0/30] [Batch 642/938] [D loss: 0.376711] [G loss: 1.576542]\n",
      "[Epoch 0/30] [Batch 643/938] [D loss: 0.401579] [G loss: 0.927195]\n",
      "[Epoch 0/30] [Batch 644/938] [D loss: 0.348537] [G loss: 1.157023]\n",
      "[Epoch 0/30] [Batch 645/938] [D loss: 0.361499] [G loss: 1.236973]\n",
      "[Epoch 0/30] [Batch 646/938] [D loss: 0.383661] [G loss: 0.975642]\n",
      "[Epoch 0/30] [Batch 647/938] [D loss: 0.385101] [G loss: 1.323951]\n",
      "[Epoch 0/30] [Batch 648/938] [D loss: 0.444779] [G loss: 0.820435]\n",
      "[Epoch 0/30] [Batch 649/938] [D loss: 0.442109] [G loss: 1.147921]\n",
      "[Epoch 0/30] [Batch 650/938] [D loss: 0.406253] [G loss: 0.878403]\n",
      "[Epoch 0/30] [Batch 651/938] [D loss: 0.431017] [G loss: 1.293798]\n",
      "[Epoch 0/30] [Batch 652/938] [D loss: 0.450859] [G loss: 0.684822]\n",
      "[Epoch 0/30] [Batch 653/938] [D loss: 0.439775] [G loss: 1.708692]\n",
      "[Epoch 0/30] [Batch 654/938] [D loss: 0.487498] [G loss: 0.584342]\n",
      "[Epoch 0/30] [Batch 655/938] [D loss: 0.447435] [G loss: 1.667483]\n",
      "[Epoch 0/30] [Batch 656/938] [D loss: 0.453558] [G loss: 0.651852]\n",
      "[Epoch 0/30] [Batch 657/938] [D loss: 0.353777] [G loss: 1.499096]\n",
      "[Epoch 0/30] [Batch 658/938] [D loss: 0.351862] [G loss: 1.061554]\n",
      "[Epoch 0/30] [Batch 659/938] [D loss: 0.369766] [G loss: 1.096302]\n",
      "[Epoch 0/30] [Batch 660/938] [D loss: 0.428733] [G loss: 1.085786]\n",
      "[Epoch 0/30] [Batch 661/938] [D loss: 0.428408] [G loss: 0.829544]\n",
      "[Epoch 0/30] [Batch 662/938] [D loss: 0.412686] [G loss: 1.306697]\n",
      "[Epoch 0/30] [Batch 663/938] [D loss: 0.475758] [G loss: 0.768717]\n",
      "[Epoch 0/30] [Batch 664/938] [D loss: 0.432222] [G loss: 1.254278]\n",
      "[Epoch 0/30] [Batch 665/938] [D loss: 0.475779] [G loss: 0.766351]\n",
      "[Epoch 0/30] [Batch 666/938] [D loss: 0.447757] [G loss: 1.143600]\n",
      "[Epoch 0/30] [Batch 667/938] [D loss: 0.391685] [G loss: 0.865300]\n",
      "[Epoch 0/30] [Batch 668/938] [D loss: 0.404887] [G loss: 1.326955]\n",
      "[Epoch 0/30] [Batch 669/938] [D loss: 0.419223] [G loss: 0.763975]\n",
      "[Epoch 0/30] [Batch 670/938] [D loss: 0.404680] [G loss: 1.434021]\n",
      "[Epoch 0/30] [Batch 671/938] [D loss: 0.366497] [G loss: 0.893962]\n",
      "[Epoch 0/30] [Batch 672/938] [D loss: 0.372728] [G loss: 1.340310]\n",
      "[Epoch 0/30] [Batch 673/938] [D loss: 0.371891] [G loss: 0.908794]\n",
      "[Epoch 0/30] [Batch 674/938] [D loss: 0.344994] [G loss: 1.278872]\n",
      "[Epoch 0/30] [Batch 675/938] [D loss: 0.347498] [G loss: 1.042785]\n",
      "[Epoch 0/30] [Batch 676/938] [D loss: 0.357585] [G loss: 1.141980]\n",
      "[Epoch 0/30] [Batch 677/938] [D loss: 0.371327] [G loss: 1.125073]\n",
      "[Epoch 0/30] [Batch 678/938] [D loss: 0.336319] [G loss: 0.980565]\n",
      "[Epoch 0/30] [Batch 679/938] [D loss: 0.353171] [G loss: 1.441123]\n",
      "[Epoch 0/30] [Batch 680/938] [D loss: 0.339689] [G loss: 0.907174]\n",
      "[Epoch 0/30] [Batch 681/938] [D loss: 0.301270] [G loss: 1.434252]\n",
      "[Epoch 0/30] [Batch 682/938] [D loss: 0.331117] [G loss: 1.156402]\n",
      "[Epoch 0/30] [Batch 683/938] [D loss: 0.356947] [G loss: 0.930494]\n",
      "[Epoch 0/30] [Batch 684/938] [D loss: 0.348717] [G loss: 1.463647]\n",
      "[Epoch 0/30] [Batch 685/938] [D loss: 0.392188] [G loss: 0.875948]\n",
      "[Epoch 0/30] [Batch 686/938] [D loss: 0.351114] [G loss: 1.360858]\n",
      "[Epoch 0/30] [Batch 687/938] [D loss: 0.351101] [G loss: 0.938255]\n",
      "[Epoch 0/30] [Batch 688/938] [D loss: 0.361700] [G loss: 1.584827]\n",
      "[Epoch 0/30] [Batch 689/938] [D loss: 0.403910] [G loss: 0.773753]\n",
      "[Epoch 0/30] [Batch 690/938] [D loss: 0.308918] [G loss: 1.709670]\n",
      "[Epoch 0/30] [Batch 691/938] [D loss: 0.301082] [G loss: 1.038496]\n",
      "[Epoch 0/30] [Batch 692/938] [D loss: 0.303630] [G loss: 1.370298]\n",
      "[Epoch 0/30] [Batch 693/938] [D loss: 0.300638] [G loss: 1.175251]\n",
      "[Epoch 0/30] [Batch 694/938] [D loss: 0.291602] [G loss: 1.241732]\n",
      "[Epoch 0/30] [Batch 695/938] [D loss: 0.323432] [G loss: 1.173152]\n",
      "[Epoch 0/30] [Batch 696/938] [D loss: 0.348356] [G loss: 1.144600]\n",
      "[Epoch 0/30] [Batch 697/938] [D loss: 0.319039] [G loss: 1.100612]\n",
      "[Epoch 0/30] [Batch 698/938] [D loss: 0.364715] [G loss: 1.384605]\n",
      "[Epoch 0/30] [Batch 699/938] [D loss: 0.406140] [G loss: 0.753081]\n",
      "[Epoch 0/30] [Batch 700/938] [D loss: 0.443842] [G loss: 1.918062]\n",
      "[Epoch 0/30] [Batch 701/938] [D loss: 0.512339] [G loss: 0.545320]\n",
      "[Epoch 0/30] [Batch 702/938] [D loss: 0.406157] [G loss: 1.802673]\n",
      "[Epoch 0/30] [Batch 703/938] [D loss: 0.327187] [G loss: 0.954423]\n",
      "[Epoch 0/30] [Batch 704/938] [D loss: 0.293471] [G loss: 1.182312]\n",
      "[Epoch 0/30] [Batch 705/938] [D loss: 0.299556] [G loss: 1.504611]\n",
      "[Epoch 0/30] [Batch 706/938] [D loss: 0.357863] [G loss: 0.876153]\n",
      "[Epoch 0/30] [Batch 707/938] [D loss: 0.347497] [G loss: 1.570297]\n",
      "[Epoch 0/30] [Batch 708/938] [D loss: 0.385745] [G loss: 0.854407]\n",
      "[Epoch 0/30] [Batch 709/938] [D loss: 0.436390] [G loss: 1.422875]\n",
      "[Epoch 0/30] [Batch 710/938] [D loss: 0.456330] [G loss: 0.669974]\n",
      "[Epoch 0/30] [Batch 711/938] [D loss: 0.356808] [G loss: 1.724576]\n",
      "[Epoch 0/30] [Batch 712/938] [D loss: 0.331333] [G loss: 0.971756]\n",
      "[Epoch 0/30] [Batch 713/938] [D loss: 0.303468] [G loss: 1.241712]\n",
      "[Epoch 0/30] [Batch 714/938] [D loss: 0.305322] [G loss: 1.367792]\n",
      "[Epoch 0/30] [Batch 715/938] [D loss: 0.308131] [G loss: 1.074486]\n",
      "[Epoch 0/30] [Batch 716/938] [D loss: 0.328211] [G loss: 1.428540]\n",
      "[Epoch 0/30] [Batch 717/938] [D loss: 0.344599] [G loss: 0.965108]\n",
      "[Epoch 0/30] [Batch 718/938] [D loss: 0.337788] [G loss: 1.366366]\n",
      "[Epoch 0/30] [Batch 719/938] [D loss: 0.370460] [G loss: 0.957925]\n",
      "[Epoch 0/30] [Batch 720/938] [D loss: 0.352397] [G loss: 1.247342]\n",
      "[Epoch 0/30] [Batch 721/938] [D loss: 0.363922] [G loss: 0.989987]\n",
      "[Epoch 0/30] [Batch 722/938] [D loss: 0.353889] [G loss: 1.329763]\n",
      "[Epoch 0/30] [Batch 723/938] [D loss: 0.343759] [G loss: 0.942555]\n",
      "[Epoch 0/30] [Batch 724/938] [D loss: 0.345770] [G loss: 1.663218]\n",
      "[Epoch 0/30] [Batch 725/938] [D loss: 0.335359] [G loss: 0.906279]\n",
      "[Epoch 0/30] [Batch 726/938] [D loss: 0.321077] [G loss: 1.648170]\n",
      "[Epoch 0/30] [Batch 727/938] [D loss: 0.305405] [G loss: 1.051459]\n",
      "[Epoch 0/30] [Batch 728/938] [D loss: 0.278691] [G loss: 1.457874]\n",
      "[Epoch 0/30] [Batch 729/938] [D loss: 0.302691] [G loss: 1.346150]\n",
      "[Epoch 0/30] [Batch 730/938] [D loss: 0.322971] [G loss: 1.078036]\n",
      "[Epoch 0/30] [Batch 731/938] [D loss: 0.294482] [G loss: 1.497243]\n",
      "[Epoch 0/30] [Batch 732/938] [D loss: 0.320736] [G loss: 1.083722]\n",
      "[Epoch 0/30] [Batch 733/938] [D loss: 0.317550] [G loss: 1.363057]\n",
      "[Epoch 0/30] [Batch 734/938] [D loss: 0.365923] [G loss: 1.059001]\n",
      "[Epoch 0/30] [Batch 735/938] [D loss: 0.325057] [G loss: 1.251917]\n",
      "[Epoch 0/30] [Batch 736/938] [D loss: 0.292445] [G loss: 1.307211]\n",
      "[Epoch 0/30] [Batch 737/938] [D loss: 0.286699] [G loss: 1.443959]\n",
      "[Epoch 0/30] [Batch 738/938] [D loss: 0.294780] [G loss: 1.227500]\n",
      "[Epoch 0/30] [Batch 739/938] [D loss: 0.270430] [G loss: 1.514753]\n",
      "[Epoch 0/30] [Batch 740/938] [D loss: 0.273291] [G loss: 1.344728]\n",
      "[Epoch 0/30] [Batch 741/938] [D loss: 0.326673] [G loss: 1.480135]\n",
      "[Epoch 0/30] [Batch 742/938] [D loss: 0.343507] [G loss: 0.899633]\n",
      "[Epoch 0/30] [Batch 743/938] [D loss: 0.409852] [G loss: 2.101092]\n",
      "[Epoch 0/30] [Batch 744/938] [D loss: 0.463450] [G loss: 0.603915]\n",
      "[Epoch 0/30] [Batch 745/938] [D loss: 0.344564] [G loss: 2.153909]\n",
      "[Epoch 0/30] [Batch 746/938] [D loss: 0.333976] [G loss: 1.003514]\n",
      "[Epoch 0/30] [Batch 747/938] [D loss: 0.278544] [G loss: 1.554474]\n",
      "[Epoch 0/30] [Batch 748/938] [D loss: 0.266389] [G loss: 1.390723]\n",
      "[Epoch 0/30] [Batch 749/938] [D loss: 0.280449] [G loss: 1.276193]\n",
      "[Epoch 0/30] [Batch 750/938] [D loss: 0.296906] [G loss: 1.549046]\n",
      "[Epoch 0/30] [Batch 751/938] [D loss: 0.307402] [G loss: 1.063024]\n",
      "[Epoch 0/30] [Batch 752/938] [D loss: 0.347622] [G loss: 1.827069]\n",
      "[Epoch 0/30] [Batch 753/938] [D loss: 0.367564] [G loss: 0.782386]\n",
      "[Epoch 0/30] [Batch 754/938] [D loss: 0.334299] [G loss: 2.128047]\n",
      "[Epoch 0/30] [Batch 755/938] [D loss: 0.342598] [G loss: 0.953466]\n",
      "[Epoch 0/30] [Batch 756/938] [D loss: 0.306231] [G loss: 1.689332]\n",
      "[Epoch 0/30] [Batch 757/938] [D loss: 0.338900] [G loss: 1.009789]\n",
      "[Epoch 0/30] [Batch 758/938] [D loss: 0.336550] [G loss: 1.585564]\n",
      "[Epoch 0/30] [Batch 759/938] [D loss: 0.359883] [G loss: 0.941658]\n",
      "[Epoch 0/30] [Batch 760/938] [D loss: 0.295922] [G loss: 1.622001]\n",
      "[Epoch 0/30] [Batch 761/938] [D loss: 0.340167] [G loss: 1.176386]\n",
      "[Epoch 0/30] [Batch 762/938] [D loss: 0.324256] [G loss: 1.223435]\n",
      "[Epoch 0/30] [Batch 763/938] [D loss: 0.320351] [G loss: 1.575516]\n",
      "[Epoch 0/30] [Batch 764/938] [D loss: 0.401204] [G loss: 0.798595]\n",
      "[Epoch 0/30] [Batch 765/938] [D loss: 0.435262] [G loss: 2.152422]\n",
      "[Epoch 0/30] [Batch 766/938] [D loss: 0.578689] [G loss: 0.449623]\n",
      "[Epoch 0/30] [Batch 767/938] [D loss: 0.506007] [G loss: 2.645825]\n",
      "[Epoch 0/30] [Batch 768/938] [D loss: 0.453971] [G loss: 0.644123]\n",
      "[Epoch 0/30] [Batch 769/938] [D loss: 0.356065] [G loss: 1.955415]\n",
      "[Epoch 0/30] [Batch 770/938] [D loss: 0.337097] [G loss: 0.933250]\n",
      "[Epoch 0/30] [Batch 771/938] [D loss: 0.290172] [G loss: 1.538072]\n",
      "[Epoch 0/30] [Batch 772/938] [D loss: 0.357926] [G loss: 1.377428]\n",
      "[Epoch 0/30] [Batch 773/938] [D loss: 0.438091] [G loss: 0.679774]\n",
      "[Epoch 0/30] [Batch 774/938] [D loss: 0.442377] [G loss: 2.193752]\n",
      "[Epoch 0/30] [Batch 775/938] [D loss: 0.469099] [G loss: 0.617450]\n",
      "[Epoch 0/30] [Batch 776/938] [D loss: 0.369705] [G loss: 1.905265]\n",
      "[Epoch 0/30] [Batch 777/938] [D loss: 0.390181] [G loss: 0.881750]\n",
      "[Epoch 0/30] [Batch 778/938] [D loss: 0.317737] [G loss: 1.580734]\n",
      "[Epoch 0/30] [Batch 779/938] [D loss: 0.301427] [G loss: 1.095003]\n",
      "[Epoch 0/30] [Batch 780/938] [D loss: 0.360308] [G loss: 1.655425]\n",
      "[Epoch 0/30] [Batch 781/938] [D loss: 0.383138] [G loss: 0.818821]\n",
      "[Epoch 0/30] [Batch 782/938] [D loss: 0.344582] [G loss: 1.765329]\n",
      "[Epoch 0/30] [Batch 783/938] [D loss: 0.370406] [G loss: 1.007993]\n",
      "[Epoch 0/30] [Batch 784/938] [D loss: 0.380364] [G loss: 1.152188]\n",
      "[Epoch 0/30] [Batch 785/938] [D loss: 0.385489] [G loss: 1.195018]\n",
      "[Epoch 0/30] [Batch 786/938] [D loss: 0.404028] [G loss: 1.046826]\n",
      "[Epoch 0/30] [Batch 787/938] [D loss: 0.367706] [G loss: 1.082351]\n",
      "[Epoch 0/30] [Batch 788/938] [D loss: 0.350124] [G loss: 1.361043]\n",
      "[Epoch 0/30] [Batch 789/938] [D loss: 0.381596] [G loss: 1.093447]\n",
      "[Epoch 0/30] [Batch 790/938] [D loss: 0.389981] [G loss: 1.112700]\n",
      "[Epoch 0/30] [Batch 791/938] [D loss: 0.413744] [G loss: 1.097567]\n",
      "[Epoch 0/30] [Batch 792/938] [D loss: 0.402489] [G loss: 1.234223]\n",
      "[Epoch 0/30] [Batch 793/938] [D loss: 0.415763] [G loss: 0.875494]\n",
      "[Epoch 0/30] [Batch 794/938] [D loss: 0.481787] [G loss: 1.711819]\n",
      "[Epoch 0/30] [Batch 795/938] [D loss: 0.598225] [G loss: 0.451670]\n",
      "[Epoch 0/30] [Batch 796/938] [D loss: 0.537968] [G loss: 2.487452]\n",
      "[Epoch 0/30] [Batch 797/938] [D loss: 0.505228] [G loss: 0.610102]\n",
      "[Epoch 0/30] [Batch 798/938] [D loss: 0.355285] [G loss: 1.625576]\n",
      "[Epoch 0/30] [Batch 799/938] [D loss: 0.350440] [G loss: 1.228683]\n",
      "[Epoch 0/30] [Batch 800/938] [D loss: 0.351250] [G loss: 1.042945]\n",
      "[Epoch 0/30] [Batch 801/938] [D loss: 0.379000] [G loss: 1.433282]\n",
      "[Epoch 0/30] [Batch 802/938] [D loss: 0.464693] [G loss: 0.739755]\n",
      "[Epoch 0/30] [Batch 803/938] [D loss: 0.427503] [G loss: 1.546110]\n",
      "[Epoch 0/30] [Batch 804/938] [D loss: 0.484986] [G loss: 0.644404]\n",
      "[Epoch 0/30] [Batch 805/938] [D loss: 0.529297] [G loss: 1.829959]\n",
      "[Epoch 0/30] [Batch 806/938] [D loss: 0.627346] [G loss: 0.441782]\n",
      "[Epoch 0/30] [Batch 807/938] [D loss: 0.464012] [G loss: 2.049977]\n",
      "[Epoch 0/30] [Batch 808/938] [D loss: 0.438938] [G loss: 0.841004]\n",
      "[Epoch 0/30] [Batch 809/938] [D loss: 0.406716] [G loss: 1.189494]\n",
      "[Epoch 0/30] [Batch 810/938] [D loss: 0.349166] [G loss: 1.060924]\n",
      "[Epoch 0/30] [Batch 811/938] [D loss: 0.395246] [G loss: 1.480742]\n",
      "[Epoch 0/30] [Batch 812/938] [D loss: 0.463894] [G loss: 0.686191]\n",
      "[Epoch 0/30] [Batch 813/938] [D loss: 0.459555] [G loss: 1.761266]\n",
      "[Epoch 0/30] [Batch 814/938] [D loss: 0.513702] [G loss: 0.587343]\n",
      "[Epoch 0/30] [Batch 815/938] [D loss: 0.500307] [G loss: 1.776569]\n",
      "[Epoch 0/30] [Batch 816/938] [D loss: 0.518177] [G loss: 0.589555]\n",
      "[Epoch 0/30] [Batch 817/938] [D loss: 0.421855] [G loss: 1.778371]\n",
      "[Epoch 0/30] [Batch 818/938] [D loss: 0.450796] [G loss: 0.799261]\n",
      "[Epoch 0/30] [Batch 819/938] [D loss: 0.392685] [G loss: 1.281501]\n",
      "[Epoch 0/30] [Batch 820/938] [D loss: 0.451783] [G loss: 0.900318]\n",
      "[Epoch 0/30] [Batch 821/938] [D loss: 0.408253] [G loss: 1.161036]\n",
      "[Epoch 0/30] [Batch 822/938] [D loss: 0.475014] [G loss: 0.947307]\n",
      "[Epoch 0/30] [Batch 823/938] [D loss: 0.503975] [G loss: 0.803466]\n",
      "[Epoch 0/30] [Batch 824/938] [D loss: 0.469982] [G loss: 1.250161]\n",
      "[Epoch 0/30] [Batch 825/938] [D loss: 0.495765] [G loss: 0.744827]\n",
      "[Epoch 0/30] [Batch 826/938] [D loss: 0.456243] [G loss: 1.369538]\n",
      "[Epoch 0/30] [Batch 827/938] [D loss: 0.509250] [G loss: 0.685037]\n",
      "[Epoch 0/30] [Batch 828/938] [D loss: 0.485848] [G loss: 1.513026]\n",
      "[Epoch 0/30] [Batch 829/938] [D loss: 0.565418] [G loss: 0.569258]\n",
      "[Epoch 0/30] [Batch 830/938] [D loss: 0.534486] [G loss: 1.746534]\n",
      "[Epoch 0/30] [Batch 831/938] [D loss: 0.565100] [G loss: 0.616085]\n",
      "[Epoch 0/30] [Batch 832/938] [D loss: 0.494710] [G loss: 1.439189]\n",
      "[Epoch 0/30] [Batch 833/938] [D loss: 0.452019] [G loss: 0.823403]\n",
      "[Epoch 0/30] [Batch 834/938] [D loss: 0.472554] [G loss: 1.199512]\n",
      "[Epoch 0/30] [Batch 835/938] [D loss: 0.446743] [G loss: 0.786224]\n",
      "[Epoch 0/30] [Batch 836/938] [D loss: 0.412626] [G loss: 1.469510]\n",
      "[Epoch 0/30] [Batch 837/938] [D loss: 0.452678] [G loss: 0.870725]\n",
      "[Epoch 0/30] [Batch 838/938] [D loss: 0.432571] [G loss: 1.161027]\n",
      "[Epoch 0/30] [Batch 839/938] [D loss: 0.488128] [G loss: 0.894901]\n",
      "[Epoch 0/30] [Batch 840/938] [D loss: 0.394575] [G loss: 1.156341]\n",
      "[Epoch 0/30] [Batch 841/938] [D loss: 0.416445] [G loss: 1.256853]\n",
      "[Epoch 0/30] [Batch 842/938] [D loss: 0.436727] [G loss: 0.881131]\n",
      "[Epoch 0/30] [Batch 843/938] [D loss: 0.383343] [G loss: 1.270388]\n",
      "[Epoch 0/30] [Batch 844/938] [D loss: 0.418554] [G loss: 1.001529]\n",
      "[Epoch 0/30] [Batch 845/938] [D loss: 0.437027] [G loss: 1.102603]\n",
      "[Epoch 0/30] [Batch 846/938] [D loss: 0.411250] [G loss: 0.895820]\n",
      "[Epoch 0/30] [Batch 847/938] [D loss: 0.430108] [G loss: 1.511056]\n",
      "[Epoch 0/30] [Batch 848/938] [D loss: 0.472324] [G loss: 0.651783]\n",
      "[Epoch 0/30] [Batch 849/938] [D loss: 0.534750] [G loss: 1.764866]\n",
      "[Epoch 0/30] [Batch 850/938] [D loss: 0.607695] [G loss: 0.455479]\n",
      "[Epoch 0/30] [Batch 851/938] [D loss: 0.438943] [G loss: 1.896451]\n",
      "[Epoch 0/30] [Batch 852/938] [D loss: 0.387788] [G loss: 0.845086]\n",
      "[Epoch 0/30] [Batch 853/938] [D loss: 0.349114] [G loss: 1.388148]\n",
      "[Epoch 0/30] [Batch 854/938] [D loss: 0.371018] [G loss: 1.102521]\n",
      "[Epoch 0/30] [Batch 855/938] [D loss: 0.372437] [G loss: 1.080829]\n",
      "[Epoch 0/30] [Batch 856/938] [D loss: 0.395067] [G loss: 1.116012]\n",
      "[Epoch 0/30] [Batch 857/938] [D loss: 0.391833] [G loss: 0.989377]\n",
      "[Epoch 0/30] [Batch 858/938] [D loss: 0.399108] [G loss: 1.190178]\n",
      "[Epoch 0/30] [Batch 859/938] [D loss: 0.456790] [G loss: 0.831463]\n",
      "[Epoch 0/30] [Batch 860/938] [D loss: 0.460098] [G loss: 1.298445]\n",
      "[Epoch 0/30] [Batch 861/938] [D loss: 0.527628] [G loss: 0.596109]\n",
      "[Epoch 0/30] [Batch 862/938] [D loss: 0.461311] [G loss: 1.814099]\n",
      "[Epoch 0/30] [Batch 863/938] [D loss: 0.526169] [G loss: 0.563811]\n",
      "[Epoch 0/30] [Batch 864/938] [D loss: 0.506674] [G loss: 1.691575]\n",
      "[Epoch 0/30] [Batch 865/938] [D loss: 0.536456] [G loss: 0.564002]\n",
      "[Epoch 0/30] [Batch 866/938] [D loss: 0.436719] [G loss: 1.572771]\n",
      "[Epoch 0/30] [Batch 867/938] [D loss: 0.438232] [G loss: 0.780524]\n",
      "[Epoch 0/30] [Batch 868/938] [D loss: 0.408927] [G loss: 1.235945]\n",
      "[Epoch 0/30] [Batch 869/938] [D loss: 0.414422] [G loss: 0.872097]\n",
      "[Epoch 0/30] [Batch 870/938] [D loss: 0.414358] [G loss: 1.301469]\n",
      "[Epoch 0/30] [Batch 871/938] [D loss: 0.391588] [G loss: 0.865204]\n",
      "[Epoch 0/30] [Batch 872/938] [D loss: 0.410912] [G loss: 1.317729]\n",
      "[Epoch 0/30] [Batch 873/938] [D loss: 0.436519] [G loss: 0.902045]\n",
      "[Epoch 0/30] [Batch 874/938] [D loss: 0.394827] [G loss: 1.115590]\n",
      "[Epoch 0/30] [Batch 875/938] [D loss: 0.403710] [G loss: 0.999855]\n",
      "[Epoch 0/30] [Batch 876/938] [D loss: 0.424712] [G loss: 1.204116]\n",
      "[Epoch 0/30] [Batch 877/938] [D loss: 0.468906] [G loss: 0.780533]\n",
      "[Epoch 0/30] [Batch 878/938] [D loss: 0.444522] [G loss: 1.336722]\n",
      "[Epoch 0/30] [Batch 879/938] [D loss: 0.492987] [G loss: 0.686473]\n",
      "[Epoch 0/30] [Batch 880/938] [D loss: 0.424048] [G loss: 1.387171]\n",
      "[Epoch 0/30] [Batch 881/938] [D loss: 0.452065] [G loss: 0.773827]\n",
      "[Epoch 0/30] [Batch 882/938] [D loss: 0.488405] [G loss: 1.326878]\n",
      "[Epoch 0/30] [Batch 883/938] [D loss: 0.486950] [G loss: 0.714203]\n",
      "[Epoch 0/30] [Batch 884/938] [D loss: 0.458021] [G loss: 1.385254]\n",
      "[Epoch 0/30] [Batch 885/938] [D loss: 0.433238] [G loss: 0.840574]\n",
      "[Epoch 0/30] [Batch 886/938] [D loss: 0.474522] [G loss: 1.107657]\n",
      "[Epoch 0/30] [Batch 887/938] [D loss: 0.457821] [G loss: 0.835336]\n",
      "[Epoch 0/30] [Batch 888/938] [D loss: 0.449541] [G loss: 1.206937]\n",
      "[Epoch 0/30] [Batch 889/938] [D loss: 0.481160] [G loss: 0.779610]\n",
      "[Epoch 0/30] [Batch 890/938] [D loss: 0.410300] [G loss: 1.241472]\n",
      "[Epoch 0/30] [Batch 891/938] [D loss: 0.458921] [G loss: 0.752343]\n",
      "[Epoch 0/30] [Batch 892/938] [D loss: 0.437131] [G loss: 1.379219]\n",
      "[Epoch 0/30] [Batch 893/938] [D loss: 0.448533] [G loss: 0.682355]\n",
      "[Epoch 0/30] [Batch 894/938] [D loss: 0.422622] [G loss: 1.579113]\n",
      "[Epoch 0/30] [Batch 895/938] [D loss: 0.426515] [G loss: 0.734314]\n",
      "[Epoch 0/30] [Batch 896/938] [D loss: 0.419822] [G loss: 1.495117]\n",
      "[Epoch 0/30] [Batch 897/938] [D loss: 0.457574] [G loss: 0.626140]\n",
      "[Epoch 0/30] [Batch 898/938] [D loss: 0.491527] [G loss: 1.868732]\n",
      "[Epoch 0/30] [Batch 899/938] [D loss: 0.590907] [G loss: 0.464786]\n",
      "[Epoch 0/30] [Batch 900/938] [D loss: 0.480898] [G loss: 1.729887]\n",
      "[Epoch 0/30] [Batch 901/938] [D loss: 0.436205] [G loss: 0.680961]\n",
      "[Epoch 0/30] [Batch 902/938] [D loss: 0.357844] [G loss: 1.381392]\n",
      "[Epoch 0/30] [Batch 903/938] [D loss: 0.394221] [G loss: 1.045570]\n",
      "[Epoch 0/30] [Batch 904/938] [D loss: 0.404933] [G loss: 0.906786]\n",
      "[Epoch 0/30] [Batch 905/938] [D loss: 0.448197] [G loss: 1.301927]\n",
      "[Epoch 0/30] [Batch 906/938] [D loss: 0.492872] [G loss: 0.640838]\n",
      "[Epoch 0/30] [Batch 907/938] [D loss: 0.529604] [G loss: 1.522181]\n",
      "[Epoch 0/30] [Batch 908/938] [D loss: 0.579737] [G loss: 0.499284]\n",
      "[Epoch 0/30] [Batch 909/938] [D loss: 0.596133] [G loss: 1.667496]\n",
      "[Epoch 0/30] [Batch 910/938] [D loss: 0.704142] [G loss: 0.403067]\n",
      "[Epoch 0/30] [Batch 911/938] [D loss: 0.563307] [G loss: 1.631515]\n",
      "[Epoch 0/30] [Batch 912/938] [D loss: 0.514479] [G loss: 0.614836]\n",
      "[Epoch 0/30] [Batch 913/938] [D loss: 0.483204] [G loss: 1.439911]\n",
      "[Epoch 0/30] [Batch 914/938] [D loss: 0.485796] [G loss: 0.668789]\n",
      "[Epoch 0/30] [Batch 915/938] [D loss: 0.464141] [G loss: 1.346175]\n",
      "[Epoch 0/30] [Batch 916/938] [D loss: 0.511231] [G loss: 0.680591]\n",
      "[Epoch 0/30] [Batch 917/938] [D loss: 0.484140] [G loss: 1.239258]\n",
      "[Epoch 0/30] [Batch 918/938] [D loss: 0.484229] [G loss: 0.749170]\n",
      "[Epoch 0/30] [Batch 919/938] [D loss: 0.444143] [G loss: 1.155338]\n",
      "[Epoch 0/30] [Batch 920/938] [D loss: 0.437045] [G loss: 0.867510]\n",
      "[Epoch 0/30] [Batch 921/938] [D loss: 0.438677] [G loss: 1.113858]\n",
      "[Epoch 0/30] [Batch 922/938] [D loss: 0.438007] [G loss: 0.898439]\n",
      "[Epoch 0/30] [Batch 923/938] [D loss: 0.422788] [G loss: 1.238177]\n",
      "[Epoch 0/30] [Batch 924/938] [D loss: 0.477076] [G loss: 0.759932]\n",
      "[Epoch 0/30] [Batch 925/938] [D loss: 0.455918] [G loss: 1.304134]\n",
      "[Epoch 0/30] [Batch 926/938] [D loss: 0.460704] [G loss: 0.799278]\n",
      "[Epoch 0/30] [Batch 927/938] [D loss: 0.421067] [G loss: 1.276466]\n",
      "[Epoch 0/30] [Batch 928/938] [D loss: 0.437984] [G loss: 0.963881]\n",
      "[Epoch 0/30] [Batch 929/938] [D loss: 0.429204] [G loss: 1.019772]\n",
      "[Epoch 0/30] [Batch 930/938] [D loss: 0.449135] [G loss: 1.132623]\n",
      "[Epoch 0/30] [Batch 931/938] [D loss: 0.458370] [G loss: 0.814997]\n",
      "[Epoch 0/30] [Batch 932/938] [D loss: 0.439093] [G loss: 1.421295]\n",
      "[Epoch 0/30] [Batch 933/938] [D loss: 0.468308] [G loss: 0.683437]\n",
      "[Epoch 0/30] [Batch 934/938] [D loss: 0.515159] [G loss: 1.922333]\n",
      "[Epoch 0/30] [Batch 935/938] [D loss: 0.635678] [G loss: 0.411524]\n",
      "[Epoch 0/30] [Batch 936/938] [D loss: 0.557995] [G loss: 2.062281]\n",
      "[Epoch 0/30] [Batch 937/938] [D loss: 0.559378] [G loss: 0.468058]\n",
      "[Epoch 1/30] [Batch 0/938] [D loss: 0.497800] [G loss: 1.971036]\n",
      "[Epoch 1/30] [Batch 1/938] [D loss: 0.483003] [G loss: 0.595297]\n",
      "[Epoch 1/30] [Batch 2/938] [D loss: 0.401736] [G loss: 1.765798]\n",
      "[Epoch 1/30] [Batch 3/938] [D loss: 0.430097] [G loss: 0.808179]\n",
      "[Epoch 1/30] [Batch 4/938] [D loss: 0.407713] [G loss: 1.306311]\n",
      "[Epoch 1/30] [Batch 5/938] [D loss: 0.413793] [G loss: 0.929265]\n",
      "[Epoch 1/30] [Batch 6/938] [D loss: 0.454911] [G loss: 1.162599]\n",
      "[Epoch 1/30] [Batch 7/938] [D loss: 0.434555] [G loss: 0.790430]\n",
      "[Epoch 1/30] [Batch 8/938] [D loss: 0.470171] [G loss: 1.689381]\n",
      "[Epoch 1/30] [Batch 9/938] [D loss: 0.574519] [G loss: 0.494524]\n",
      "[Epoch 1/30] [Batch 10/938] [D loss: 0.549841] [G loss: 1.968048]\n",
      "[Epoch 1/30] [Batch 11/938] [D loss: 0.672781] [G loss: 0.352482]\n",
      "[Epoch 1/30] [Batch 12/938] [D loss: 0.481451] [G loss: 2.109330]\n",
      "[Epoch 1/30] [Batch 13/938] [D loss: 0.457365] [G loss: 0.794949]\n",
      "[Epoch 1/30] [Batch 14/938] [D loss: 0.403508] [G loss: 0.999011]\n",
      "[Epoch 1/30] [Batch 15/938] [D loss: 0.513674] [G loss: 1.476287]\n",
      "[Epoch 1/30] [Batch 16/938] [D loss: 0.629592] [G loss: 0.410810]\n",
      "[Epoch 1/30] [Batch 17/938] [D loss: 0.732772] [G loss: 2.044461]\n",
      "[Epoch 1/30] [Batch 18/938] [D loss: 0.745132] [G loss: 0.317861]\n",
      "[Epoch 1/30] [Batch 19/938] [D loss: 0.602609] [G loss: 1.690167]\n",
      "[Epoch 1/30] [Batch 20/938] [D loss: 0.551142] [G loss: 0.579111]\n",
      "[Epoch 1/30] [Batch 21/938] [D loss: 0.539055] [G loss: 1.410754]\n",
      "[Epoch 1/30] [Batch 22/938] [D loss: 0.526588] [G loss: 0.681155]\n",
      "[Epoch 1/30] [Batch 23/938] [D loss: 0.548939] [G loss: 1.206746]\n",
      "[Epoch 1/30] [Batch 24/938] [D loss: 0.544518] [G loss: 0.631639]\n",
      "[Epoch 1/30] [Batch 25/938] [D loss: 0.461854] [G loss: 1.320645]\n",
      "[Epoch 1/30] [Batch 26/938] [D loss: 0.519493] [G loss: 0.896445]\n",
      "[Epoch 1/30] [Batch 27/938] [D loss: 0.530398] [G loss: 0.717112]\n",
      "[Epoch 1/30] [Batch 28/938] [D loss: 0.515211] [G loss: 1.322392]\n",
      "[Epoch 1/30] [Batch 29/938] [D loss: 0.575389] [G loss: 0.654287]\n",
      "[Epoch 1/30] [Batch 30/938] [D loss: 0.541176] [G loss: 1.039608]\n",
      "[Epoch 1/30] [Batch 31/938] [D loss: 0.565503] [G loss: 0.749825]\n",
      "[Epoch 1/30] [Batch 32/938] [D loss: 0.575776] [G loss: 0.896721]\n",
      "[Epoch 1/30] [Batch 33/938] [D loss: 0.505347] [G loss: 0.845438]\n",
      "[Epoch 1/30] [Batch 34/938] [D loss: 0.495471] [G loss: 1.113390]\n",
      "[Epoch 1/30] [Batch 35/938] [D loss: 0.488156] [G loss: 0.840080]\n",
      "[Epoch 1/30] [Batch 36/938] [D loss: 0.512036] [G loss: 1.131389]\n",
      "[Epoch 1/30] [Batch 37/938] [D loss: 0.536760] [G loss: 0.667711]\n",
      "[Epoch 1/30] [Batch 38/938] [D loss: 0.535249] [G loss: 1.368460]\n",
      "[Epoch 1/30] [Batch 39/938] [D loss: 0.538713] [G loss: 0.540533]\n",
      "[Epoch 1/30] [Batch 40/938] [D loss: 0.614251] [G loss: 1.831285]\n",
      "[Epoch 1/30] [Batch 41/938] [D loss: 0.637589] [G loss: 0.407494]\n",
      "[Epoch 1/30] [Batch 42/938] [D loss: 0.510701] [G loss: 1.699331]\n",
      "[Epoch 1/30] [Batch 43/938] [D loss: 0.459450] [G loss: 0.756776]\n",
      "[Epoch 1/30] [Batch 44/938] [D loss: 0.440999] [G loss: 1.103207]\n",
      "[Epoch 1/30] [Batch 45/938] [D loss: 0.413120] [G loss: 1.177041]\n",
      "[Epoch 1/30] [Batch 46/938] [D loss: 0.467044] [G loss: 0.890467]\n",
      "[Epoch 1/30] [Batch 47/938] [D loss: 0.511788] [G loss: 1.002371]\n",
      "[Epoch 1/30] [Batch 48/938] [D loss: 0.472768] [G loss: 0.807472]\n",
      "[Epoch 1/30] [Batch 49/938] [D loss: 0.511874] [G loss: 1.259405]\n",
      "[Epoch 1/30] [Batch 50/938] [D loss: 0.564794] [G loss: 0.653531]\n",
      "[Epoch 1/30] [Batch 51/938] [D loss: 0.485630] [G loss: 1.135691]\n",
      "[Epoch 1/30] [Batch 52/938] [D loss: 0.480183] [G loss: 0.897761]\n",
      "[Epoch 1/30] [Batch 53/938] [D loss: 0.501632] [G loss: 1.036557]\n",
      "[Epoch 1/30] [Batch 54/938] [D loss: 0.494842] [G loss: 0.793197]\n",
      "[Epoch 1/30] [Batch 55/938] [D loss: 0.462616] [G loss: 1.274492]\n",
      "[Epoch 1/30] [Batch 56/938] [D loss: 0.484108] [G loss: 0.790638]\n",
      "[Epoch 1/30] [Batch 57/938] [D loss: 0.439881] [G loss: 1.260852]\n",
      "[Epoch 1/30] [Batch 58/938] [D loss: 0.463446] [G loss: 0.879830]\n",
      "[Epoch 1/30] [Batch 59/938] [D loss: 0.411620] [G loss: 1.148941]\n",
      "[Epoch 1/30] [Batch 60/938] [D loss: 0.479855] [G loss: 1.051327]\n",
      "[Epoch 1/30] [Batch 61/938] [D loss: 0.454191] [G loss: 0.810593]\n",
      "[Epoch 1/30] [Batch 62/938] [D loss: 0.432159] [G loss: 1.305394]\n",
      "[Epoch 1/30] [Batch 63/938] [D loss: 0.444432] [G loss: 0.872987]\n",
      "[Epoch 1/30] [Batch 64/938] [D loss: 0.420684] [G loss: 1.128664]\n",
      "[Epoch 1/30] [Batch 65/938] [D loss: 0.430674] [G loss: 1.067906]\n",
      "[Epoch 1/30] [Batch 66/938] [D loss: 0.421089] [G loss: 0.990360]\n",
      "[Epoch 1/30] [Batch 67/938] [D loss: 0.431897] [G loss: 1.140192]\n",
      "[Epoch 1/30] [Batch 68/938] [D loss: 0.426642] [G loss: 0.859201]\n",
      "[Epoch 1/30] [Batch 69/938] [D loss: 0.458238] [G loss: 1.487289]\n",
      "[Epoch 1/30] [Batch 70/938] [D loss: 0.511894] [G loss: 0.557745]\n",
      "[Epoch 1/30] [Batch 71/938] [D loss: 0.442058] [G loss: 1.924871]\n",
      "[Epoch 1/30] [Batch 72/938] [D loss: 0.475229] [G loss: 0.713675]\n",
      "[Epoch 1/30] [Batch 73/938] [D loss: 0.397558] [G loss: 1.184486]\n",
      "[Epoch 1/30] [Batch 74/938] [D loss: 0.460842] [G loss: 1.169540]\n",
      "[Epoch 1/30] [Batch 75/938] [D loss: 0.501026] [G loss: 0.680219]\n",
      "[Epoch 1/30] [Batch 76/938] [D loss: 0.507334] [G loss: 1.576003]\n",
      "[Epoch 1/30] [Batch 77/938] [D loss: 0.579741] [G loss: 0.471704]\n",
      "[Epoch 1/30] [Batch 78/938] [D loss: 0.553042] [G loss: 1.927578]\n",
      "[Epoch 1/30] [Batch 79/938] [D loss: 0.548138] [G loss: 0.519342]\n",
      "[Epoch 1/30] [Batch 80/938] [D loss: 0.424906] [G loss: 1.579725]\n",
      "[Epoch 1/30] [Batch 81/938] [D loss: 0.420661] [G loss: 0.842477]\n",
      "[Epoch 1/30] [Batch 82/938] [D loss: 0.382265] [G loss: 1.256256]\n",
      "[Epoch 1/30] [Batch 83/938] [D loss: 0.436174] [G loss: 1.078980]\n",
      "[Epoch 1/30] [Batch 84/938] [D loss: 0.456129] [G loss: 0.791040]\n",
      "[Epoch 1/30] [Batch 85/938] [D loss: 0.491273] [G loss: 1.568680]\n",
      "[Epoch 1/30] [Batch 86/938] [D loss: 0.518162] [G loss: 0.560828]\n",
      "[Epoch 1/30] [Batch 87/938] [D loss: 0.559071] [G loss: 1.801416]\n",
      "[Epoch 1/30] [Batch 88/938] [D loss: 0.537246] [G loss: 0.541972]\n",
      "[Epoch 1/30] [Batch 89/938] [D loss: 0.480219] [G loss: 1.503970]\n",
      "[Epoch 1/30] [Batch 90/938] [D loss: 0.455899] [G loss: 0.852634]\n",
      "[Epoch 1/30] [Batch 91/938] [D loss: 0.425083] [G loss: 1.067598]\n",
      "[Epoch 1/30] [Batch 92/938] [D loss: 0.481638] [G loss: 1.177401]\n",
      "[Epoch 1/30] [Batch 93/938] [D loss: 0.503222] [G loss: 0.695423]\n",
      "[Epoch 1/30] [Batch 94/938] [D loss: 0.482697] [G loss: 1.471550]\n",
      "[Epoch 1/30] [Batch 95/938] [D loss: 0.534389] [G loss: 0.587675]\n",
      "[Epoch 1/30] [Batch 96/938] [D loss: 0.479935] [G loss: 1.607411]\n",
      "[Epoch 1/30] [Batch 97/938] [D loss: 0.506505] [G loss: 0.705780]\n",
      "[Epoch 1/30] [Batch 98/938] [D loss: 0.414690] [G loss: 1.124754]\n",
      "[Epoch 1/30] [Batch 99/938] [D loss: 0.468028] [G loss: 1.151652]\n",
      "[Epoch 1/30] [Batch 100/938] [D loss: 0.551920] [G loss: 0.631018]\n",
      "[Epoch 1/30] [Batch 101/938] [D loss: 0.580840] [G loss: 1.456581]\n",
      "[Epoch 1/30] [Batch 102/938] [D loss: 0.650196] [G loss: 0.413693]\n",
      "[Epoch 1/30] [Batch 103/938] [D loss: 0.526708] [G loss: 1.658767]\n",
      "[Epoch 1/30] [Batch 104/938] [D loss: 0.489612] [G loss: 0.683018]\n",
      "[Epoch 1/30] [Batch 105/938] [D loss: 0.437575] [G loss: 1.195864]\n",
      "[Epoch 1/30] [Batch 106/938] [D loss: 0.438922] [G loss: 0.991423]\n",
      "[Epoch 1/30] [Batch 107/938] [D loss: 0.408770] [G loss: 1.033242]\n",
      "[Epoch 1/30] [Batch 108/938] [D loss: 0.431086] [G loss: 1.154583]\n",
      "[Epoch 1/30] [Batch 109/938] [D loss: 0.422382] [G loss: 0.872716]\n",
      "[Epoch 1/30] [Batch 110/938] [D loss: 0.490029] [G loss: 1.364007]\n",
      "[Epoch 1/30] [Batch 111/938] [D loss: 0.536210] [G loss: 0.567765]\n",
      "[Epoch 1/30] [Batch 112/938] [D loss: 0.528501] [G loss: 1.705150]\n",
      "[Epoch 1/30] [Batch 113/938] [D loss: 0.480096] [G loss: 0.636211]\n",
      "[Epoch 1/30] [Batch 114/938] [D loss: 0.441696] [G loss: 1.498211]\n",
      "[Epoch 1/30] [Batch 115/938] [D loss: 0.506730] [G loss: 0.802747]\n",
      "[Epoch 1/30] [Batch 116/938] [D loss: 0.433903] [G loss: 0.936253]\n",
      "[Epoch 1/30] [Batch 117/938] [D loss: 0.451326] [G loss: 1.335633]\n",
      "[Epoch 1/30] [Batch 118/938] [D loss: 0.464264] [G loss: 0.740015]\n",
      "[Epoch 1/30] [Batch 119/938] [D loss: 0.384160] [G loss: 1.416981]\n",
      "[Epoch 1/30] [Batch 120/938] [D loss: 0.443998] [G loss: 0.948660]\n",
      "[Epoch 1/30] [Batch 121/938] [D loss: 0.433073] [G loss: 0.991144]\n",
      "[Epoch 1/30] [Batch 122/938] [D loss: 0.399984] [G loss: 1.188023]\n",
      "[Epoch 1/30] [Batch 123/938] [D loss: 0.416870] [G loss: 1.049700]\n",
      "[Epoch 1/30] [Batch 124/938] [D loss: 0.407378] [G loss: 1.026280]\n",
      "[Epoch 1/30] [Batch 125/938] [D loss: 0.471841] [G loss: 1.115066]\n",
      "[Epoch 1/30] [Batch 126/938] [D loss: 0.440362] [G loss: 0.834489]\n",
      "[Epoch 1/30] [Batch 127/938] [D loss: 0.431331] [G loss: 1.290663]\n",
      "[Epoch 1/30] [Batch 128/938] [D loss: 0.456424] [G loss: 0.799798]\n",
      "[Epoch 1/30] [Batch 129/938] [D loss: 0.421857] [G loss: 1.227213]\n",
      "[Epoch 1/30] [Batch 130/938] [D loss: 0.460787] [G loss: 0.999584]\n",
      "[Epoch 1/30] [Batch 131/938] [D loss: 0.465841] [G loss: 0.821006]\n",
      "[Epoch 1/30] [Batch 132/938] [D loss: 0.439881] [G loss: 1.282000]\n",
      "[Epoch 1/30] [Batch 133/938] [D loss: 0.458688] [G loss: 0.738573]\n",
      "[Epoch 1/30] [Batch 134/938] [D loss: 0.516934] [G loss: 1.433399]\n",
      "[Epoch 1/30] [Batch 135/938] [D loss: 0.538245] [G loss: 0.544141]\n",
      "[Epoch 1/30] [Batch 136/938] [D loss: 0.558860] [G loss: 1.651337]\n",
      "[Epoch 1/30] [Batch 137/938] [D loss: 0.559343] [G loss: 0.465527]\n",
      "[Epoch 1/30] [Batch 138/938] [D loss: 0.494506] [G loss: 1.859532]\n",
      "[Epoch 1/30] [Batch 139/938] [D loss: 0.437487] [G loss: 0.766475]\n",
      "[Epoch 1/30] [Batch 140/938] [D loss: 0.415858] [G loss: 1.042512]\n",
      "[Epoch 1/30] [Batch 141/938] [D loss: 0.409672] [G loss: 1.171391]\n",
      "[Epoch 1/30] [Batch 142/938] [D loss: 0.424813] [G loss: 0.830239]\n",
      "[Epoch 1/30] [Batch 143/938] [D loss: 0.406299] [G loss: 1.379413]\n",
      "[Epoch 1/30] [Batch 144/938] [D loss: 0.397460] [G loss: 0.894410]\n",
      "[Epoch 1/30] [Batch 145/938] [D loss: 0.426785] [G loss: 1.288379]\n",
      "[Epoch 1/30] [Batch 146/938] [D loss: 0.453660] [G loss: 0.807420]\n",
      "[Epoch 1/30] [Batch 147/938] [D loss: 0.422463] [G loss: 1.273305]\n",
      "[Epoch 1/30] [Batch 148/938] [D loss: 0.444953] [G loss: 0.930601]\n",
      "[Epoch 1/30] [Batch 149/938] [D loss: 0.406592] [G loss: 1.136934]\n",
      "[Epoch 1/30] [Batch 150/938] [D loss: 0.413216] [G loss: 1.017547]\n",
      "[Epoch 1/30] [Batch 151/938] [D loss: 0.392492] [G loss: 1.051625]\n",
      "[Epoch 1/30] [Batch 152/938] [D loss: 0.384428] [G loss: 1.225454]\n",
      "[Epoch 1/30] [Batch 153/938] [D loss: 0.362555] [G loss: 0.958813]\n",
      "[Epoch 1/30] [Batch 154/938] [D loss: 0.394016] [G loss: 1.523209]\n",
      "[Epoch 1/30] [Batch 155/938] [D loss: 0.413385] [G loss: 0.803203]\n",
      "[Epoch 1/30] [Batch 156/938] [D loss: 0.400315] [G loss: 1.542181]\n",
      "[Epoch 1/30] [Batch 157/938] [D loss: 0.445598] [G loss: 0.832494]\n",
      "[Epoch 1/30] [Batch 158/938] [D loss: 0.384808] [G loss: 1.154646]\n",
      "[Epoch 1/30] [Batch 159/938] [D loss: 0.414795] [G loss: 1.170217]\n",
      "[Epoch 1/30] [Batch 160/938] [D loss: 0.409806] [G loss: 0.920566]\n",
      "[Epoch 1/30] [Batch 161/938] [D loss: 0.409075] [G loss: 1.318346]\n",
      "[Epoch 1/30] [Batch 162/938] [D loss: 0.399695] [G loss: 0.863015]\n",
      "[Epoch 1/30] [Batch 163/938] [D loss: 0.414708] [G loss: 1.458552]\n",
      "[Epoch 1/30] [Batch 164/938] [D loss: 0.439210] [G loss: 0.806934]\n",
      "[Epoch 1/30] [Batch 165/938] [D loss: 0.456532] [G loss: 1.371239]\n",
      "[Epoch 1/30] [Batch 166/938] [D loss: 0.483538] [G loss: 0.694203]\n",
      "[Epoch 1/30] [Batch 167/938] [D loss: 0.467836] [G loss: 1.636072]\n",
      "[Epoch 1/30] [Batch 168/938] [D loss: 0.496493] [G loss: 0.584741]\n",
      "[Epoch 1/30] [Batch 169/938] [D loss: 0.522140] [G loss: 1.889710]\n",
      "[Epoch 1/30] [Batch 170/938] [D loss: 0.544338] [G loss: 0.505879]\n",
      "[Epoch 1/30] [Batch 171/938] [D loss: 0.457727] [G loss: 1.754586]\n",
      "[Epoch 1/30] [Batch 172/938] [D loss: 0.406661] [G loss: 0.845962]\n",
      "[Epoch 1/30] [Batch 173/938] [D loss: 0.418886] [G loss: 1.229893]\n",
      "[Epoch 1/30] [Batch 174/938] [D loss: 0.413982] [G loss: 1.048581]\n",
      "[Epoch 1/30] [Batch 175/938] [D loss: 0.414097] [G loss: 1.017263]\n",
      "[Epoch 1/30] [Batch 176/938] [D loss: 0.409932] [G loss: 1.189278]\n",
      "[Epoch 1/30] [Batch 177/938] [D loss: 0.416352] [G loss: 1.068407]\n",
      "[Epoch 1/30] [Batch 178/938] [D loss: 0.440081] [G loss: 0.926169]\n",
      "[Epoch 1/30] [Batch 179/938] [D loss: 0.419955] [G loss: 1.248727]\n",
      "[Epoch 1/30] [Batch 180/938] [D loss: 0.443084] [G loss: 0.941939]\n",
      "[Epoch 1/30] [Batch 181/938] [D loss: 0.406996] [G loss: 1.043219]\n",
      "[Epoch 1/30] [Batch 182/938] [D loss: 0.416651] [G loss: 1.134577]\n",
      "[Epoch 1/30] [Batch 183/938] [D loss: 0.433838] [G loss: 0.955411]\n",
      "[Epoch 1/30] [Batch 184/938] [D loss: 0.467910] [G loss: 1.228724]\n",
      "[Epoch 1/30] [Batch 185/938] [D loss: 0.474402] [G loss: 0.777427]\n",
      "[Epoch 1/30] [Batch 186/938] [D loss: 0.455810] [G loss: 1.405059]\n",
      "[Epoch 1/30] [Batch 187/938] [D loss: 0.516255] [G loss: 0.712153]\n",
      "[Epoch 1/30] [Batch 188/938] [D loss: 0.458263] [G loss: 1.394539]\n",
      "[Epoch 1/30] [Batch 189/938] [D loss: 0.496397] [G loss: 0.692122]\n",
      "[Epoch 1/30] [Batch 190/938] [D loss: 0.452470] [G loss: 1.461858]\n",
      "[Epoch 1/30] [Batch 191/938] [D loss: 0.506276] [G loss: 0.652264]\n",
      "[Epoch 1/30] [Batch 192/938] [D loss: 0.484888] [G loss: 1.670630]\n",
      "[Epoch 1/30] [Batch 193/938] [D loss: 0.548924] [G loss: 0.572823]\n",
      "[Epoch 1/30] [Batch 194/938] [D loss: 0.511215] [G loss: 1.660752]\n",
      "[Epoch 1/30] [Batch 195/938] [D loss: 0.583780] [G loss: 0.494856]\n",
      "[Epoch 1/30] [Batch 196/938] [D loss: 0.524250] [G loss: 1.846245]\n",
      "[Epoch 1/30] [Batch 197/938] [D loss: 0.585261] [G loss: 0.467969]\n",
      "[Epoch 1/30] [Batch 198/938] [D loss: 0.524084] [G loss: 1.892947]\n",
      "[Epoch 1/30] [Batch 199/938] [D loss: 0.489275] [G loss: 0.625055]\n",
      "[Epoch 1/30] [Batch 200/938] [D loss: 0.368879] [G loss: 1.495714]\n",
      "[Epoch 1/30] [Batch 201/938] [D loss: 0.428233] [G loss: 1.170429]\n",
      "[Epoch 1/30] [Batch 202/938] [D loss: 0.496568] [G loss: 0.677693]\n",
      "[Epoch 1/30] [Batch 203/938] [D loss: 0.488482] [G loss: 1.749295]\n",
      "[Epoch 1/30] [Batch 204/938] [D loss: 0.524073] [G loss: 0.575346]\n",
      "[Epoch 1/30] [Batch 205/938] [D loss: 0.490211] [G loss: 1.741420]\n",
      "[Epoch 1/30] [Batch 206/938] [D loss: 0.534315] [G loss: 0.591735]\n",
      "[Epoch 1/30] [Batch 207/938] [D loss: 0.464453] [G loss: 1.614930]\n",
      "[Epoch 1/30] [Batch 208/938] [D loss: 0.510240] [G loss: 0.710720]\n",
      "[Epoch 1/30] [Batch 209/938] [D loss: 0.504927] [G loss: 1.110863]\n",
      "[Epoch 1/30] [Batch 210/938] [D loss: 0.478715] [G loss: 0.784449]\n",
      "[Epoch 1/30] [Batch 211/938] [D loss: 0.484821] [G loss: 1.406860]\n",
      "[Epoch 1/30] [Batch 212/938] [D loss: 0.557775] [G loss: 0.550504]\n",
      "[Epoch 1/30] [Batch 213/938] [D loss: 0.590293] [G loss: 1.746639]\n",
      "[Epoch 1/30] [Batch 214/938] [D loss: 0.637819] [G loss: 0.418898]\n",
      "[Epoch 1/30] [Batch 215/938] [D loss: 0.588821] [G loss: 1.955313]\n",
      "[Epoch 1/30] [Batch 216/938] [D loss: 0.598128] [G loss: 0.493003]\n",
      "[Epoch 1/30] [Batch 217/938] [D loss: 0.564197] [G loss: 1.464171]\n",
      "[Epoch 1/30] [Batch 218/938] [D loss: 0.561480] [G loss: 0.588828]\n",
      "[Epoch 1/30] [Batch 219/938] [D loss: 0.502490] [G loss: 1.422779]\n",
      "[Epoch 1/30] [Batch 220/938] [D loss: 0.544638] [G loss: 0.684597]\n",
      "[Epoch 1/30] [Batch 221/938] [D loss: 0.512707] [G loss: 1.180375]\n",
      "[Epoch 1/30] [Batch 222/938] [D loss: 0.555553] [G loss: 0.753613]\n",
      "[Epoch 1/30] [Batch 223/938] [D loss: 0.517768] [G loss: 1.084752]\n",
      "[Epoch 1/30] [Batch 224/938] [D loss: 0.465833] [G loss: 0.869127]\n",
      "[Epoch 1/30] [Batch 225/938] [D loss: 0.579950] [G loss: 1.169893]\n",
      "[Epoch 1/30] [Batch 226/938] [D loss: 0.625575] [G loss: 0.526043]\n",
      "[Epoch 1/30] [Batch 227/938] [D loss: 0.602415] [G loss: 1.728176]\n",
      "[Epoch 1/30] [Batch 228/938] [D loss: 0.703952] [G loss: 0.386834]\n",
      "[Epoch 1/30] [Batch 229/938] [D loss: 0.615396] [G loss: 1.678870]\n",
      "[Epoch 1/30] [Batch 230/938] [D loss: 0.628940] [G loss: 0.467417]\n",
      "[Epoch 1/30] [Batch 231/938] [D loss: 0.541717] [G loss: 1.556406]\n",
      "[Epoch 1/30] [Batch 232/938] [D loss: 0.567371] [G loss: 0.624623]\n",
      "[Epoch 1/30] [Batch 233/938] [D loss: 0.484868] [G loss: 1.072157]\n",
      "[Epoch 1/30] [Batch 234/938] [D loss: 0.535094] [G loss: 1.005391]\n",
      "[Epoch 1/30] [Batch 235/938] [D loss: 0.499803] [G loss: 0.740477]\n",
      "[Epoch 1/30] [Batch 236/938] [D loss: 0.548374] [G loss: 1.371186]\n",
      "[Epoch 1/30] [Batch 237/938] [D loss: 0.578621] [G loss: 0.520716]\n",
      "[Epoch 1/30] [Batch 238/938] [D loss: 0.502153] [G loss: 1.643904]\n",
      "[Epoch 1/30] [Batch 239/938] [D loss: 0.556108] [G loss: 0.618435]\n",
      "[Epoch 1/30] [Batch 240/938] [D loss: 0.491080] [G loss: 1.246969]\n",
      "[Epoch 1/30] [Batch 241/938] [D loss: 0.486122] [G loss: 0.810485]\n",
      "[Epoch 1/30] [Batch 242/938] [D loss: 0.482598] [G loss: 1.174646]\n",
      "[Epoch 1/30] [Batch 243/938] [D loss: 0.537988] [G loss: 0.743137]\n",
      "[Epoch 1/30] [Batch 244/938] [D loss: 0.519069] [G loss: 1.216370]\n",
      "[Epoch 1/30] [Batch 245/938] [D loss: 0.532183] [G loss: 0.665996]\n",
      "[Epoch 1/30] [Batch 246/938] [D loss: 0.518357] [G loss: 1.403736]\n",
      "[Epoch 1/30] [Batch 247/938] [D loss: 0.533411] [G loss: 0.626582]\n",
      "[Epoch 1/30] [Batch 248/938] [D loss: 0.486400] [G loss: 1.567148]\n",
      "[Epoch 1/30] [Batch 249/938] [D loss: 0.530363] [G loss: 0.669473]\n",
      "[Epoch 1/30] [Batch 250/938] [D loss: 0.596039] [G loss: 1.425384]\n",
      "[Epoch 1/30] [Batch 251/938] [D loss: 0.649663] [G loss: 0.420997]\n",
      "[Epoch 1/30] [Batch 252/938] [D loss: 0.739065] [G loss: 1.928408]\n",
      "[Epoch 1/30] [Batch 253/938] [D loss: 0.734522] [G loss: 0.325818]\n",
      "[Epoch 1/30] [Batch 254/938] [D loss: 0.598158] [G loss: 1.753871]\n",
      "[Epoch 1/30] [Batch 255/938] [D loss: 0.560644] [G loss: 0.572681]\n",
      "[Epoch 1/30] [Batch 256/938] [D loss: 0.514380] [G loss: 1.530177]\n",
      "[Epoch 1/30] [Batch 257/938] [D loss: 0.526416] [G loss: 0.721842]\n",
      "[Epoch 1/30] [Batch 258/938] [D loss: 0.487884] [G loss: 1.108335]\n",
      "[Epoch 1/30] [Batch 259/938] [D loss: 0.493288] [G loss: 0.886782]\n",
      "[Epoch 1/30] [Batch 260/938] [D loss: 0.440514] [G loss: 1.047994]\n",
      "[Epoch 1/30] [Batch 261/938] [D loss: 0.468107] [G loss: 1.104053]\n",
      "[Epoch 1/30] [Batch 262/938] [D loss: 0.482352] [G loss: 0.840570]\n",
      "[Epoch 1/30] [Batch 263/938] [D loss: 0.439631] [G loss: 1.280359]\n",
      "[Epoch 1/30] [Batch 264/938] [D loss: 0.461915] [G loss: 0.808459]\n",
      "[Epoch 1/30] [Batch 265/938] [D loss: 0.461067] [G loss: 1.341638]\n",
      "[Epoch 1/30] [Batch 266/938] [D loss: 0.511383] [G loss: 0.721449]\n",
      "[Epoch 1/30] [Batch 267/938] [D loss: 0.494227] [G loss: 1.362312]\n",
      "[Epoch 1/30] [Batch 268/938] [D loss: 0.518943] [G loss: 0.678358]\n",
      "[Epoch 1/30] [Batch 269/938] [D loss: 0.531342] [G loss: 1.437626]\n",
      "[Epoch 1/30] [Batch 270/938] [D loss: 0.562062] [G loss: 0.588315]\n",
      "[Epoch 1/30] [Batch 271/938] [D loss: 0.469501] [G loss: 1.464022]\n",
      "[Epoch 1/30] [Batch 272/938] [D loss: 0.474939] [G loss: 0.810174]\n",
      "[Epoch 1/30] [Batch 273/938] [D loss: 0.430439] [G loss: 1.198028]\n",
      "[Epoch 1/30] [Batch 274/938] [D loss: 0.412503] [G loss: 0.921200]\n",
      "[Epoch 1/30] [Batch 275/938] [D loss: 0.481496] [G loss: 1.452050]\n",
      "[Epoch 1/30] [Batch 276/938] [D loss: 0.568026] [G loss: 0.555779]\n",
      "[Epoch 1/30] [Batch 277/938] [D loss: 0.499415] [G loss: 1.540616]\n",
      "[Epoch 1/30] [Batch 278/938] [D loss: 0.510262] [G loss: 0.760352]\n",
      "[Epoch 1/30] [Batch 279/938] [D loss: 0.402906] [G loss: 1.100944]\n",
      "[Epoch 1/30] [Batch 280/938] [D loss: 0.413863] [G loss: 1.328872]\n",
      "[Epoch 1/30] [Batch 281/938] [D loss: 0.472785] [G loss: 0.770952]\n",
      "[Epoch 1/30] [Batch 282/938] [D loss: 0.439030] [G loss: 1.262877]\n",
      "[Epoch 1/30] [Batch 283/938] [D loss: 0.472623] [G loss: 0.956158]\n",
      "[Epoch 1/30] [Batch 284/938] [D loss: 0.463150] [G loss: 1.031767]\n",
      "[Epoch 1/30] [Batch 285/938] [D loss: 0.455042] [G loss: 0.991050]\n",
      "[Epoch 1/30] [Batch 286/938] [D loss: 0.401945] [G loss: 1.129962]\n",
      "[Epoch 1/30] [Batch 287/938] [D loss: 0.498045] [G loss: 1.131811]\n",
      "[Epoch 1/30] [Batch 288/938] [D loss: 0.497956] [G loss: 0.672698]\n",
      "[Epoch 1/30] [Batch 289/938] [D loss: 0.501293] [G loss: 1.686181]\n",
      "[Epoch 1/30] [Batch 290/938] [D loss: 0.550748] [G loss: 0.545041]\n",
      "[Epoch 1/30] [Batch 291/938] [D loss: 0.488536] [G loss: 1.741288]\n",
      "[Epoch 1/30] [Batch 292/938] [D loss: 0.522072] [G loss: 0.628983]\n",
      "[Epoch 1/30] [Batch 293/938] [D loss: 0.432322] [G loss: 1.362591]\n",
      "[Epoch 1/30] [Batch 294/938] [D loss: 0.476388] [G loss: 0.894743]\n",
      "[Epoch 1/30] [Batch 295/938] [D loss: 0.438252] [G loss: 1.098741]\n",
      "[Epoch 1/30] [Batch 296/938] [D loss: 0.445221] [G loss: 0.974762]\n",
      "[Epoch 1/30] [Batch 297/938] [D loss: 0.448575] [G loss: 1.064311]\n",
      "[Epoch 1/30] [Batch 298/938] [D loss: 0.434371] [G loss: 0.961439]\n",
      "[Epoch 1/30] [Batch 299/938] [D loss: 0.465023] [G loss: 1.126597]\n",
      "[Epoch 1/30] [Batch 300/938] [D loss: 0.442643] [G loss: 0.823941]\n",
      "[Epoch 1/30] [Batch 301/938] [D loss: 0.450403] [G loss: 1.400200]\n",
      "[Epoch 1/30] [Batch 302/938] [D loss: 0.496060] [G loss: 0.741266]\n",
      "[Epoch 1/30] [Batch 303/938] [D loss: 0.473911] [G loss: 1.248974]\n",
      "[Epoch 1/30] [Batch 304/938] [D loss: 0.483203] [G loss: 0.865886]\n",
      "[Epoch 1/30] [Batch 305/938] [D loss: 0.469708] [G loss: 1.016162]\n",
      "[Epoch 1/30] [Batch 306/938] [D loss: 0.465849] [G loss: 1.030506]\n",
      "[Epoch 1/30] [Batch 307/938] [D loss: 0.498981] [G loss: 0.979781]\n",
      "[Epoch 1/30] [Batch 308/938] [D loss: 0.423933] [G loss: 0.903719]\n",
      "[Epoch 1/30] [Batch 309/938] [D loss: 0.531785] [G loss: 1.481085]\n",
      "[Epoch 1/30] [Batch 310/938] [D loss: 0.625892] [G loss: 0.444532]\n",
      "[Epoch 1/30] [Batch 311/938] [D loss: 0.610251] [G loss: 2.020323]\n",
      "[Epoch 1/30] [Batch 312/938] [D loss: 0.554228] [G loss: 0.543059]\n",
      "[Epoch 1/30] [Batch 313/938] [D loss: 0.391536] [G loss: 1.472242]\n",
      "[Epoch 1/30] [Batch 314/938] [D loss: 0.387520] [G loss: 1.245746]\n",
      "[Epoch 1/30] [Batch 315/938] [D loss: 0.424812] [G loss: 0.852941]\n",
      "[Epoch 1/30] [Batch 316/938] [D loss: 0.505019] [G loss: 1.368558]\n",
      "[Epoch 1/30] [Batch 317/938] [D loss: 0.483543] [G loss: 0.672301]\n",
      "[Epoch 1/30] [Batch 318/938] [D loss: 0.495856] [G loss: 1.608295]\n",
      "[Epoch 1/30] [Batch 319/938] [D loss: 0.543713] [G loss: 0.588568]\n",
      "[Epoch 1/30] [Batch 320/938] [D loss: 0.488815] [G loss: 1.553507]\n",
      "[Epoch 1/30] [Batch 321/938] [D loss: 0.503970] [G loss: 0.666216]\n",
      "[Epoch 1/30] [Batch 322/938] [D loss: 0.499061] [G loss: 1.420282]\n",
      "[Epoch 1/30] [Batch 323/938] [D loss: 0.509871] [G loss: 0.664179]\n",
      "[Epoch 1/30] [Batch 324/938] [D loss: 0.496425] [G loss: 1.413655]\n",
      "[Epoch 1/30] [Batch 325/938] [D loss: 0.512462] [G loss: 0.663702]\n",
      "[Epoch 1/30] [Batch 326/938] [D loss: 0.466819] [G loss: 1.448484]\n",
      "[Epoch 1/30] [Batch 327/938] [D loss: 0.485455] [G loss: 0.733965]\n",
      "[Epoch 1/30] [Batch 328/938] [D loss: 0.474731] [G loss: 1.428590]\n",
      "[Epoch 1/30] [Batch 329/938] [D loss: 0.512783] [G loss: 0.691096]\n",
      "[Epoch 1/30] [Batch 330/938] [D loss: 0.436995] [G loss: 1.380471]\n",
      "[Epoch 1/30] [Batch 331/938] [D loss: 0.424524] [G loss: 0.931028]\n",
      "[Epoch 1/30] [Batch 332/938] [D loss: 0.396476] [G loss: 1.160791]\n",
      "[Epoch 1/30] [Batch 333/938] [D loss: 0.443166] [G loss: 1.167611]\n",
      "[Epoch 1/30] [Batch 334/938] [D loss: 0.436079] [G loss: 0.829516]\n",
      "[Epoch 1/30] [Batch 335/938] [D loss: 0.422571] [G loss: 1.566214]\n",
      "[Epoch 1/30] [Batch 336/938] [D loss: 0.486028] [G loss: 0.763930]\n",
      "[Epoch 1/30] [Batch 337/938] [D loss: 0.473280] [G loss: 1.268256]\n",
      "[Epoch 1/30] [Batch 338/938] [D loss: 0.466148] [G loss: 0.829038]\n",
      "[Epoch 1/30] [Batch 339/938] [D loss: 0.428051] [G loss: 1.258315]\n",
      "[Epoch 1/30] [Batch 340/938] [D loss: 0.451053] [G loss: 0.982050]\n",
      "[Epoch 1/30] [Batch 341/938] [D loss: 0.471621] [G loss: 1.032592]\n",
      "[Epoch 1/30] [Batch 342/938] [D loss: 0.431845] [G loss: 0.929420]\n",
      "[Epoch 1/30] [Batch 343/938] [D loss: 0.418210] [G loss: 1.396299]\n",
      "[Epoch 1/30] [Batch 344/938] [D loss: 0.487931] [G loss: 0.790374]\n",
      "[Epoch 1/30] [Batch 345/938] [D loss: 0.420955] [G loss: 1.289838]\n",
      "[Epoch 1/30] [Batch 346/938] [D loss: 0.481734] [G loss: 0.924522]\n",
      "[Epoch 1/30] [Batch 347/938] [D loss: 0.444718] [G loss: 1.076226]\n",
      "[Epoch 1/30] [Batch 348/938] [D loss: 0.423734] [G loss: 1.087362]\n",
      "[Epoch 1/30] [Batch 349/938] [D loss: 0.454616] [G loss: 1.169010]\n",
      "[Epoch 1/30] [Batch 350/938] [D loss: 0.484586] [G loss: 0.834110]\n",
      "[Epoch 1/30] [Batch 351/938] [D loss: 0.466862] [G loss: 1.307163]\n",
      "[Epoch 1/30] [Batch 352/938] [D loss: 0.518787] [G loss: 0.658246]\n",
      "[Epoch 1/30] [Batch 353/938] [D loss: 0.529462] [G loss: 1.733628]\n",
      "[Epoch 1/30] [Batch 354/938] [D loss: 0.597943] [G loss: 0.490319]\n",
      "[Epoch 1/30] [Batch 355/938] [D loss: 0.610830] [G loss: 1.897563]\n",
      "[Epoch 1/30] [Batch 356/938] [D loss: 0.643058] [G loss: 0.430917]\n",
      "[Epoch 1/30] [Batch 357/938] [D loss: 0.546451] [G loss: 2.013399]\n",
      "[Epoch 1/30] [Batch 358/938] [D loss: 0.457770] [G loss: 0.743618]\n",
      "[Epoch 1/30] [Batch 359/938] [D loss: 0.359472] [G loss: 1.419007]\n",
      "[Epoch 1/30] [Batch 360/938] [D loss: 0.362293] [G loss: 1.223173]\n",
      "[Epoch 1/30] [Batch 361/938] [D loss: 0.373962] [G loss: 1.136852]\n",
      "[Epoch 1/30] [Batch 362/938] [D loss: 0.378936] [G loss: 1.210178]\n",
      "[Epoch 1/30] [Batch 363/938] [D loss: 0.438463] [G loss: 1.159665]\n",
      "[Epoch 1/30] [Batch 364/938] [D loss: 0.418423] [G loss: 0.950594]\n",
      "[Epoch 1/30] [Batch 365/938] [D loss: 0.408241] [G loss: 1.360459]\n",
      "[Epoch 1/30] [Batch 366/938] [D loss: 0.452619] [G loss: 0.925655]\n",
      "[Epoch 1/30] [Batch 367/938] [D loss: 0.413169] [G loss: 1.236456]\n",
      "[Epoch 1/30] [Batch 368/938] [D loss: 0.459993] [G loss: 0.969890]\n",
      "[Epoch 1/30] [Batch 369/938] [D loss: 0.399040] [G loss: 1.150577]\n",
      "[Epoch 1/30] [Batch 370/938] [D loss: 0.475399] [G loss: 1.073110]\n",
      "[Epoch 1/30] [Batch 371/938] [D loss: 0.417224] [G loss: 0.945702]\n",
      "[Epoch 1/30] [Batch 372/938] [D loss: 0.421256] [G loss: 1.428542]\n",
      "[Epoch 1/30] [Batch 373/938] [D loss: 0.473200] [G loss: 0.831575]\n",
      "[Epoch 1/30] [Batch 374/938] [D loss: 0.410628] [G loss: 1.182301]\n",
      "[Epoch 1/30] [Batch 375/938] [D loss: 0.444247] [G loss: 1.077733]\n",
      "[Epoch 1/30] [Batch 376/938] [D loss: 0.450556] [G loss: 0.963762]\n",
      "[Epoch 1/30] [Batch 377/938] [D loss: 0.462256] [G loss: 1.143449]\n",
      "[Epoch 1/30] [Batch 378/938] [D loss: 0.481482] [G loss: 0.847629]\n",
      "[Epoch 1/30] [Batch 379/938] [D loss: 0.464489] [G loss: 1.247574]\n",
      "[Epoch 1/30] [Batch 380/938] [D loss: 0.472201] [G loss: 0.700691]\n",
      "[Epoch 1/30] [Batch 381/938] [D loss: 0.465898] [G loss: 1.834216]\n",
      "[Epoch 1/30] [Batch 382/938] [D loss: 0.534450] [G loss: 0.564934]\n",
      "[Epoch 1/30] [Batch 383/938] [D loss: 0.533595] [G loss: 1.723365]\n",
      "[Epoch 1/30] [Batch 384/938] [D loss: 0.573968] [G loss: 0.503083]\n",
      "[Epoch 1/30] [Batch 385/938] [D loss: 0.526217] [G loss: 1.733423]\n",
      "[Epoch 1/30] [Batch 386/938] [D loss: 0.462950] [G loss: 0.696165]\n",
      "[Epoch 1/30] [Batch 387/938] [D loss: 0.450652] [G loss: 1.492641]\n",
      "[Epoch 1/30] [Batch 388/938] [D loss: 0.477564] [G loss: 0.690858]\n",
      "[Epoch 1/30] [Batch 389/938] [D loss: 0.472152] [G loss: 1.632549]\n",
      "[Epoch 1/30] [Batch 390/938] [D loss: 0.477790] [G loss: 0.730625]\n",
      "[Epoch 1/30] [Batch 391/938] [D loss: 0.452861] [G loss: 1.323761]\n",
      "[Epoch 1/30] [Batch 392/938] [D loss: 0.503998] [G loss: 0.772256]\n",
      "[Epoch 1/30] [Batch 393/938] [D loss: 0.463465] [G loss: 1.224374]\n",
      "[Epoch 1/30] [Batch 394/938] [D loss: 0.485823] [G loss: 0.800175]\n",
      "[Epoch 1/30] [Batch 395/938] [D loss: 0.467929] [G loss: 1.257157]\n",
      "[Epoch 1/30] [Batch 396/938] [D loss: 0.532348] [G loss: 0.749236]\n",
      "[Epoch 1/30] [Batch 397/938] [D loss: 0.510396] [G loss: 1.265181]\n",
      "[Epoch 1/30] [Batch 398/938] [D loss: 0.516905] [G loss: 0.652936]\n",
      "[Epoch 1/30] [Batch 399/938] [D loss: 0.656090] [G loss: 1.791099]\n",
      "[Epoch 1/30] [Batch 400/938] [D loss: 0.735548] [G loss: 0.340412]\n",
      "[Epoch 1/30] [Batch 401/938] [D loss: 0.542383] [G loss: 2.012777]\n",
      "[Epoch 1/30] [Batch 402/938] [D loss: 0.513436] [G loss: 0.677969]\n",
      "[Epoch 1/30] [Batch 403/938] [D loss: 0.463099] [G loss: 1.179009]\n",
      "[Epoch 1/30] [Batch 404/938] [D loss: 0.454792] [G loss: 0.946854]\n",
      "[Epoch 1/30] [Batch 405/938] [D loss: 0.438760] [G loss: 1.022366]\n",
      "[Epoch 1/30] [Batch 406/938] [D loss: 0.457351] [G loss: 1.075364]\n",
      "[Epoch 1/30] [Batch 407/938] [D loss: 0.448483] [G loss: 0.940857]\n",
      "[Epoch 1/30] [Batch 408/938] [D loss: 0.468079] [G loss: 1.064974]\n",
      "[Epoch 1/30] [Batch 409/938] [D loss: 0.509565] [G loss: 0.893642]\n",
      "[Epoch 1/30] [Batch 410/938] [D loss: 0.471279] [G loss: 0.948270]\n",
      "[Epoch 1/30] [Batch 411/938] [D loss: 0.446746] [G loss: 1.099781]\n",
      "[Epoch 1/30] [Batch 412/938] [D loss: 0.479537] [G loss: 0.931834]\n",
      "[Epoch 1/30] [Batch 413/938] [D loss: 0.495182] [G loss: 0.937652]\n",
      "[Epoch 1/30] [Batch 414/938] [D loss: 0.450426] [G loss: 1.067503]\n",
      "[Epoch 1/30] [Batch 415/938] [D loss: 0.482666] [G loss: 0.924925]\n",
      "[Epoch 1/30] [Batch 416/938] [D loss: 0.474161] [G loss: 1.017224]\n",
      "[Epoch 1/30] [Batch 417/938] [D loss: 0.489966] [G loss: 0.865474]\n",
      "[Epoch 1/30] [Batch 418/938] [D loss: 0.451876] [G loss: 1.154700]\n",
      "[Epoch 1/30] [Batch 419/938] [D loss: 0.462253] [G loss: 0.901060]\n",
      "[Epoch 1/30] [Batch 420/938] [D loss: 0.438035] [G loss: 1.057667]\n",
      "[Epoch 1/30] [Batch 421/938] [D loss: 0.490805] [G loss: 1.042899]\n",
      "[Epoch 1/30] [Batch 422/938] [D loss: 0.492184] [G loss: 0.732562]\n",
      "[Epoch 1/30] [Batch 423/938] [D loss: 0.553912] [G loss: 1.748597]\n",
      "[Epoch 1/30] [Batch 424/938] [D loss: 0.702634] [G loss: 0.352138]\n",
      "[Epoch 1/30] [Batch 425/938] [D loss: 0.593410] [G loss: 2.078488]\n",
      "[Epoch 1/30] [Batch 426/938] [D loss: 0.562336] [G loss: 0.549714]\n",
      "[Epoch 1/30] [Batch 427/938] [D loss: 0.461419] [G loss: 1.379670]\n",
      "[Epoch 1/30] [Batch 428/938] [D loss: 0.486373] [G loss: 0.851724]\n",
      "[Epoch 1/30] [Batch 429/938] [D loss: 0.440763] [G loss: 0.965537]\n",
      "[Epoch 1/30] [Batch 430/938] [D loss: 0.500077] [G loss: 1.197118]\n",
      "[Epoch 1/30] [Batch 431/938] [D loss: 0.545591] [G loss: 0.588732]\n",
      "[Epoch 1/30] [Batch 432/938] [D loss: 0.585461] [G loss: 1.741935]\n",
      "[Epoch 1/30] [Batch 433/938] [D loss: 0.667547] [G loss: 0.394681]\n",
      "[Epoch 1/30] [Batch 434/938] [D loss: 0.719312] [G loss: 1.829586]\n",
      "[Epoch 1/30] [Batch 435/938] [D loss: 0.692731] [G loss: 0.363114]\n",
      "[Epoch 1/30] [Batch 436/938] [D loss: 0.665191] [G loss: 1.743138]\n",
      "[Epoch 1/30] [Batch 437/938] [D loss: 0.593461] [G loss: 0.471698]\n",
      "[Epoch 1/30] [Batch 438/938] [D loss: 0.516035] [G loss: 1.554265]\n",
      "[Epoch 1/30] [Batch 439/938] [D loss: 0.436219] [G loss: 0.827397]\n",
      "[Epoch 1/30] [Batch 440/938] [D loss: 0.481650] [G loss: 1.055317]\n",
      "[Epoch 1/30] [Batch 441/938] [D loss: 0.466416] [G loss: 0.926652]\n",
      "[Epoch 1/30] [Batch 442/938] [D loss: 0.446169] [G loss: 1.062374]\n",
      "[Epoch 1/30] [Batch 443/938] [D loss: 0.437825] [G loss: 1.025172]\n",
      "[Epoch 1/30] [Batch 444/938] [D loss: 0.476527] [G loss: 1.031413]\n",
      "[Epoch 1/30] [Batch 445/938] [D loss: 0.476965] [G loss: 0.970790]\n",
      "[Epoch 1/30] [Batch 446/938] [D loss: 0.426504] [G loss: 0.996431]\n",
      "[Epoch 1/30] [Batch 447/938] [D loss: 0.464301] [G loss: 1.239268]\n",
      "[Epoch 1/30] [Batch 448/938] [D loss: 0.497084] [G loss: 0.699465]\n",
      "[Epoch 1/30] [Batch 449/938] [D loss: 0.495070] [G loss: 1.401998]\n",
      "[Epoch 1/30] [Batch 450/938] [D loss: 0.445846] [G loss: 0.735621]\n",
      "[Epoch 1/30] [Batch 451/938] [D loss: 0.473684] [G loss: 1.502910]\n",
      "[Epoch 1/30] [Batch 452/938] [D loss: 0.506822] [G loss: 0.764622]\n",
      "[Epoch 1/30] [Batch 453/938] [D loss: 0.422973] [G loss: 1.099429]\n",
      "[Epoch 1/30] [Batch 454/938] [D loss: 0.439288] [G loss: 1.070927]\n",
      "[Epoch 1/30] [Batch 455/938] [D loss: 0.468963] [G loss: 1.091128]\n",
      "[Epoch 1/30] [Batch 456/938] [D loss: 0.455953] [G loss: 0.793029]\n",
      "[Epoch 1/30] [Batch 457/938] [D loss: 0.453051] [G loss: 1.532830]\n",
      "[Epoch 1/30] [Batch 458/938] [D loss: 0.468947] [G loss: 0.729250]\n",
      "[Epoch 1/30] [Batch 459/938] [D loss: 0.457280] [G loss: 1.462878]\n",
      "[Epoch 1/30] [Batch 460/938] [D loss: 0.468761] [G loss: 0.782635]\n",
      "[Epoch 1/30] [Batch 461/938] [D loss: 0.442566] [G loss: 1.270316]\n",
      "[Epoch 1/30] [Batch 462/938] [D loss: 0.436562] [G loss: 0.929165]\n",
      "[Epoch 1/30] [Batch 463/938] [D loss: 0.469979] [G loss: 1.166692]\n",
      "[Epoch 1/30] [Batch 464/938] [D loss: 0.470459] [G loss: 0.809827]\n",
      "[Epoch 1/30] [Batch 465/938] [D loss: 0.445233] [G loss: 1.238881]\n",
      "[Epoch 1/30] [Batch 466/938] [D loss: 0.476578] [G loss: 0.824913]\n",
      "[Epoch 1/30] [Batch 467/938] [D loss: 0.429842] [G loss: 1.231775]\n",
      "[Epoch 1/30] [Batch 468/938] [D loss: 0.488317] [G loss: 0.942481]\n",
      "[Epoch 1/30] [Batch 469/938] [D loss: 0.496950] [G loss: 0.839336]\n",
      "[Epoch 1/30] [Batch 470/938] [D loss: 0.462877] [G loss: 1.102325]\n",
      "[Epoch 1/30] [Batch 471/938] [D loss: 0.458697] [G loss: 0.904239]\n",
      "[Epoch 1/30] [Batch 472/938] [D loss: 0.522912] [G loss: 1.091907]\n",
      "[Epoch 1/30] [Batch 473/938] [D loss: 0.513158] [G loss: 0.675589]\n",
      "[Epoch 1/30] [Batch 474/938] [D loss: 0.570526] [G loss: 1.636113]\n",
      "[Epoch 1/30] [Batch 475/938] [D loss: 0.737613] [G loss: 0.330627]\n",
      "[Epoch 1/30] [Batch 476/938] [D loss: 0.721736] [G loss: 2.142708]\n",
      "[Epoch 1/30] [Batch 477/938] [D loss: 0.698954] [G loss: 0.363059]\n",
      "[Epoch 1/30] [Batch 478/938] [D loss: 0.511830] [G loss: 1.727217]\n",
      "[Epoch 1/30] [Batch 479/938] [D loss: 0.486134] [G loss: 0.737285]\n",
      "[Epoch 1/30] [Batch 480/938] [D loss: 0.438467] [G loss: 1.254737]\n",
      "[Epoch 1/30] [Batch 481/938] [D loss: 0.459908] [G loss: 0.880043]\n",
      "[Epoch 1/30] [Batch 482/938] [D loss: 0.497494] [G loss: 1.188268]\n",
      "[Epoch 1/30] [Batch 483/938] [D loss: 0.516107] [G loss: 0.685218]\n",
      "[Epoch 1/30] [Batch 484/938] [D loss: 0.505101] [G loss: 1.431734]\n",
      "[Epoch 1/30] [Batch 485/938] [D loss: 0.518216] [G loss: 0.625218]\n",
      "[Epoch 1/30] [Batch 486/938] [D loss: 0.459090] [G loss: 1.491109]\n",
      "[Epoch 1/30] [Batch 487/938] [D loss: 0.519634] [G loss: 0.768993]\n",
      "[Epoch 1/30] [Batch 488/938] [D loss: 0.434489] [G loss: 1.081974]\n",
      "[Epoch 1/30] [Batch 489/938] [D loss: 0.490087] [G loss: 1.163035]\n",
      "[Epoch 1/30] [Batch 490/938] [D loss: 0.530399] [G loss: 0.657803]\n",
      "[Epoch 1/30] [Batch 491/938] [D loss: 0.559738] [G loss: 1.566937]\n",
      "[Epoch 1/30] [Batch 492/938] [D loss: 0.631387] [G loss: 0.433606]\n",
      "[Epoch 1/30] [Batch 493/938] [D loss: 0.677195] [G loss: 2.051204]\n",
      "[Epoch 1/30] [Batch 494/938] [D loss: 0.694530] [G loss: 0.351463]\n",
      "[Epoch 1/30] [Batch 495/938] [D loss: 0.483047] [G loss: 1.896776]\n",
      "[Epoch 1/30] [Batch 496/938] [D loss: 0.432668] [G loss: 0.827860]\n",
      "[Epoch 1/30] [Batch 497/938] [D loss: 0.416288] [G loss: 1.331276]\n",
      "[Epoch 1/30] [Batch 498/938] [D loss: 0.431758] [G loss: 0.877068]\n",
      "[Epoch 1/30] [Batch 499/938] [D loss: 0.432199] [G loss: 1.312132]\n",
      "[Epoch 1/30] [Batch 500/938] [D loss: 0.430970] [G loss: 0.939213]\n",
      "[Epoch 1/30] [Batch 501/938] [D loss: 0.473255] [G loss: 1.150888]\n",
      "[Epoch 1/30] [Batch 502/938] [D loss: 0.501630] [G loss: 0.807052]\n",
      "[Epoch 1/30] [Batch 503/938] [D loss: 0.460613] [G loss: 1.234303]\n",
      "[Epoch 1/30] [Batch 504/938] [D loss: 0.480544] [G loss: 0.829783]\n",
      "[Epoch 1/30] [Batch 505/938] [D loss: 0.445168] [G loss: 1.098804]\n",
      "[Epoch 1/30] [Batch 506/938] [D loss: 0.485563] [G loss: 1.100703]\n",
      "[Epoch 1/30] [Batch 507/938] [D loss: 0.501571] [G loss: 0.702357]\n",
      "[Epoch 1/30] [Batch 508/938] [D loss: 0.524307] [G loss: 1.681157]\n",
      "[Epoch 1/30] [Batch 509/938] [D loss: 0.607932] [G loss: 0.447656]\n",
      "[Epoch 1/30] [Batch 510/938] [D loss: 0.553806] [G loss: 2.085568]\n",
      "[Epoch 1/30] [Batch 511/938] [D loss: 0.524051] [G loss: 0.596432]\n",
      "[Epoch 1/30] [Batch 512/938] [D loss: 0.427101] [G loss: 1.478595]\n",
      "[Epoch 1/30] [Batch 513/938] [D loss: 0.423960] [G loss: 0.856856]\n",
      "[Epoch 1/30] [Batch 514/938] [D loss: 0.426909] [G loss: 1.456282]\n",
      "[Epoch 1/30] [Batch 515/938] [D loss: 0.437754] [G loss: 0.816683]\n",
      "[Epoch 1/30] [Batch 516/938] [D loss: 0.414516] [G loss: 1.471274]\n",
      "[Epoch 1/30] [Batch 517/938] [D loss: 0.437952] [G loss: 0.817046]\n",
      "[Epoch 1/30] [Batch 518/938] [D loss: 0.455987] [G loss: 1.540162]\n",
      "[Epoch 1/30] [Batch 519/938] [D loss: 0.490892] [G loss: 0.637340]\n",
      "[Epoch 1/30] [Batch 520/938] [D loss: 0.489201] [G loss: 1.883950]\n",
      "[Epoch 1/30] [Batch 521/938] [D loss: 0.467573] [G loss: 0.662353]\n",
      "[Epoch 1/30] [Batch 522/938] [D loss: 0.473429] [G loss: 1.712264]\n",
      "[Epoch 1/30] [Batch 523/938] [D loss: 0.483095] [G loss: 0.781224]\n",
      "[Epoch 1/30] [Batch 524/938] [D loss: 0.421115] [G loss: 1.223018]\n",
      "[Epoch 1/30] [Batch 525/938] [D loss: 0.424744] [G loss: 1.039922]\n",
      "[Epoch 1/30] [Batch 526/938] [D loss: 0.428496] [G loss: 1.124019]\n",
      "[Epoch 1/30] [Batch 527/938] [D loss: 0.410152] [G loss: 1.123183]\n",
      "[Epoch 1/30] [Batch 528/938] [D loss: 0.438155] [G loss: 1.007866]\n",
      "[Epoch 1/30] [Batch 529/938] [D loss: 0.464159] [G loss: 1.187554]\n",
      "[Epoch 1/30] [Batch 530/938] [D loss: 0.464224] [G loss: 0.832687]\n",
      "[Epoch 1/30] [Batch 531/938] [D loss: 0.481189] [G loss: 1.425745]\n",
      "[Epoch 1/30] [Batch 532/938] [D loss: 0.511323] [G loss: 0.635244]\n",
      "[Epoch 1/30] [Batch 533/938] [D loss: 0.592088] [G loss: 1.738015]\n",
      "[Epoch 1/30] [Batch 534/938] [D loss: 0.620244] [G loss: 0.476708]\n",
      "[Epoch 1/30] [Batch 535/938] [D loss: 0.477432] [G loss: 1.732352]\n",
      "[Epoch 1/30] [Batch 536/938] [D loss: 0.443880] [G loss: 0.914037]\n",
      "[Epoch 1/30] [Batch 537/938] [D loss: 0.498155] [G loss: 1.090954]\n",
      "[Epoch 1/30] [Batch 538/938] [D loss: 0.450263] [G loss: 0.892246]\n",
      "[Epoch 1/30] [Batch 539/938] [D loss: 0.487152] [G loss: 1.271008]\n",
      "[Epoch 1/30] [Batch 540/938] [D loss: 0.474402] [G loss: 0.845361]\n",
      "[Epoch 1/30] [Batch 541/938] [D loss: 0.424842] [G loss: 1.258007]\n",
      "[Epoch 1/30] [Batch 542/938] [D loss: 0.484751] [G loss: 0.986513]\n",
      "[Epoch 1/30] [Batch 543/938] [D loss: 0.426992] [G loss: 0.913626]\n",
      "[Epoch 1/30] [Batch 544/938] [D loss: 0.447884] [G loss: 1.447468]\n",
      "[Epoch 1/30] [Batch 545/938] [D loss: 0.459750] [G loss: 0.773288]\n",
      "[Epoch 1/30] [Batch 546/938] [D loss: 0.386358] [G loss: 1.392287]\n",
      "[Epoch 1/30] [Batch 547/938] [D loss: 0.403133] [G loss: 1.070541]\n",
      "[Epoch 1/30] [Batch 548/938] [D loss: 0.426792] [G loss: 1.071088]\n",
      "[Epoch 1/30] [Batch 549/938] [D loss: 0.383513] [G loss: 1.058183]\n",
      "[Epoch 1/30] [Batch 550/938] [D loss: 0.386452] [G loss: 1.311343]\n",
      "[Epoch 1/30] [Batch 551/938] [D loss: 0.410057] [G loss: 0.944931]\n",
      "[Epoch 1/30] [Batch 552/938] [D loss: 0.412872] [G loss: 1.176763]\n",
      "[Epoch 1/30] [Batch 553/938] [D loss: 0.416246] [G loss: 1.017189]\n",
      "[Epoch 1/30] [Batch 554/938] [D loss: 0.395348] [G loss: 1.091575]\n",
      "[Epoch 1/30] [Batch 555/938] [D loss: 0.406714] [G loss: 1.186975]\n",
      "[Epoch 1/30] [Batch 556/938] [D loss: 0.392605] [G loss: 0.933854]\n",
      "[Epoch 1/30] [Batch 557/938] [D loss: 0.418562] [G loss: 1.442340]\n",
      "[Epoch 1/30] [Batch 558/938] [D loss: 0.399057] [G loss: 0.854215]\n",
      "[Epoch 1/30] [Batch 559/938] [D loss: 0.365999] [G loss: 1.456783]\n",
      "[Epoch 1/30] [Batch 560/938] [D loss: 0.382913] [G loss: 1.124035]\n",
      "[Epoch 1/30] [Batch 561/938] [D loss: 0.397213] [G loss: 0.981159]\n",
      "[Epoch 1/30] [Batch 562/938] [D loss: 0.452302] [G loss: 1.416357]\n",
      "[Epoch 1/30] [Batch 563/938] [D loss: 0.465189] [G loss: 0.674195]\n",
      "[Epoch 1/30] [Batch 564/938] [D loss: 0.432561] [G loss: 1.853375]\n",
      "[Epoch 1/30] [Batch 565/938] [D loss: 0.418420] [G loss: 0.733112]\n",
      "[Epoch 1/30] [Batch 566/938] [D loss: 0.407723] [G loss: 1.669155]\n",
      "[Epoch 1/30] [Batch 567/938] [D loss: 0.398435] [G loss: 0.929522]\n",
      "[Epoch 1/30] [Batch 568/938] [D loss: 0.373106] [G loss: 1.150709]\n",
      "[Epoch 1/30] [Batch 569/938] [D loss: 0.382892] [G loss: 1.234378]\n",
      "[Epoch 1/30] [Batch 570/938] [D loss: 0.332041] [G loss: 1.077983]\n",
      "[Epoch 1/30] [Batch 571/938] [D loss: 0.358960] [G loss: 1.455257]\n",
      "[Epoch 1/30] [Batch 572/938] [D loss: 0.358548] [G loss: 0.944667]\n",
      "[Epoch 1/30] [Batch 573/938] [D loss: 0.361664] [G loss: 1.439088]\n",
      "[Epoch 1/30] [Batch 574/938] [D loss: 0.364045] [G loss: 1.037317]\n",
      "[Epoch 1/30] [Batch 575/938] [D loss: 0.392810] [G loss: 1.229346]\n",
      "[Epoch 1/30] [Batch 576/938] [D loss: 0.415523] [G loss: 1.026879]\n",
      "[Epoch 1/30] [Batch 577/938] [D loss: 0.408954] [G loss: 1.059231]\n",
      "[Epoch 1/30] [Batch 578/938] [D loss: 0.400747] [G loss: 1.073373]\n",
      "[Epoch 1/30] [Batch 579/938] [D loss: 0.423357] [G loss: 1.107078]\n",
      "[Epoch 1/30] [Batch 580/938] [D loss: 0.429618] [G loss: 0.861797]\n",
      "[Epoch 1/30] [Batch 581/938] [D loss: 0.400065] [G loss: 1.460038]\n",
      "[Epoch 1/30] [Batch 582/938] [D loss: 0.456542] [G loss: 0.750058]\n",
      "[Epoch 1/30] [Batch 583/938] [D loss: 0.460573] [G loss: 1.591419]\n",
      "[Epoch 1/30] [Batch 584/938] [D loss: 0.528011] [G loss: 0.575644]\n",
      "[Epoch 1/30] [Batch 585/938] [D loss: 0.514874] [G loss: 2.001551]\n",
      "[Epoch 1/30] [Batch 586/938] [D loss: 0.562695] [G loss: 0.500970]\n",
      "[Epoch 1/30] [Batch 587/938] [D loss: 0.568783] [G loss: 1.993077]\n",
      "[Epoch 1/30] [Batch 588/938] [D loss: 0.578178] [G loss: 0.531760]\n",
      "[Epoch 1/30] [Batch 589/938] [D loss: 0.420541] [G loss: 1.720388]\n",
      "[Epoch 1/30] [Batch 590/938] [D loss: 0.389553] [G loss: 0.862290]\n",
      "[Epoch 1/30] [Batch 591/938] [D loss: 0.369408] [G loss: 1.383809]\n",
      "[Epoch 1/30] [Batch 592/938] [D loss: 0.359942] [G loss: 0.995825]\n",
      "[Epoch 1/30] [Batch 593/938] [D loss: 0.411694] [G loss: 1.406728]\n",
      "[Epoch 1/30] [Batch 594/938] [D loss: 0.455472] [G loss: 0.707261]\n",
      "[Epoch 1/30] [Batch 595/938] [D loss: 0.545915] [G loss: 2.031278]\n",
      "[Epoch 1/30] [Batch 596/938] [D loss: 0.586151] [G loss: 0.464805]\n",
      "[Epoch 1/30] [Batch 597/938] [D loss: 0.465936] [G loss: 1.953720]\n",
      "[Epoch 1/30] [Batch 598/938] [D loss: 0.426018] [G loss: 0.830731]\n",
      "[Epoch 1/30] [Batch 599/938] [D loss: 0.382538] [G loss: 1.151917]\n",
      "[Epoch 1/30] [Batch 600/938] [D loss: 0.438752] [G loss: 1.344150]\n",
      "[Epoch 1/30] [Batch 601/938] [D loss: 0.520465] [G loss: 0.607911]\n",
      "[Epoch 1/30] [Batch 602/938] [D loss: 0.510613] [G loss: 1.892354]\n",
      "[Epoch 1/30] [Batch 603/938] [D loss: 0.540122] [G loss: 0.531047]\n",
      "[Epoch 1/30] [Batch 604/938] [D loss: 0.549124] [G loss: 1.926528]\n",
      "[Epoch 1/30] [Batch 605/938] [D loss: 0.530572] [G loss: 0.551130]\n",
      "[Epoch 1/30] [Batch 606/938] [D loss: 0.571361] [G loss: 1.661108]\n",
      "[Epoch 1/30] [Batch 607/938] [D loss: 0.600995] [G loss: 0.445809]\n",
      "[Epoch 1/30] [Batch 608/938] [D loss: 0.579446] [G loss: 1.932794]\n",
      "[Epoch 1/30] [Batch 609/938] [D loss: 0.501689] [G loss: 0.607384]\n",
      "[Epoch 1/30] [Batch 610/938] [D loss: 0.406012] [G loss: 1.466158]\n",
      "[Epoch 1/30] [Batch 611/938] [D loss: 0.383849] [G loss: 1.014502]\n",
      "[Epoch 1/30] [Batch 612/938] [D loss: 0.447342] [G loss: 1.138559]\n",
      "[Epoch 1/30] [Batch 613/938] [D loss: 0.404657] [G loss: 0.931624]\n",
      "[Epoch 1/30] [Batch 614/938] [D loss: 0.471347] [G loss: 1.452872]\n",
      "[Epoch 1/30] [Batch 615/938] [D loss: 0.496943] [G loss: 0.616486]\n",
      "[Epoch 1/30] [Batch 616/938] [D loss: 0.501206] [G loss: 1.666414]\n",
      "[Epoch 1/30] [Batch 617/938] [D loss: 0.491738] [G loss: 0.674124]\n",
      "[Epoch 1/30] [Batch 618/938] [D loss: 0.387954] [G loss: 1.440869]\n",
      "[Epoch 1/30] [Batch 619/938] [D loss: 0.446072] [G loss: 1.075486]\n",
      "[Epoch 1/30] [Batch 620/938] [D loss: 0.417721] [G loss: 0.855260]\n",
      "[Epoch 1/30] [Batch 621/938] [D loss: 0.445306] [G loss: 1.643518]\n",
      "[Epoch 1/30] [Batch 622/938] [D loss: 0.549209] [G loss: 0.674052]\n",
      "[Epoch 1/30] [Batch 623/938] [D loss: 0.432903] [G loss: 1.204662]\n",
      "[Epoch 1/30] [Batch 624/938] [D loss: 0.450661] [G loss: 1.101767]\n",
      "[Epoch 1/30] [Batch 625/938] [D loss: 0.485750] [G loss: 0.848412]\n",
      "[Epoch 1/30] [Batch 626/938] [D loss: 0.483082] [G loss: 1.334473]\n",
      "[Epoch 1/30] [Batch 627/938] [D loss: 0.465086] [G loss: 0.730206]\n",
      "[Epoch 1/30] [Batch 628/938] [D loss: 0.547623] [G loss: 1.726772]\n",
      "[Epoch 1/30] [Batch 629/938] [D loss: 0.609818] [G loss: 0.456055]\n",
      "[Epoch 1/30] [Batch 630/938] [D loss: 0.537300] [G loss: 2.218721]\n",
      "[Epoch 1/30] [Batch 631/938] [D loss: 0.588198] [G loss: 0.509018]\n",
      "[Epoch 1/30] [Batch 632/938] [D loss: 0.430384] [G loss: 1.752632]\n",
      "[Epoch 1/30] [Batch 633/938] [D loss: 0.460288] [G loss: 0.873677]\n",
      "[Epoch 1/30] [Batch 634/938] [D loss: 0.428419] [G loss: 1.173466]\n",
      "[Epoch 1/30] [Batch 635/938] [D loss: 0.402815] [G loss: 1.099427]\n",
      "[Epoch 1/30] [Batch 636/938] [D loss: 0.488289] [G loss: 1.313112]\n",
      "[Epoch 1/30] [Batch 637/938] [D loss: 0.505229] [G loss: 0.674283]\n",
      "[Epoch 1/30] [Batch 638/938] [D loss: 0.472352] [G loss: 1.820218]\n",
      "[Epoch 1/30] [Batch 639/938] [D loss: 0.532192] [G loss: 0.591467]\n",
      "[Epoch 1/30] [Batch 640/938] [D loss: 0.519949] [G loss: 1.739130]\n",
      "[Epoch 1/30] [Batch 641/938] [D loss: 0.548690] [G loss: 0.556437]\n",
      "[Epoch 1/30] [Batch 642/938] [D loss: 0.511378] [G loss: 1.861172]\n",
      "[Epoch 1/30] [Batch 643/938] [D loss: 0.522106] [G loss: 0.663939]\n",
      "[Epoch 1/30] [Batch 644/938] [D loss: 0.443271] [G loss: 1.418787]\n",
      "[Epoch 1/30] [Batch 645/938] [D loss: 0.423809] [G loss: 0.987721]\n",
      "[Epoch 1/30] [Batch 646/938] [D loss: 0.416332] [G loss: 1.078622]\n",
      "[Epoch 1/30] [Batch 647/938] [D loss: 0.426839] [G loss: 1.283245]\n",
      "[Epoch 1/30] [Batch 648/938] [D loss: 0.435101] [G loss: 0.927086]\n",
      "[Epoch 1/30] [Batch 649/938] [D loss: 0.437472] [G loss: 1.315667]\n",
      "[Epoch 1/30] [Batch 650/938] [D loss: 0.477200] [G loss: 0.810046]\n",
      "[Epoch 1/30] [Batch 651/938] [D loss: 0.407325] [G loss: 1.400033]\n",
      "[Epoch 1/30] [Batch 652/938] [D loss: 0.431569] [G loss: 0.938162]\n",
      "[Epoch 1/30] [Batch 653/938] [D loss: 0.429549] [G loss: 1.256717]\n",
      "[Epoch 1/30] [Batch 654/938] [D loss: 0.436735] [G loss: 0.954709]\n",
      "[Epoch 1/30] [Batch 655/938] [D loss: 0.428963] [G loss: 1.273662]\n",
      "[Epoch 1/30] [Batch 656/938] [D loss: 0.456216] [G loss: 0.869601]\n",
      "[Epoch 1/30] [Batch 657/938] [D loss: 0.435529] [G loss: 1.394456]\n",
      "[Epoch 1/30] [Batch 658/938] [D loss: 0.407856] [G loss: 0.850139]\n",
      "[Epoch 1/30] [Batch 659/938] [D loss: 0.428764] [G loss: 1.713815]\n",
      "[Epoch 1/30] [Batch 660/938] [D loss: 0.506717] [G loss: 0.642571]\n",
      "[Epoch 1/30] [Batch 661/938] [D loss: 0.410672] [G loss: 1.835663]\n",
      "[Epoch 1/30] [Batch 662/938] [D loss: 0.422525] [G loss: 0.802558]\n",
      "[Epoch 1/30] [Batch 663/938] [D loss: 0.404687] [G loss: 1.647772]\n",
      "[Epoch 1/30] [Batch 664/938] [D loss: 0.407629] [G loss: 0.801453]\n",
      "[Epoch 1/30] [Batch 665/938] [D loss: 0.413829] [G loss: 1.888980]\n",
      "[Epoch 1/30] [Batch 666/938] [D loss: 0.472497] [G loss: 0.675824]\n",
      "[Epoch 1/30] [Batch 667/938] [D loss: 0.482279] [G loss: 1.824984]\n",
      "[Epoch 1/30] [Batch 668/938] [D loss: 0.478725] [G loss: 0.621766]\n",
      "[Epoch 1/30] [Batch 669/938] [D loss: 0.403575] [G loss: 2.050354]\n",
      "[Epoch 1/30] [Batch 670/938] [D loss: 0.430526] [G loss: 0.982818]\n",
      "[Epoch 1/30] [Batch 671/938] [D loss: 0.425615] [G loss: 0.875978]\n",
      "[Epoch 1/30] [Batch 672/938] [D loss: 0.493119] [G loss: 1.855448]\n",
      "[Epoch 1/30] [Batch 673/938] [D loss: 0.576977] [G loss: 0.528168]\n",
      "[Epoch 1/30] [Batch 674/938] [D loss: 0.562108] [G loss: 2.005441]\n",
      "[Epoch 1/30] [Batch 675/938] [D loss: 0.577320] [G loss: 0.488316]\n",
      "[Epoch 1/30] [Batch 676/938] [D loss: 0.607336] [G loss: 2.155056]\n",
      "[Epoch 1/30] [Batch 677/938] [D loss: 0.605136] [G loss: 0.445238]\n",
      "[Epoch 1/30] [Batch 678/938] [D loss: 0.508068] [G loss: 2.075842]\n",
      "[Epoch 1/30] [Batch 679/938] [D loss: 0.438732] [G loss: 0.800788]\n",
      "[Epoch 1/30] [Batch 680/938] [D loss: 0.409913] [G loss: 1.312706]\n",
      "[Epoch 1/30] [Batch 681/938] [D loss: 0.416654] [G loss: 1.156296]\n",
      "[Epoch 1/30] [Batch 682/938] [D loss: 0.398133] [G loss: 1.019718]\n",
      "[Epoch 1/30] [Batch 683/938] [D loss: 0.473805] [G loss: 1.425687]\n",
      "[Epoch 1/30] [Batch 684/938] [D loss: 0.505204] [G loss: 0.636491]\n",
      "[Epoch 1/30] [Batch 685/938] [D loss: 0.545016] [G loss: 1.943873]\n",
      "[Epoch 1/30] [Batch 686/938] [D loss: 0.593252] [G loss: 0.482816]\n",
      "[Epoch 1/30] [Batch 687/938] [D loss: 0.442063] [G loss: 1.818631]\n",
      "[Epoch 1/30] [Batch 688/938] [D loss: 0.486377] [G loss: 0.842004]\n",
      "[Epoch 1/30] [Batch 689/938] [D loss: 0.413623] [G loss: 0.946981]\n",
      "[Epoch 1/30] [Batch 690/938] [D loss: 0.523532] [G loss: 1.537060]\n",
      "[Epoch 1/30] [Batch 691/938] [D loss: 0.534457] [G loss: 0.519911]\n",
      "[Epoch 1/30] [Batch 692/938] [D loss: 0.611274] [G loss: 2.056318]\n",
      "[Epoch 1/30] [Batch 693/938] [D loss: 0.550655] [G loss: 0.506638]\n",
      "[Epoch 1/30] [Batch 694/938] [D loss: 0.481181] [G loss: 1.644014]\n",
      "[Epoch 1/30] [Batch 695/938] [D loss: 0.409872] [G loss: 0.799877]\n",
      "[Epoch 1/30] [Batch 696/938] [D loss: 0.460156] [G loss: 1.502262]\n",
      "[Epoch 1/30] [Batch 697/938] [D loss: 0.502965] [G loss: 0.649383]\n",
      "[Epoch 1/30] [Batch 698/938] [D loss: 0.435693] [G loss: 1.663681]\n",
      "[Epoch 1/30] [Batch 699/938] [D loss: 0.430763] [G loss: 0.949646]\n",
      "[Epoch 1/30] [Batch 700/938] [D loss: 0.437121] [G loss: 0.970486]\n",
      "[Epoch 1/30] [Batch 701/938] [D loss: 0.398713] [G loss: 1.298156]\n",
      "[Epoch 1/30] [Batch 702/938] [D loss: 0.413192] [G loss: 1.014694]\n",
      "[Epoch 1/30] [Batch 703/938] [D loss: 0.436794] [G loss: 1.207336]\n",
      "[Epoch 1/30] [Batch 704/938] [D loss: 0.417674] [G loss: 0.949703]\n",
      "[Epoch 1/30] [Batch 705/938] [D loss: 0.449659] [G loss: 1.373200]\n",
      "[Epoch 1/30] [Batch 706/938] [D loss: 0.425349] [G loss: 0.812028]\n",
      "[Epoch 1/30] [Batch 707/938] [D loss: 0.475452] [G loss: 1.668440]\n",
      "[Epoch 1/30] [Batch 708/938] [D loss: 0.534469] [G loss: 0.557510]\n",
      "[Epoch 1/30] [Batch 709/938] [D loss: 0.556541] [G loss: 2.007159]\n",
      "[Epoch 1/30] [Batch 710/938] [D loss: 0.552917] [G loss: 0.536749]\n",
      "[Epoch 1/30] [Batch 711/938] [D loss: 0.487635] [G loss: 1.833802]\n",
      "[Epoch 1/30] [Batch 712/938] [D loss: 0.482938] [G loss: 0.687661]\n",
      "[Epoch 1/30] [Batch 713/938] [D loss: 0.448439] [G loss: 1.446372]\n",
      "[Epoch 1/30] [Batch 714/938] [D loss: 0.423214] [G loss: 0.963045]\n",
      "[Epoch 1/30] [Batch 715/938] [D loss: 0.400150] [G loss: 1.245117]\n",
      "[Epoch 1/30] [Batch 716/938] [D loss: 0.396028] [G loss: 1.117323]\n",
      "[Epoch 1/30] [Batch 717/938] [D loss: 0.387841] [G loss: 1.157096]\n",
      "[Epoch 1/30] [Batch 718/938] [D loss: 0.364172] [G loss: 1.280410]\n",
      "[Epoch 1/30] [Batch 719/938] [D loss: 0.406761] [G loss: 1.125853]\n",
      "[Epoch 1/30] [Batch 720/938] [D loss: 0.417004] [G loss: 1.114248]\n",
      "[Epoch 1/30] [Batch 721/938] [D loss: 0.420537] [G loss: 1.094611]\n",
      "[Epoch 1/30] [Batch 722/938] [D loss: 0.460169] [G loss: 1.129920]\n",
      "[Epoch 1/30] [Batch 723/938] [D loss: 0.423611] [G loss: 0.923260]\n",
      "[Epoch 1/30] [Batch 724/938] [D loss: 0.435498] [G loss: 1.393442]\n",
      "[Epoch 1/30] [Batch 725/938] [D loss: 0.456805] [G loss: 0.762636]\n",
      "[Epoch 1/30] [Batch 726/938] [D loss: 0.475201] [G loss: 1.672099]\n",
      "[Epoch 1/30] [Batch 727/938] [D loss: 0.502759] [G loss: 0.616680]\n",
      "[Epoch 1/30] [Batch 728/938] [D loss: 0.504896] [G loss: 1.802918]\n",
      "[Epoch 1/30] [Batch 729/938] [D loss: 0.536555] [G loss: 0.597041]\n",
      "[Epoch 1/30] [Batch 730/938] [D loss: 0.543798] [G loss: 1.785169]\n",
      "[Epoch 1/30] [Batch 731/938] [D loss: 0.586025] [G loss: 0.482067]\n",
      "[Epoch 1/30] [Batch 732/938] [D loss: 0.550083] [G loss: 1.930036]\n",
      "[Epoch 1/30] [Batch 733/938] [D loss: 0.542559] [G loss: 0.624725]\n",
      "[Epoch 1/30] [Batch 734/938] [D loss: 0.510035] [G loss: 1.361752]\n",
      "[Epoch 1/30] [Batch 735/938] [D loss: 0.463144] [G loss: 0.733773]\n",
      "[Epoch 1/30] [Batch 736/938] [D loss: 0.511945] [G loss: 1.699112]\n",
      "[Epoch 1/30] [Batch 737/938] [D loss: 0.548525] [G loss: 0.593751]\n",
      "[Epoch 1/30] [Batch 738/938] [D loss: 0.518129] [G loss: 1.561233]\n",
      "[Epoch 1/30] [Batch 739/938] [D loss: 0.508291] [G loss: 0.689450]\n",
      "[Epoch 1/30] [Batch 740/938] [D loss: 0.393979] [G loss: 1.298546]\n",
      "[Epoch 1/30] [Batch 741/938] [D loss: 0.386145] [G loss: 1.234413]\n",
      "[Epoch 1/30] [Batch 742/938] [D loss: 0.450390] [G loss: 0.935735]\n",
      "[Epoch 1/30] [Batch 743/938] [D loss: 0.447675] [G loss: 1.132054]\n",
      "[Epoch 1/30] [Batch 744/938] [D loss: 0.488113] [G loss: 0.988318]\n",
      "[Epoch 1/30] [Batch 745/938] [D loss: 0.482932] [G loss: 0.967748]\n",
      "[Epoch 1/30] [Batch 746/938] [D loss: 0.427597] [G loss: 1.244345]\n",
      "[Epoch 1/30] [Batch 747/938] [D loss: 0.423058] [G loss: 1.015670]\n",
      "[Epoch 1/30] [Batch 748/938] [D loss: 0.407043] [G loss: 1.278857]\n",
      "[Epoch 1/30] [Batch 749/938] [D loss: 0.441166] [G loss: 0.988824]\n",
      "[Epoch 1/30] [Batch 750/938] [D loss: 0.437252] [G loss: 1.226773]\n",
      "[Epoch 1/30] [Batch 751/938] [D loss: 0.413590] [G loss: 0.938923]\n",
      "[Epoch 1/30] [Batch 752/938] [D loss: 0.499854] [G loss: 1.495179]\n",
      "[Epoch 1/30] [Batch 753/938] [D loss: 0.597083] [G loss: 0.465180]\n",
      "[Epoch 1/30] [Batch 754/938] [D loss: 0.605278] [G loss: 2.368608]\n",
      "[Epoch 1/30] [Batch 755/938] [D loss: 0.604130] [G loss: 0.436875]\n",
      "[Epoch 1/30] [Batch 756/938] [D loss: 0.504582] [G loss: 1.983959]\n",
      "[Epoch 1/30] [Batch 757/938] [D loss: 0.422275] [G loss: 0.857631]\n",
      "[Epoch 1/30] [Batch 758/938] [D loss: 0.420898] [G loss: 1.303491]\n",
      "[Epoch 1/30] [Batch 759/938] [D loss: 0.435913] [G loss: 0.854786]\n",
      "[Epoch 1/30] [Batch 760/938] [D loss: 0.425198] [G loss: 1.519822]\n",
      "[Epoch 1/30] [Batch 761/938] [D loss: 0.450341] [G loss: 0.822847]\n",
      "[Epoch 1/30] [Batch 762/938] [D loss: 0.471623] [G loss: 1.398824]\n",
      "[Epoch 1/30] [Batch 763/938] [D loss: 0.490193] [G loss: 0.723112]\n",
      "[Epoch 1/30] [Batch 764/938] [D loss: 0.511702] [G loss: 1.598851]\n",
      "[Epoch 1/30] [Batch 765/938] [D loss: 0.520071] [G loss: 0.562299]\n",
      "[Epoch 1/30] [Batch 766/938] [D loss: 0.511327] [G loss: 2.075506]\n",
      "[Epoch 1/30] [Batch 767/938] [D loss: 0.443729] [G loss: 0.701138]\n",
      "[Epoch 1/30] [Batch 768/938] [D loss: 0.429341] [G loss: 1.582948]\n",
      "[Epoch 1/30] [Batch 769/938] [D loss: 0.403330] [G loss: 0.835077]\n",
      "[Epoch 1/30] [Batch 770/938] [D loss: 0.424040] [G loss: 1.635515]\n",
      "[Epoch 1/30] [Batch 771/938] [D loss: 0.413604] [G loss: 0.810963]\n",
      "[Epoch 1/30] [Batch 772/938] [D loss: 0.459173] [G loss: 1.597156]\n",
      "[Epoch 1/30] [Batch 773/938] [D loss: 0.450484] [G loss: 0.750333]\n",
      "[Epoch 1/30] [Batch 774/938] [D loss: 0.388015] [G loss: 1.630336]\n",
      "[Epoch 1/30] [Batch 775/938] [D loss: 0.384388] [G loss: 0.994158]\n",
      "[Epoch 1/30] [Batch 776/938] [D loss: 0.428119] [G loss: 1.308715]\n",
      "[Epoch 1/30] [Batch 777/938] [D loss: 0.486734] [G loss: 0.892786]\n",
      "[Epoch 1/30] [Batch 778/938] [D loss: 0.455834] [G loss: 1.152878]\n",
      "[Epoch 1/30] [Batch 779/938] [D loss: 0.452816] [G loss: 0.950440]\n",
      "[Epoch 1/30] [Batch 780/938] [D loss: 0.382848] [G loss: 1.188757]\n",
      "[Epoch 1/30] [Batch 781/938] [D loss: 0.451036] [G loss: 1.185623]\n",
      "[Epoch 1/30] [Batch 782/938] [D loss: 0.480839] [G loss: 0.702674]\n",
      "[Epoch 1/30] [Batch 783/938] [D loss: 0.560852] [G loss: 1.966135]\n",
      "[Epoch 1/30] [Batch 784/938] [D loss: 0.702840] [G loss: 0.357422]\n",
      "[Epoch 1/30] [Batch 785/938] [D loss: 0.621421] [G loss: 2.277128]\n",
      "[Epoch 1/30] [Batch 786/938] [D loss: 0.611278] [G loss: 0.440212]\n",
      "[Epoch 1/30] [Batch 787/938] [D loss: 0.482655] [G loss: 2.048248]\n",
      "[Epoch 1/30] [Batch 788/938] [D loss: 0.490968] [G loss: 0.670502]\n",
      "[Epoch 1/30] [Batch 789/938] [D loss: 0.434647] [G loss: 1.535554]\n",
      "[Epoch 1/30] [Batch 790/938] [D loss: 0.403950] [G loss: 0.866033]\n",
      "[Epoch 1/30] [Batch 791/938] [D loss: 0.412252] [G loss: 1.545362]\n",
      "[Epoch 1/30] [Batch 792/938] [D loss: 0.444162] [G loss: 0.860894]\n",
      "[Epoch 1/30] [Batch 793/938] [D loss: 0.385528] [G loss: 1.266377]\n",
      "[Epoch 1/30] [Batch 794/938] [D loss: 0.393923] [G loss: 1.229707]\n",
      "[Epoch 1/30] [Batch 795/938] [D loss: 0.440358] [G loss: 0.952727]\n",
      "[Epoch 1/30] [Batch 796/938] [D loss: 0.386128] [G loss: 1.218352]\n",
      "[Epoch 1/30] [Batch 797/938] [D loss: 0.430456] [G loss: 1.167332]\n",
      "[Epoch 1/30] [Batch 798/938] [D loss: 0.463865] [G loss: 0.910700]\n",
      "[Epoch 1/30] [Batch 799/938] [D loss: 0.429366] [G loss: 1.227467]\n",
      "[Epoch 1/30] [Batch 800/938] [D loss: 0.481072] [G loss: 1.020849]\n",
      "[Epoch 1/30] [Batch 801/938] [D loss: 0.432957] [G loss: 0.878080]\n",
      "[Epoch 1/30] [Batch 802/938] [D loss: 0.522511] [G loss: 1.530654]\n",
      "[Epoch 1/30] [Batch 803/938] [D loss: 0.649612] [G loss: 0.402694]\n",
      "[Epoch 1/30] [Batch 804/938] [D loss: 0.787479] [G loss: 2.645448]\n",
      "[Epoch 1/30] [Batch 805/938] [D loss: 0.746974] [G loss: 0.295399]\n",
      "[Epoch 1/30] [Batch 806/938] [D loss: 0.485316] [G loss: 2.163567]\n",
      "[Epoch 1/30] [Batch 807/938] [D loss: 0.373268] [G loss: 0.880298]\n",
      "[Epoch 1/30] [Batch 808/938] [D loss: 0.479559] [G loss: 1.449225]\n",
      "[Epoch 1/30] [Batch 809/938] [D loss: 0.466832] [G loss: 0.704696]\n",
      "[Epoch 1/30] [Batch 810/938] [D loss: 0.499059] [G loss: 1.784120]\n",
      "[Epoch 1/30] [Batch 811/938] [D loss: 0.510179] [G loss: 0.606847]\n",
      "[Epoch 1/30] [Batch 812/938] [D loss: 0.443101] [G loss: 1.862953]\n",
      "[Epoch 1/30] [Batch 813/938] [D loss: 0.413689] [G loss: 0.841219]\n",
      "[Epoch 1/30] [Batch 814/938] [D loss: 0.405621] [G loss: 1.460917]\n",
      "[Epoch 1/30] [Batch 815/938] [D loss: 0.382810] [G loss: 1.135808]\n",
      "[Epoch 1/30] [Batch 816/938] [D loss: 0.417335] [G loss: 1.149738]\n",
      "[Epoch 1/30] [Batch 817/938] [D loss: 0.402195] [G loss: 0.941980]\n",
      "[Epoch 1/30] [Batch 818/938] [D loss: 0.427438] [G loss: 1.586766]\n",
      "[Epoch 1/30] [Batch 819/938] [D loss: 0.469808] [G loss: 0.667302]\n",
      "[Epoch 1/30] [Batch 820/938] [D loss: 0.452466] [G loss: 2.088757]\n",
      "[Epoch 1/30] [Batch 821/938] [D loss: 0.479368] [G loss: 0.643135]\n",
      "[Epoch 1/30] [Batch 822/938] [D loss: 0.481049] [G loss: 1.806155]\n",
      "[Epoch 1/30] [Batch 823/938] [D loss: 0.509351] [G loss: 0.618485]\n",
      "[Epoch 1/30] [Batch 824/938] [D loss: 0.455462] [G loss: 1.845021]\n",
      "[Epoch 1/30] [Batch 825/938] [D loss: 0.466833] [G loss: 0.698675]\n",
      "[Epoch 1/30] [Batch 826/938] [D loss: 0.495523] [G loss: 1.777836]\n",
      "[Epoch 1/30] [Batch 827/938] [D loss: 0.532888] [G loss: 0.532079]\n",
      "[Epoch 1/30] [Batch 828/938] [D loss: 0.579639] [G loss: 2.251805]\n",
      "[Epoch 1/30] [Batch 829/938] [D loss: 0.620637] [G loss: 0.412895]\n",
      "[Epoch 1/30] [Batch 830/938] [D loss: 0.608685] [G loss: 2.152026]\n",
      "[Epoch 1/30] [Batch 831/938] [D loss: 0.559896] [G loss: 0.551456]\n",
      "[Epoch 1/30] [Batch 832/938] [D loss: 0.499002] [G loss: 1.649537]\n",
      "[Epoch 1/30] [Batch 833/938] [D loss: 0.435389] [G loss: 0.739882]\n",
      "[Epoch 1/30] [Batch 834/938] [D loss: 0.443016] [G loss: 1.717104]\n",
      "[Epoch 1/30] [Batch 835/938] [D loss: 0.482590] [G loss: 0.762318]\n",
      "[Epoch 1/30] [Batch 836/938] [D loss: 0.415650] [G loss: 1.371025]\n",
      "[Epoch 1/30] [Batch 837/938] [D loss: 0.404266] [G loss: 0.949411]\n",
      "[Epoch 1/30] [Batch 838/938] [D loss: 0.459739] [G loss: 1.545467]\n",
      "[Epoch 1/30] [Batch 839/938] [D loss: 0.511705] [G loss: 0.630681]\n",
      "[Epoch 1/30] [Batch 840/938] [D loss: 0.559552] [G loss: 1.864064]\n",
      "[Epoch 1/30] [Batch 841/938] [D loss: 0.631427] [G loss: 0.431059]\n",
      "[Epoch 1/30] [Batch 842/938] [D loss: 0.626828] [G loss: 2.309134]\n",
      "[Epoch 1/30] [Batch 843/938] [D loss: 0.628088] [G loss: 0.427529]\n",
      "[Epoch 1/30] [Batch 844/938] [D loss: 0.481575] [G loss: 1.843013]\n",
      "[Epoch 1/30] [Batch 845/938] [D loss: 0.445217] [G loss: 0.936338]\n",
      "[Epoch 1/30] [Batch 846/938] [D loss: 0.396721] [G loss: 0.929409]\n",
      "[Epoch 1/30] [Batch 847/938] [D loss: 0.484815] [G loss: 1.785247]\n",
      "[Epoch 1/30] [Batch 848/938] [D loss: 0.586961] [G loss: 0.480869]\n",
      "[Epoch 1/30] [Batch 849/938] [D loss: 0.548863] [G loss: 1.968732]\n",
      "[Epoch 1/30] [Batch 850/938] [D loss: 0.509723] [G loss: 0.644737]\n",
      "[Epoch 1/30] [Batch 851/938] [D loss: 0.414134] [G loss: 1.353035]\n",
      "[Epoch 1/30] [Batch 852/938] [D loss: 0.423873] [G loss: 1.053982]\n",
      "[Epoch 1/30] [Batch 853/938] [D loss: 0.411547] [G loss: 0.981993]\n",
      "[Epoch 1/30] [Batch 854/938] [D loss: 0.491213] [G loss: 1.385221]\n",
      "[Epoch 1/30] [Batch 855/938] [D loss: 0.509114] [G loss: 0.579508]\n",
      "[Epoch 1/30] [Batch 856/938] [D loss: 0.632657] [G loss: 2.073587]\n",
      "[Epoch 1/30] [Batch 857/938] [D loss: 0.629312] [G loss: 0.403984]\n",
      "[Epoch 1/30] [Batch 858/938] [D loss: 0.481660] [G loss: 2.007082]\n",
      "[Epoch 1/30] [Batch 859/938] [D loss: 0.422465] [G loss: 0.846109]\n",
      "[Epoch 1/30] [Batch 860/938] [D loss: 0.414437] [G loss: 1.170363]\n",
      "[Epoch 1/30] [Batch 861/938] [D loss: 0.388313] [G loss: 1.163135]\n",
      "[Epoch 1/30] [Batch 862/938] [D loss: 0.430321] [G loss: 1.107438]\n",
      "[Epoch 1/30] [Batch 863/938] [D loss: 0.388890] [G loss: 1.023863]\n",
      "[Epoch 1/30] [Batch 864/938] [D loss: 0.440446] [G loss: 1.344460]\n",
      "[Epoch 1/30] [Batch 865/938] [D loss: 0.439052] [G loss: 0.793976]\n",
      "[Epoch 1/30] [Batch 866/938] [D loss: 0.409838] [G loss: 1.621429]\n",
      "[Epoch 1/30] [Batch 867/938] [D loss: 0.387881] [G loss: 0.987153]\n",
      "[Epoch 1/30] [Batch 868/938] [D loss: 0.407120] [G loss: 1.255987]\n",
      "[Epoch 1/30] [Batch 869/938] [D loss: 0.407268] [G loss: 1.050373]\n",
      "[Epoch 1/30] [Batch 870/938] [D loss: 0.395947] [G loss: 1.203781]\n",
      "[Epoch 1/30] [Batch 871/938] [D loss: 0.422760] [G loss: 1.135072]\n",
      "[Epoch 1/30] [Batch 872/938] [D loss: 0.393393] [G loss: 1.045021]\n",
      "[Epoch 1/30] [Batch 873/938] [D loss: 0.403940] [G loss: 1.535568]\n",
      "[Epoch 1/30] [Batch 874/938] [D loss: 0.385119] [G loss: 0.876833]\n",
      "[Epoch 1/30] [Batch 875/938] [D loss: 0.483534] [G loss: 1.803096]\n",
      "[Epoch 1/30] [Batch 876/938] [D loss: 0.554937] [G loss: 0.530309]\n",
      "[Epoch 1/30] [Batch 877/938] [D loss: 0.496108] [G loss: 2.045206]\n",
      "[Epoch 1/30] [Batch 878/938] [D loss: 0.444559] [G loss: 0.710354]\n",
      "[Epoch 1/30] [Batch 879/938] [D loss: 0.443385] [G loss: 1.690149]\n",
      "[Epoch 1/30] [Batch 880/938] [D loss: 0.428015] [G loss: 0.811230]\n",
      "[Epoch 1/30] [Batch 881/938] [D loss: 0.428277] [G loss: 1.601695]\n",
      "[Epoch 1/30] [Batch 882/938] [D loss: 0.457267] [G loss: 0.807449]\n",
      "[Epoch 1/30] [Batch 883/938] [D loss: 0.418542] [G loss: 1.489609]\n",
      "[Epoch 1/30] [Batch 884/938] [D loss: 0.482045] [G loss: 0.830338]\n",
      "[Epoch 1/30] [Batch 885/938] [D loss: 0.392263] [G loss: 1.277949]\n",
      "[Epoch 1/30] [Batch 886/938] [D loss: 0.409400] [G loss: 1.147608]\n",
      "[Epoch 1/30] [Batch 887/938] [D loss: 0.439344] [G loss: 1.013446]\n",
      "[Epoch 1/30] [Batch 888/938] [D loss: 0.423419] [G loss: 1.241586]\n",
      "[Epoch 1/30] [Batch 889/938] [D loss: 0.404050] [G loss: 0.922975]\n",
      "[Epoch 1/30] [Batch 890/938] [D loss: 0.458739] [G loss: 1.614052]\n",
      "[Epoch 1/30] [Batch 891/938] [D loss: 0.482080] [G loss: 0.669454]\n",
      "[Epoch 1/30] [Batch 892/938] [D loss: 0.397053] [G loss: 1.878722]\n",
      "[Epoch 1/30] [Batch 893/938] [D loss: 0.446255] [G loss: 0.797716]\n",
      "[Epoch 1/30] [Batch 894/938] [D loss: 0.383807] [G loss: 1.466679]\n",
      "[Epoch 1/30] [Batch 895/938] [D loss: 0.383899] [G loss: 1.037164]\n",
      "[Epoch 1/30] [Batch 896/938] [D loss: 0.417198] [G loss: 1.320025]\n",
      "[Epoch 1/30] [Batch 897/938] [D loss: 0.418390] [G loss: 0.891769]\n",
      "[Epoch 1/30] [Batch 898/938] [D loss: 0.477955] [G loss: 1.571588]\n",
      "[Epoch 1/30] [Batch 899/938] [D loss: 0.529981] [G loss: 0.534672]\n",
      "[Epoch 1/30] [Batch 900/938] [D loss: 0.608784] [G loss: 2.437018]\n",
      "[Epoch 1/30] [Batch 901/938] [D loss: 0.585977] [G loss: 0.460403]\n",
      "[Epoch 1/30] [Batch 902/938] [D loss: 0.482320] [G loss: 2.066326]\n",
      "[Epoch 1/30] [Batch 903/938] [D loss: 0.448514] [G loss: 0.728396]\n",
      "[Epoch 1/30] [Batch 904/938] [D loss: 0.400200] [G loss: 1.646833]\n",
      "[Epoch 1/30] [Batch 905/938] [D loss: 0.423964] [G loss: 0.959322]\n",
      "[Epoch 1/30] [Batch 906/938] [D loss: 0.432881] [G loss: 1.088380]\n",
      "[Epoch 1/30] [Batch 907/938] [D loss: 0.425923] [G loss: 1.129249]\n",
      "[Epoch 1/30] [Batch 908/938] [D loss: 0.446599] [G loss: 1.066566]\n",
      "[Epoch 1/30] [Batch 909/938] [D loss: 0.426651] [G loss: 1.047237]\n",
      "[Epoch 1/30] [Batch 910/938] [D loss: 0.476506] [G loss: 1.319297]\n",
      "[Epoch 1/30] [Batch 911/938] [D loss: 0.534373] [G loss: 0.613807]\n",
      "[Epoch 1/30] [Batch 912/938] [D loss: 0.559230] [G loss: 2.113556]\n",
      "[Epoch 1/30] [Batch 913/938] [D loss: 0.597443] [G loss: 0.453292]\n",
      "[Epoch 1/30] [Batch 914/938] [D loss: 0.580286] [G loss: 2.277771]\n",
      "[Epoch 1/30] [Batch 915/938] [D loss: 0.546107] [G loss: 0.502059]\n",
      "[Epoch 1/30] [Batch 916/938] [D loss: 0.450933] [G loss: 2.038685]\n",
      "[Epoch 1/30] [Batch 917/938] [D loss: 0.406191] [G loss: 0.809081]\n",
      "[Epoch 1/30] [Batch 918/938] [D loss: 0.382769] [G loss: 1.608196]\n",
      "[Epoch 1/30] [Batch 919/938] [D loss: 0.358128] [G loss: 1.022807]\n",
      "[Epoch 1/30] [Batch 920/938] [D loss: 0.428543] [G loss: 1.496700]\n",
      "[Epoch 1/30] [Batch 921/938] [D loss: 0.435682] [G loss: 0.839154]\n",
      "[Epoch 1/30] [Batch 922/938] [D loss: 0.416775] [G loss: 1.620386]\n",
      "[Epoch 1/30] [Batch 923/938] [D loss: 0.439843] [G loss: 0.783483]\n",
      "[Epoch 1/30] [Batch 924/938] [D loss: 0.500373] [G loss: 1.814410]\n",
      "[Epoch 1/30] [Batch 925/938] [D loss: 0.531353] [G loss: 0.540581]\n",
      "[Epoch 1/30] [Batch 926/938] [D loss: 0.469852] [G loss: 2.245519]\n",
      "[Epoch 1/30] [Batch 927/938] [D loss: 0.440562] [G loss: 0.730035]\n",
      "[Epoch 1/30] [Batch 928/938] [D loss: 0.407295] [G loss: 1.516377]\n",
      "[Epoch 1/30] [Batch 929/938] [D loss: 0.436372] [G loss: 1.041044]\n",
      "[Epoch 1/30] [Batch 930/938] [D loss: 0.385405] [G loss: 1.035344]\n",
      "[Epoch 1/30] [Batch 931/938] [D loss: 0.444666] [G loss: 1.597347]\n",
      "[Epoch 1/30] [Batch 932/938] [D loss: 0.551907] [G loss: 0.554119]\n",
      "[Epoch 1/30] [Batch 933/938] [D loss: 0.580423] [G loss: 2.248541]\n",
      "[Epoch 1/30] [Batch 934/938] [D loss: 0.617924] [G loss: 0.440066]\n",
      "[Epoch 1/30] [Batch 935/938] [D loss: 0.435616] [G loss: 2.062421]\n",
      "[Epoch 1/30] [Batch 936/938] [D loss: 0.383434] [G loss: 1.028511]\n",
      "[Epoch 1/30] [Batch 937/938] [D loss: 0.385448] [G loss: 1.000735]\n",
      "[Epoch 2/30] [Batch 0/938] [D loss: 0.461071] [G loss: 1.611130]\n",
      "[Epoch 2/30] [Batch 1/938] [D loss: 0.490801] [G loss: 0.589623]\n",
      "[Epoch 2/30] [Batch 2/938] [D loss: 0.590001] [G loss: 2.165720]\n",
      "[Epoch 2/30] [Batch 3/938] [D loss: 0.599060] [G loss: 0.451214]\n",
      "[Epoch 2/30] [Batch 4/938] [D loss: 0.487601] [G loss: 1.966840]\n",
      "[Epoch 2/30] [Batch 5/938] [D loss: 0.448906] [G loss: 0.733813]\n",
      "[Epoch 2/30] [Batch 6/938] [D loss: 0.397979] [G loss: 1.620889]\n",
      "[Epoch 2/30] [Batch 7/938] [D loss: 0.405954] [G loss: 0.988684]\n",
      "[Epoch 2/30] [Batch 8/938] [D loss: 0.431395] [G loss: 1.006621]\n",
      "[Epoch 2/30] [Batch 9/938] [D loss: 0.408056] [G loss: 1.279927]\n",
      "[Epoch 2/30] [Batch 10/938] [D loss: 0.469930] [G loss: 0.798907]\n",
      "[Epoch 2/30] [Batch 11/938] [D loss: 0.465633] [G loss: 1.414323]\n",
      "[Epoch 2/30] [Batch 12/938] [D loss: 0.520575] [G loss: 0.626784]\n",
      "[Epoch 2/30] [Batch 13/938] [D loss: 0.523361] [G loss: 1.686949]\n",
      "[Epoch 2/30] [Batch 14/938] [D loss: 0.591635] [G loss: 0.497320]\n",
      "[Epoch 2/30] [Batch 15/938] [D loss: 0.585670] [G loss: 1.803944]\n",
      "[Epoch 2/30] [Batch 16/938] [D loss: 0.647117] [G loss: 0.455407]\n",
      "[Epoch 2/30] [Batch 17/938] [D loss: 0.462538] [G loss: 1.522716]\n",
      "[Epoch 2/30] [Batch 18/938] [D loss: 0.447307] [G loss: 0.977407]\n",
      "[Epoch 2/30] [Batch 19/938] [D loss: 0.461381] [G loss: 0.985766]\n",
      "[Epoch 2/30] [Batch 20/938] [D loss: 0.488215] [G loss: 0.995324]\n",
      "[Epoch 2/30] [Batch 21/938] [D loss: 0.441591] [G loss: 0.993088]\n",
      "[Epoch 2/30] [Batch 22/938] [D loss: 0.438187] [G loss: 1.162578]\n",
      "[Epoch 2/30] [Batch 23/938] [D loss: 0.461659] [G loss: 0.892140]\n",
      "[Epoch 2/30] [Batch 24/938] [D loss: 0.476845] [G loss: 1.229247]\n",
      "[Epoch 2/30] [Batch 25/938] [D loss: 0.454146] [G loss: 0.767192]\n",
      "[Epoch 2/30] [Batch 26/938] [D loss: 0.540993] [G loss: 1.626750]\n",
      "[Epoch 2/30] [Batch 27/938] [D loss: 0.603938] [G loss: 0.443708]\n",
      "[Epoch 2/30] [Batch 28/938] [D loss: 0.515953] [G loss: 2.078834]\n",
      "[Epoch 2/30] [Batch 29/938] [D loss: 0.493161] [G loss: 0.652993]\n",
      "[Epoch 2/30] [Batch 30/938] [D loss: 0.473745] [G loss: 1.428671]\n",
      "[Epoch 2/30] [Batch 31/938] [D loss: 0.422911] [G loss: 0.758553]\n",
      "[Epoch 2/30] [Batch 32/938] [D loss: 0.455102] [G loss: 1.673688]\n",
      "[Epoch 2/30] [Batch 33/938] [D loss: 0.463934] [G loss: 0.693153]\n",
      "[Epoch 2/30] [Batch 34/938] [D loss: 0.422262] [G loss: 1.607017]\n",
      "[Epoch 2/30] [Batch 35/938] [D loss: 0.424747] [G loss: 0.846966]\n",
      "[Epoch 2/30] [Batch 36/938] [D loss: 0.440757] [G loss: 1.335215]\n",
      "[Epoch 2/30] [Batch 37/938] [D loss: 0.430533] [G loss: 0.823907]\n",
      "[Epoch 2/30] [Batch 38/938] [D loss: 0.401020] [G loss: 1.588588]\n",
      "[Epoch 2/30] [Batch 39/938] [D loss: 0.410745] [G loss: 0.810771]\n",
      "[Epoch 2/30] [Batch 40/938] [D loss: 0.403773] [G loss: 1.703382]\n",
      "[Epoch 2/30] [Batch 41/938] [D loss: 0.445424] [G loss: 0.813547]\n",
      "[Epoch 2/30] [Batch 42/938] [D loss: 0.454379] [G loss: 1.339908]\n",
      "[Epoch 2/30] [Batch 43/938] [D loss: 0.437886] [G loss: 0.919066]\n",
      "[Epoch 2/30] [Batch 44/938] [D loss: 0.416724] [G loss: 1.217956]\n",
      "[Epoch 2/30] [Batch 45/938] [D loss: 0.374339] [G loss: 1.079392]\n",
      "[Epoch 2/30] [Batch 46/938] [D loss: 0.367373] [G loss: 1.322574]\n",
      "[Epoch 2/30] [Batch 47/938] [D loss: 0.373536] [G loss: 1.056603]\n",
      "[Epoch 2/30] [Batch 48/938] [D loss: 0.382323] [G loss: 1.475566]\n",
      "[Epoch 2/30] [Batch 49/938] [D loss: 0.425033] [G loss: 0.881888]\n",
      "[Epoch 2/30] [Batch 50/938] [D loss: 0.362117] [G loss: 1.525795]\n",
      "[Epoch 2/30] [Batch 51/938] [D loss: 0.410683] [G loss: 0.963059]\n",
      "[Epoch 2/30] [Batch 52/938] [D loss: 0.461796] [G loss: 1.296778]\n",
      "[Epoch 2/30] [Batch 53/938] [D loss: 0.448740] [G loss: 0.781845]\n",
      "[Epoch 2/30] [Batch 54/938] [D loss: 0.486457] [G loss: 1.684653]\n",
      "[Epoch 2/30] [Batch 55/938] [D loss: 0.464941] [G loss: 0.718266]\n",
      "[Epoch 2/30] [Batch 56/938] [D loss: 0.399801] [G loss: 1.684510]\n",
      "[Epoch 2/30] [Batch 57/938] [D loss: 0.404666] [G loss: 0.862584]\n",
      "[Epoch 2/30] [Batch 58/938] [D loss: 0.391364] [G loss: 1.590076]\n",
      "[Epoch 2/30] [Batch 59/938] [D loss: 0.414052] [G loss: 0.868013]\n",
      "[Epoch 2/30] [Batch 60/938] [D loss: 0.421535] [G loss: 1.491291]\n",
      "[Epoch 2/30] [Batch 61/938] [D loss: 0.439087] [G loss: 0.872044]\n",
      "[Epoch 2/30] [Batch 62/938] [D loss: 0.416773] [G loss: 1.330412]\n",
      "[Epoch 2/30] [Batch 63/938] [D loss: 0.411811] [G loss: 0.993914]\n",
      "[Epoch 2/30] [Batch 64/938] [D loss: 0.360684] [G loss: 1.224880]\n",
      "[Epoch 2/30] [Batch 65/938] [D loss: 0.390601] [G loss: 1.279402]\n",
      "[Epoch 2/30] [Batch 66/938] [D loss: 0.435116] [G loss: 0.900338]\n",
      "[Epoch 2/30] [Batch 67/938] [D loss: 0.432463] [G loss: 1.449777]\n",
      "[Epoch 2/30] [Batch 68/938] [D loss: 0.481762] [G loss: 0.720427]\n",
      "[Epoch 2/30] [Batch 69/938] [D loss: 0.469251] [G loss: 1.690125]\n",
      "[Epoch 2/30] [Batch 70/938] [D loss: 0.461546] [G loss: 0.662751]\n",
      "[Epoch 2/30] [Batch 71/938] [D loss: 0.397151] [G loss: 2.012779]\n",
      "[Epoch 2/30] [Batch 72/938] [D loss: 0.337831] [G loss: 1.077840]\n",
      "[Epoch 2/30] [Batch 73/938] [D loss: 0.388514] [G loss: 1.266742]\n",
      "[Epoch 2/30] [Batch 74/938] [D loss: 0.393824] [G loss: 1.100055]\n",
      "[Epoch 2/30] [Batch 75/938] [D loss: 0.302326] [G loss: 1.264123]\n",
      "[Epoch 2/30] [Batch 76/938] [D loss: 0.393173] [G loss: 1.628745]\n",
      "[Epoch 2/30] [Batch 77/938] [D loss: 0.429776] [G loss: 0.722637]\n",
      "[Epoch 2/30] [Batch 78/938] [D loss: 0.489736] [G loss: 2.167346]\n",
      "[Epoch 2/30] [Batch 79/938] [D loss: 0.462204] [G loss: 0.681852]\n",
      "[Epoch 2/30] [Batch 80/938] [D loss: 0.344868] [G loss: 1.764464]\n",
      "[Epoch 2/30] [Batch 81/938] [D loss: 0.332127] [G loss: 1.184600]\n",
      "[Epoch 2/30] [Batch 82/938] [D loss: 0.358332] [G loss: 1.228658]\n",
      "[Epoch 2/30] [Batch 83/938] [D loss: 0.351745] [G loss: 1.347708]\n",
      "[Epoch 2/30] [Batch 84/938] [D loss: 0.382742] [G loss: 1.149679]\n",
      "[Epoch 2/30] [Batch 85/938] [D loss: 0.345404] [G loss: 1.336061]\n",
      "[Epoch 2/30] [Batch 86/938] [D loss: 0.345909] [G loss: 1.291537]\n",
      "[Epoch 2/30] [Batch 87/938] [D loss: 0.360773] [G loss: 1.320029]\n",
      "[Epoch 2/30] [Batch 88/938] [D loss: 0.426032] [G loss: 1.078208]\n",
      "[Epoch 2/30] [Batch 89/938] [D loss: 0.408872] [G loss: 1.236464]\n",
      "[Epoch 2/30] [Batch 90/938] [D loss: 0.393181] [G loss: 1.223147]\n",
      "[Epoch 2/30] [Batch 91/938] [D loss: 0.373616] [G loss: 1.285089]\n",
      "[Epoch 2/30] [Batch 92/938] [D loss: 0.371184] [G loss: 1.292829]\n",
      "[Epoch 2/30] [Batch 93/938] [D loss: 0.378755] [G loss: 1.265851]\n",
      "[Epoch 2/30] [Batch 94/938] [D loss: 0.406020] [G loss: 1.112772]\n",
      "[Epoch 2/30] [Batch 95/938] [D loss: 0.434732] [G loss: 1.482501]\n",
      "[Epoch 2/30] [Batch 96/938] [D loss: 0.478089] [G loss: 0.709081]\n",
      "[Epoch 2/30] [Batch 97/938] [D loss: 0.577782] [G loss: 2.339042]\n",
      "[Epoch 2/30] [Batch 98/938] [D loss: 0.663715] [G loss: 0.407822]\n",
      "[Epoch 2/30] [Batch 99/938] [D loss: 0.545437] [G loss: 2.514061]\n",
      "[Epoch 2/30] [Batch 100/938] [D loss: 0.465679] [G loss: 0.663638]\n",
      "[Epoch 2/30] [Batch 101/938] [D loss: 0.437920] [G loss: 1.886918]\n",
      "[Epoch 2/30] [Batch 102/938] [D loss: 0.401406] [G loss: 0.821905]\n",
      "[Epoch 2/30] [Batch 103/938] [D loss: 0.321052] [G loss: 1.758613]\n",
      "[Epoch 2/30] [Batch 104/938] [D loss: 0.351934] [G loss: 1.227126]\n",
      "[Epoch 2/30] [Batch 105/938] [D loss: 0.415653] [G loss: 1.129361]\n",
      "[Epoch 2/30] [Batch 106/938] [D loss: 0.338405] [G loss: 1.142640]\n",
      "[Epoch 2/30] [Batch 107/938] [D loss: 0.342521] [G loss: 1.630340]\n",
      "[Epoch 2/30] [Batch 108/938] [D loss: 0.430462] [G loss: 0.900009]\n",
      "[Epoch 2/30] [Batch 109/938] [D loss: 0.380060] [G loss: 1.378705]\n",
      "[Epoch 2/30] [Batch 110/938] [D loss: 0.448340] [G loss: 1.130771]\n",
      "[Epoch 2/30] [Batch 111/938] [D loss: 0.424447] [G loss: 0.974235]\n",
      "[Epoch 2/30] [Batch 112/938] [D loss: 0.416019] [G loss: 1.474413]\n",
      "[Epoch 2/30] [Batch 113/938] [D loss: 0.456295] [G loss: 0.735506]\n",
      "[Epoch 2/30] [Batch 114/938] [D loss: 0.491165] [G loss: 2.004583]\n",
      "[Epoch 2/30] [Batch 115/938] [D loss: 0.509423] [G loss: 0.553307]\n",
      "[Epoch 2/30] [Batch 116/938] [D loss: 0.557267] [G loss: 2.276882]\n",
      "[Epoch 2/30] [Batch 117/938] [D loss: 0.562978] [G loss: 0.509620]\n",
      "[Epoch 2/30] [Batch 118/938] [D loss: 0.500926] [G loss: 2.002056]\n",
      "[Epoch 2/30] [Batch 119/938] [D loss: 0.457167] [G loss: 0.684544]\n",
      "[Epoch 2/30] [Batch 120/938] [D loss: 0.383841] [G loss: 1.797650]\n",
      "[Epoch 2/30] [Batch 121/938] [D loss: 0.402255] [G loss: 0.927062]\n",
      "[Epoch 2/30] [Batch 122/938] [D loss: 0.374847] [G loss: 1.395767]\n",
      "[Epoch 2/30] [Batch 123/938] [D loss: 0.373493] [G loss: 1.031322]\n",
      "[Epoch 2/30] [Batch 124/938] [D loss: 0.393314] [G loss: 1.476634]\n",
      "[Epoch 2/30] [Batch 125/938] [D loss: 0.425125] [G loss: 0.925653]\n",
      "[Epoch 2/30] [Batch 126/938] [D loss: 0.420624] [G loss: 1.277298]\n",
      "[Epoch 2/30] [Batch 127/938] [D loss: 0.406976] [G loss: 1.070405]\n",
      "[Epoch 2/30] [Batch 128/938] [D loss: 0.465552] [G loss: 1.136953]\n",
      "[Epoch 2/30] [Batch 129/938] [D loss: 0.452617] [G loss: 0.861220]\n",
      "[Epoch 2/30] [Batch 130/938] [D loss: 0.468326] [G loss: 1.479756]\n",
      "[Epoch 2/30] [Batch 131/938] [D loss: 0.481065] [G loss: 0.647125]\n",
      "[Epoch 2/30] [Batch 132/938] [D loss: 0.567054] [G loss: 2.221660]\n",
      "[Epoch 2/30] [Batch 133/938] [D loss: 0.537361] [G loss: 0.543955]\n",
      "[Epoch 2/30] [Batch 134/938] [D loss: 0.489781] [G loss: 1.930299]\n",
      "[Epoch 2/30] [Batch 135/938] [D loss: 0.485257] [G loss: 0.640637]\n",
      "[Epoch 2/30] [Batch 136/938] [D loss: 0.388084] [G loss: 1.673564]\n",
      "[Epoch 2/30] [Batch 137/938] [D loss: 0.362083] [G loss: 1.025644]\n",
      "[Epoch 2/30] [Batch 138/938] [D loss: 0.373604] [G loss: 1.403890]\n",
      "[Epoch 2/30] [Batch 139/938] [D loss: 0.383466] [G loss: 0.970759]\n",
      "[Epoch 2/30] [Batch 140/938] [D loss: 0.403845] [G loss: 1.477704]\n",
      "[Epoch 2/30] [Batch 141/938] [D loss: 0.437574] [G loss: 0.824078]\n",
      "[Epoch 2/30] [Batch 142/938] [D loss: 0.434693] [G loss: 1.672983]\n",
      "[Epoch 2/30] [Batch 143/938] [D loss: 0.453124] [G loss: 0.669054]\n",
      "[Epoch 2/30] [Batch 144/938] [D loss: 0.486941] [G loss: 2.072987]\n",
      "[Epoch 2/30] [Batch 145/938] [D loss: 0.455096] [G loss: 0.725887]\n",
      "[Epoch 2/30] [Batch 146/938] [D loss: 0.448558] [G loss: 1.558264]\n",
      "[Epoch 2/30] [Batch 147/938] [D loss: 0.456018] [G loss: 0.776404]\n",
      "[Epoch 2/30] [Batch 148/938] [D loss: 0.413902] [G loss: 1.526852]\n",
      "[Epoch 2/30] [Batch 149/938] [D loss: 0.351564] [G loss: 0.934587]\n",
      "[Epoch 2/30] [Batch 150/938] [D loss: 0.422848] [G loss: 1.850685]\n",
      "[Epoch 2/30] [Batch 151/938] [D loss: 0.419234] [G loss: 0.720753]\n",
      "[Epoch 2/30] [Batch 152/938] [D loss: 0.348617] [G loss: 2.039424]\n",
      "[Epoch 2/30] [Batch 153/938] [D loss: 0.359928] [G loss: 1.082864]\n",
      "[Epoch 2/30] [Batch 154/938] [D loss: 0.339565] [G loss: 1.253963]\n",
      "[Epoch 2/30] [Batch 155/938] [D loss: 0.361661] [G loss: 1.449656]\n",
      "[Epoch 2/30] [Batch 156/938] [D loss: 0.324077] [G loss: 1.002298]\n",
      "[Epoch 2/30] [Batch 157/938] [D loss: 0.368046] [G loss: 1.929794]\n",
      "[Epoch 2/30] [Batch 158/938] [D loss: 0.358141] [G loss: 0.925443]\n",
      "[Epoch 2/30] [Batch 159/938] [D loss: 0.316026] [G loss: 1.642884]\n",
      "[Epoch 2/30] [Batch 160/938] [D loss: 0.346658] [G loss: 1.352177]\n",
      "[Epoch 2/30] [Batch 161/938] [D loss: 0.364988] [G loss: 0.923130]\n",
      "[Epoch 2/30] [Batch 162/938] [D loss: 0.436423] [G loss: 1.968694]\n",
      "[Epoch 2/30] [Batch 163/938] [D loss: 0.501777] [G loss: 0.564952]\n",
      "[Epoch 2/30] [Batch 164/938] [D loss: 0.473689] [G loss: 2.318773]\n",
      "[Epoch 2/30] [Batch 165/938] [D loss: 0.408896] [G loss: 0.707390]\n",
      "[Epoch 2/30] [Batch 166/938] [D loss: 0.335155] [G loss: 1.947630]\n",
      "[Epoch 2/30] [Batch 167/938] [D loss: 0.330677] [G loss: 1.138703]\n",
      "[Epoch 2/30] [Batch 168/938] [D loss: 0.296709] [G loss: 1.276993]\n",
      "[Epoch 2/30] [Batch 169/938] [D loss: 0.375009] [G loss: 1.720711]\n",
      "[Epoch 2/30] [Batch 170/938] [D loss: 0.395894] [G loss: 0.824891]\n",
      "[Epoch 2/30] [Batch 171/938] [D loss: 0.340669] [G loss: 1.830852]\n",
      "[Epoch 2/30] [Batch 172/938] [D loss: 0.354555] [G loss: 1.051767]\n",
      "[Epoch 2/30] [Batch 173/938] [D loss: 0.350056] [G loss: 1.367900]\n",
      "[Epoch 2/30] [Batch 174/938] [D loss: 0.381745] [G loss: 1.158842]\n",
      "[Epoch 2/30] [Batch 175/938] [D loss: 0.391798] [G loss: 1.120149]\n",
      "[Epoch 2/30] [Batch 176/938] [D loss: 0.395615] [G loss: 1.394336]\n",
      "[Epoch 2/30] [Batch 177/938] [D loss: 0.401440] [G loss: 0.944933]\n",
      "[Epoch 2/30] [Batch 178/938] [D loss: 0.441828] [G loss: 1.645038]\n",
      "[Epoch 2/30] [Batch 179/938] [D loss: 0.475408] [G loss: 0.710061]\n",
      "[Epoch 2/30] [Batch 180/938] [D loss: 0.445978] [G loss: 1.905353]\n",
      "[Epoch 2/30] [Batch 181/938] [D loss: 0.503754] [G loss: 0.563658]\n",
      "[Epoch 2/30] [Batch 182/938] [D loss: 0.527169] [G loss: 2.792596]\n",
      "[Epoch 2/30] [Batch 183/938] [D loss: 0.465804] [G loss: 0.623438]\n",
      "[Epoch 2/30] [Batch 184/938] [D loss: 0.436862] [G loss: 2.121440]\n",
      "[Epoch 2/30] [Batch 185/938] [D loss: 0.391706] [G loss: 0.747776]\n",
      "[Epoch 2/30] [Batch 186/938] [D loss: 0.397116] [G loss: 2.158356]\n",
      "[Epoch 2/30] [Batch 187/938] [D loss: 0.365121] [G loss: 0.890217]\n",
      "[Epoch 2/30] [Batch 188/938] [D loss: 0.286812] [G loss: 1.801160]\n",
      "[Epoch 2/30] [Batch 189/938] [D loss: 0.252270] [G loss: 1.533128]\n",
      "[Epoch 2/30] [Batch 190/938] [D loss: 0.273675] [G loss: 1.372077]\n",
      "[Epoch 2/30] [Batch 191/938] [D loss: 0.349255] [G loss: 1.591576]\n",
      "[Epoch 2/30] [Batch 192/938] [D loss: 0.368329] [G loss: 1.004451]\n",
      "[Epoch 2/30] [Batch 193/938] [D loss: 0.402825] [G loss: 1.714731]\n",
      "[Epoch 2/30] [Batch 194/938] [D loss: 0.404042] [G loss: 0.813303]\n",
      "[Epoch 2/30] [Batch 195/938] [D loss: 0.469368] [G loss: 2.208763]\n",
      "[Epoch 2/30] [Batch 196/938] [D loss: 0.478857] [G loss: 0.649528]\n",
      "[Epoch 2/30] [Batch 197/938] [D loss: 0.471119] [G loss: 2.212200]\n",
      "[Epoch 2/30] [Batch 198/938] [D loss: 0.419989] [G loss: 0.735008]\n",
      "[Epoch 2/30] [Batch 199/938] [D loss: 0.418480] [G loss: 2.448518]\n",
      "[Epoch 2/30] [Batch 200/938] [D loss: 0.358133] [G loss: 0.891092]\n",
      "[Epoch 2/30] [Batch 201/938] [D loss: 0.273511] [G loss: 1.892268]\n",
      "[Epoch 2/30] [Batch 202/938] [D loss: 0.298588] [G loss: 1.557718]\n",
      "[Epoch 2/30] [Batch 203/938] [D loss: 0.339653] [G loss: 1.103755]\n",
      "[Epoch 2/30] [Batch 204/938] [D loss: 0.321423] [G loss: 1.807607]\n",
      "[Epoch 2/30] [Batch 205/938] [D loss: 0.350538] [G loss: 1.216774]\n",
      "[Epoch 2/30] [Batch 206/938] [D loss: 0.307351] [G loss: 1.306491]\n",
      "[Epoch 2/30] [Batch 207/938] [D loss: 0.340896] [G loss: 1.683840]\n",
      "[Epoch 2/30] [Batch 208/938] [D loss: 0.365865] [G loss: 0.953646]\n",
      "[Epoch 2/30] [Batch 209/938] [D loss: 0.404269] [G loss: 1.865207]\n",
      "[Epoch 2/30] [Batch 210/938] [D loss: 0.391656] [G loss: 0.884655]\n",
      "[Epoch 2/30] [Batch 211/938] [D loss: 0.381901] [G loss: 1.997301]\n",
      "[Epoch 2/30] [Batch 212/938] [D loss: 0.352525] [G loss: 1.037996]\n",
      "[Epoch 2/30] [Batch 213/938] [D loss: 0.353956] [G loss: 1.691650]\n",
      "[Epoch 2/30] [Batch 214/938] [D loss: 0.384134] [G loss: 1.055764]\n",
      "[Epoch 2/30] [Batch 215/938] [D loss: 0.357420] [G loss: 1.470684]\n",
      "[Epoch 2/30] [Batch 216/938] [D loss: 0.369762] [G loss: 1.102349]\n",
      "[Epoch 2/30] [Batch 217/938] [D loss: 0.383979] [G loss: 1.750891]\n",
      "[Epoch 2/30] [Batch 218/938] [D loss: 0.463946] [G loss: 0.709612]\n",
      "[Epoch 2/30] [Batch 219/938] [D loss: 0.483032] [G loss: 2.202494]\n",
      "[Epoch 2/30] [Batch 220/938] [D loss: 0.543902] [G loss: 0.542013]\n",
      "[Epoch 2/30] [Batch 221/938] [D loss: 0.515330] [G loss: 2.547412]\n",
      "[Epoch 2/30] [Batch 222/938] [D loss: 0.425124] [G loss: 0.748860]\n",
      "[Epoch 2/30] [Batch 223/938] [D loss: 0.330414] [G loss: 1.882470]\n",
      "[Epoch 2/30] [Batch 224/938] [D loss: 0.331922] [G loss: 1.251391]\n",
      "[Epoch 2/30] [Batch 225/938] [D loss: 0.297083] [G loss: 1.375666]\n",
      "[Epoch 2/30] [Batch 226/938] [D loss: 0.344142] [G loss: 1.500263]\n",
      "[Epoch 2/30] [Batch 227/938] [D loss: 0.354242] [G loss: 0.995744]\n",
      "[Epoch 2/30] [Batch 228/938] [D loss: 0.330368] [G loss: 1.924957]\n",
      "[Epoch 2/30] [Batch 229/938] [D loss: 0.351309] [G loss: 1.053008]\n",
      "[Epoch 2/30] [Batch 230/938] [D loss: 0.328527] [G loss: 1.476822]\n",
      "[Epoch 2/30] [Batch 231/938] [D loss: 0.406805] [G loss: 1.358203]\n",
      "[Epoch 2/30] [Batch 232/938] [D loss: 0.385735] [G loss: 1.005701]\n",
      "[Epoch 2/30] [Batch 233/938] [D loss: 0.491518] [G loss: 1.903899]\n",
      "[Epoch 2/30] [Batch 234/938] [D loss: 0.556198] [G loss: 0.500734]\n",
      "[Epoch 2/30] [Batch 235/938] [D loss: 0.569476] [G loss: 2.685220]\n",
      "[Epoch 2/30] [Batch 236/938] [D loss: 0.420940] [G loss: 0.760518]\n",
      "[Epoch 2/30] [Batch 237/938] [D loss: 0.372428] [G loss: 1.559537]\n",
      "[Epoch 2/30] [Batch 238/938] [D loss: 0.314583] [G loss: 1.303689]\n",
      "[Epoch 2/30] [Batch 239/938] [D loss: 0.336517] [G loss: 1.460142]\n",
      "[Epoch 2/30] [Batch 240/938] [D loss: 0.358660] [G loss: 1.226748]\n",
      "[Epoch 2/30] [Batch 241/938] [D loss: 0.354279] [G loss: 1.366579]\n",
      "[Epoch 2/30] [Batch 242/938] [D loss: 0.351560] [G loss: 1.145224]\n",
      "[Epoch 2/30] [Batch 243/938] [D loss: 0.350992] [G loss: 1.483457]\n",
      "[Epoch 2/30] [Batch 244/938] [D loss: 0.365580] [G loss: 1.057739]\n",
      "[Epoch 2/30] [Batch 245/938] [D loss: 0.399427] [G loss: 1.577451]\n",
      "[Epoch 2/30] [Batch 246/938] [D loss: 0.434704] [G loss: 0.743269]\n",
      "[Epoch 2/30] [Batch 247/938] [D loss: 0.512131] [G loss: 2.160547]\n",
      "[Epoch 2/30] [Batch 248/938] [D loss: 0.597516] [G loss: 0.445136]\n",
      "[Epoch 2/30] [Batch 249/938] [D loss: 0.518245] [G loss: 2.669759]\n",
      "[Epoch 2/30] [Batch 250/938] [D loss: 0.448666] [G loss: 0.665595]\n",
      "[Epoch 2/30] [Batch 251/938] [D loss: 0.377730] [G loss: 1.993063]\n",
      "[Epoch 2/30] [Batch 252/938] [D loss: 0.289664] [G loss: 1.177654]\n",
      "[Epoch 2/30] [Batch 253/938] [D loss: 0.335933] [G loss: 1.452640]\n",
      "[Epoch 2/30] [Batch 254/938] [D loss: 0.372785] [G loss: 1.323605]\n",
      "[Epoch 2/30] [Batch 255/938] [D loss: 0.348461] [G loss: 1.070338]\n",
      "[Epoch 2/30] [Batch 256/938] [D loss: 0.327084] [G loss: 1.900678]\n",
      "[Epoch 2/30] [Batch 257/938] [D loss: 0.356868] [G loss: 0.996130]\n",
      "[Epoch 2/30] [Batch 258/938] [D loss: 0.298809] [G loss: 1.547132]\n",
      "[Epoch 2/30] [Batch 259/938] [D loss: 0.306534] [G loss: 1.271212]\n",
      "[Epoch 2/30] [Batch 260/938] [D loss: 0.321429] [G loss: 1.351021]\n",
      "[Epoch 2/30] [Batch 261/938] [D loss: 0.378122] [G loss: 1.293927]\n",
      "[Epoch 2/30] [Batch 262/938] [D loss: 0.344254] [G loss: 1.104269]\n",
      "[Epoch 2/30] [Batch 263/938] [D loss: 0.331198] [G loss: 1.656392]\n",
      "[Epoch 2/30] [Batch 264/938] [D loss: 0.319096] [G loss: 1.124449]\n",
      "[Epoch 2/30] [Batch 265/938] [D loss: 0.362094] [G loss: 1.535866]\n",
      "[Epoch 2/30] [Batch 266/938] [D loss: 0.360801] [G loss: 1.029651]\n",
      "[Epoch 2/30] [Batch 267/938] [D loss: 0.444633] [G loss: 1.905874]\n",
      "[Epoch 2/30] [Batch 268/938] [D loss: 0.582731] [G loss: 0.449561]\n",
      "[Epoch 2/30] [Batch 269/938] [D loss: 0.651712] [G loss: 2.773279]\n",
      "[Epoch 2/30] [Batch 270/938] [D loss: 0.607571] [G loss: 0.421831]\n",
      "[Epoch 2/30] [Batch 271/938] [D loss: 0.360945] [G loss: 2.518704]\n",
      "[Epoch 2/30] [Batch 272/938] [D loss: 0.307674] [G loss: 1.517430]\n",
      "[Epoch 2/30] [Batch 273/938] [D loss: 0.331154] [G loss: 1.136890]\n",
      "[Epoch 2/30] [Batch 274/938] [D loss: 0.313071] [G loss: 1.762087]\n",
      "[Epoch 2/30] [Batch 275/938] [D loss: 0.355540] [G loss: 1.288131]\n",
      "[Epoch 2/30] [Batch 276/938] [D loss: 0.393449] [G loss: 1.046847]\n",
      "[Epoch 2/30] [Batch 277/938] [D loss: 0.315729] [G loss: 1.459553]\n",
      "[Epoch 2/30] [Batch 278/938] [D loss: 0.307962] [G loss: 1.398120]\n",
      "[Epoch 2/30] [Batch 279/938] [D loss: 0.348138] [G loss: 1.236762]\n",
      "[Epoch 2/30] [Batch 280/938] [D loss: 0.414496] [G loss: 1.299371]\n",
      "[Epoch 2/30] [Batch 281/938] [D loss: 0.388116] [G loss: 0.851436]\n",
      "[Epoch 2/30] [Batch 282/938] [D loss: 0.429571] [G loss: 2.220800]\n",
      "[Epoch 2/30] [Batch 283/938] [D loss: 0.439056] [G loss: 0.678723]\n",
      "[Epoch 2/30] [Batch 284/938] [D loss: 0.424091] [G loss: 2.058281]\n",
      "[Epoch 2/30] [Batch 285/938] [D loss: 0.443325] [G loss: 0.722327]\n",
      "[Epoch 2/30] [Batch 286/938] [D loss: 0.382968] [G loss: 1.952506]\n",
      "[Epoch 2/30] [Batch 287/938] [D loss: 0.413349] [G loss: 0.832006]\n",
      "[Epoch 2/30] [Batch 288/938] [D loss: 0.367033] [G loss: 1.586301]\n",
      "[Epoch 2/30] [Batch 289/938] [D loss: 0.342629] [G loss: 1.021490]\n",
      "[Epoch 2/30] [Batch 290/938] [D loss: 0.408849] [G loss: 1.802854]\n",
      "[Epoch 2/30] [Batch 291/938] [D loss: 0.482285] [G loss: 0.602846]\n",
      "[Epoch 2/30] [Batch 292/938] [D loss: 0.444221] [G loss: 2.667194]\n",
      "[Epoch 2/30] [Batch 293/938] [D loss: 0.433843] [G loss: 0.708469]\n",
      "[Epoch 2/30] [Batch 294/938] [D loss: 0.371925] [G loss: 2.164552]\n",
      "[Epoch 2/30] [Batch 295/938] [D loss: 0.312106] [G loss: 1.143021]\n",
      "[Epoch 2/30] [Batch 296/938] [D loss: 0.271665] [G loss: 1.439347]\n",
      "[Epoch 2/30] [Batch 297/938] [D loss: 0.351923] [G loss: 1.798596]\n",
      "[Epoch 2/30] [Batch 298/938] [D loss: 0.397250] [G loss: 0.837039]\n",
      "[Epoch 2/30] [Batch 299/938] [D loss: 0.372671] [G loss: 2.165695]\n",
      "[Epoch 2/30] [Batch 300/938] [D loss: 0.387791] [G loss: 0.827457]\n",
      "[Epoch 2/30] [Batch 301/938] [D loss: 0.324047] [G loss: 2.090854]\n",
      "[Epoch 2/30] [Batch 302/938] [D loss: 0.351375] [G loss: 1.033597]\n",
      "[Epoch 2/30] [Batch 303/938] [D loss: 0.281072] [G loss: 1.506942]\n",
      "[Epoch 2/30] [Batch 304/938] [D loss: 0.271870] [G loss: 1.742881]\n",
      "[Epoch 2/30] [Batch 305/938] [D loss: 0.311173] [G loss: 1.116638]\n",
      "[Epoch 2/30] [Batch 306/938] [D loss: 0.332908] [G loss: 1.959603]\n",
      "[Epoch 2/30] [Batch 307/938] [D loss: 0.358183] [G loss: 0.892345]\n",
      "[Epoch 2/30] [Batch 308/938] [D loss: 0.454924] [G loss: 2.138695]\n",
      "[Epoch 2/30] [Batch 309/938] [D loss: 0.546738] [G loss: 0.510605]\n",
      "[Epoch 2/30] [Batch 310/938] [D loss: 0.516246] [G loss: 2.988174]\n",
      "[Epoch 2/30] [Batch 311/938] [D loss: 0.419979] [G loss: 0.730124]\n",
      "[Epoch 2/30] [Batch 312/938] [D loss: 0.301249] [G loss: 2.008764]\n",
      "[Epoch 2/30] [Batch 313/938] [D loss: 0.296366] [G loss: 1.366440]\n",
      "[Epoch 2/30] [Batch 314/938] [D loss: 0.306156] [G loss: 1.176686]\n",
      "[Epoch 2/30] [Batch 315/938] [D loss: 0.309966] [G loss: 1.817208]\n",
      "[Epoch 2/30] [Batch 316/938] [D loss: 0.329374] [G loss: 1.023446]\n",
      "[Epoch 2/30] [Batch 317/938] [D loss: 0.418206] [G loss: 1.916399]\n",
      "[Epoch 2/30] [Batch 318/938] [D loss: 0.527148] [G loss: 0.564304]\n",
      "[Epoch 2/30] [Batch 319/938] [D loss: 0.500387] [G loss: 2.462598]\n",
      "[Epoch 2/30] [Batch 320/938] [D loss: 0.559050] [G loss: 0.537278]\n",
      "[Epoch 2/30] [Batch 321/938] [D loss: 0.519680] [G loss: 2.607425]\n",
      "[Epoch 2/30] [Batch 322/938] [D loss: 0.496850] [G loss: 0.636718]\n",
      "[Epoch 2/30] [Batch 323/938] [D loss: 0.357986] [G loss: 2.092471]\n",
      "[Epoch 2/30] [Batch 324/938] [D loss: 0.373053] [G loss: 1.061468]\n",
      "[Epoch 2/30] [Batch 325/938] [D loss: 0.315854] [G loss: 1.423087]\n",
      "[Epoch 2/30] [Batch 326/938] [D loss: 0.314763] [G loss: 1.469739]\n",
      "[Epoch 2/30] [Batch 327/938] [D loss: 0.348017] [G loss: 1.110179]\n",
      "[Epoch 2/30] [Batch 328/938] [D loss: 0.372744] [G loss: 1.579275]\n",
      "[Epoch 2/30] [Batch 329/938] [D loss: 0.381575] [G loss: 0.840645]\n",
      "[Epoch 2/30] [Batch 330/938] [D loss: 0.517087] [G loss: 2.370883]\n",
      "[Epoch 2/30] [Batch 331/938] [D loss: 0.744881] [G loss: 0.312778]\n",
      "[Epoch 2/30] [Batch 332/938] [D loss: 0.589386] [G loss: 3.093271]\n",
      "[Epoch 2/30] [Batch 333/938] [D loss: 0.414119] [G loss: 0.707479]\n",
      "[Epoch 2/30] [Batch 334/938] [D loss: 0.277650] [G loss: 1.856575]\n",
      "[Epoch 2/30] [Batch 335/938] [D loss: 0.317705] [G loss: 1.545425]\n",
      "[Epoch 2/30] [Batch 336/938] [D loss: 0.310989] [G loss: 1.013501]\n",
      "[Epoch 2/30] [Batch 337/938] [D loss: 0.392917] [G loss: 2.047364]\n",
      "[Epoch 2/30] [Batch 338/938] [D loss: 0.453777] [G loss: 0.605509]\n",
      "[Epoch 2/30] [Batch 339/938] [D loss: 0.582014] [G loss: 2.594235]\n",
      "[Epoch 2/30] [Batch 340/938] [D loss: 0.642287] [G loss: 0.385730]\n",
      "[Epoch 2/30] [Batch 341/938] [D loss: 0.567378] [G loss: 2.672348]\n",
      "[Epoch 2/30] [Batch 342/938] [D loss: 0.494552] [G loss: 0.586466]\n",
      "[Epoch 2/30] [Batch 343/938] [D loss: 0.381846] [G loss: 2.147159]\n",
      "[Epoch 2/30] [Batch 344/938] [D loss: 0.373208] [G loss: 0.977574]\n",
      "[Epoch 2/30] [Batch 345/938] [D loss: 0.312621] [G loss: 1.493544]\n",
      "[Epoch 2/30] [Batch 346/938] [D loss: 0.398921] [G loss: 1.240598]\n",
      "[Epoch 2/30] [Batch 347/938] [D loss: 0.418890] [G loss: 0.950965]\n",
      "[Epoch 2/30] [Batch 348/938] [D loss: 0.444995] [G loss: 1.450421]\n",
      "[Epoch 2/30] [Batch 349/938] [D loss: 0.499922] [G loss: 0.735088]\n",
      "[Epoch 2/30] [Batch 350/938] [D loss: 0.491387] [G loss: 1.671346]\n",
      "[Epoch 2/30] [Batch 351/938] [D loss: 0.532950] [G loss: 0.580932]\n",
      "[Epoch 2/30] [Batch 352/938] [D loss: 0.590454] [G loss: 2.416753]\n",
      "[Epoch 2/30] [Batch 353/938] [D loss: 0.695272] [G loss: 0.376065]\n",
      "[Epoch 2/30] [Batch 354/938] [D loss: 0.546073] [G loss: 2.530251]\n",
      "[Epoch 2/30] [Batch 355/938] [D loss: 0.499033] [G loss: 0.581199]\n",
      "[Epoch 2/30] [Batch 356/938] [D loss: 0.375601] [G loss: 2.222070]\n",
      "[Epoch 2/30] [Batch 357/938] [D loss: 0.365784] [G loss: 1.073741]\n",
      "[Epoch 2/30] [Batch 358/938] [D loss: 0.344339] [G loss: 1.167024]\n",
      "[Epoch 2/30] [Batch 359/938] [D loss: 0.340586] [G loss: 1.681073]\n",
      "[Epoch 2/30] [Batch 360/938] [D loss: 0.372894] [G loss: 0.976275]\n",
      "[Epoch 2/30] [Batch 361/938] [D loss: 0.525191] [G loss: 1.959518]\n",
      "[Epoch 2/30] [Batch 362/938] [D loss: 0.698287] [G loss: 0.359919]\n",
      "[Epoch 2/30] [Batch 363/938] [D loss: 0.691848] [G loss: 2.866139]\n",
      "[Epoch 2/30] [Batch 364/938] [D loss: 0.548704] [G loss: 0.518539]\n",
      "[Epoch 2/30] [Batch 365/938] [D loss: 0.381795] [G loss: 2.321030]\n",
      "[Epoch 2/30] [Batch 366/938] [D loss: 0.306382] [G loss: 1.153763]\n",
      "[Epoch 2/30] [Batch 367/938] [D loss: 0.295770] [G loss: 1.443144]\n",
      "[Epoch 2/30] [Batch 368/938] [D loss: 0.327115] [G loss: 1.525023]\n",
      "[Epoch 2/30] [Batch 369/938] [D loss: 0.287200] [G loss: 1.330576]\n",
      "[Epoch 2/30] [Batch 370/938] [D loss: 0.295550] [G loss: 1.476153]\n",
      "[Epoch 2/30] [Batch 371/938] [D loss: 0.377228] [G loss: 1.439457]\n",
      "[Epoch 2/30] [Batch 372/938] [D loss: 0.399570] [G loss: 0.858982]\n",
      "[Epoch 2/30] [Batch 373/938] [D loss: 0.415457] [G loss: 2.319846]\n",
      "[Epoch 2/30] [Batch 374/938] [D loss: 0.480675] [G loss: 0.616621]\n",
      "[Epoch 2/30] [Batch 375/938] [D loss: 0.454934] [G loss: 2.592719]\n",
      "[Epoch 2/30] [Batch 376/938] [D loss: 0.410166] [G loss: 0.792042]\n",
      "[Epoch 2/30] [Batch 377/938] [D loss: 0.326272] [G loss: 2.124030]\n",
      "[Epoch 2/30] [Batch 378/938] [D loss: 0.318139] [G loss: 1.098943]\n",
      "[Epoch 2/30] [Batch 379/938] [D loss: 0.323797] [G loss: 1.674350]\n",
      "[Epoch 2/30] [Batch 380/938] [D loss: 0.344652] [G loss: 1.151874]\n",
      "[Epoch 2/30] [Batch 381/938] [D loss: 0.366102] [G loss: 1.517007]\n",
      "[Epoch 2/30] [Batch 382/938] [D loss: 0.385389] [G loss: 1.036209]\n",
      "[Epoch 2/30] [Batch 383/938] [D loss: 0.372450] [G loss: 1.702249]\n",
      "[Epoch 2/30] [Batch 384/938] [D loss: 0.402046] [G loss: 0.928927]\n",
      "[Epoch 2/30] [Batch 385/938] [D loss: 0.324801] [G loss: 1.850022]\n",
      "[Epoch 2/30] [Batch 386/938] [D loss: 0.381987] [G loss: 0.998275]\n",
      "[Epoch 2/30] [Batch 387/938] [D loss: 0.320031] [G loss: 1.528242]\n",
      "[Epoch 2/30] [Batch 388/938] [D loss: 0.344053] [G loss: 1.259855]\n",
      "[Epoch 2/30] [Batch 389/938] [D loss: 0.368468] [G loss: 1.211982]\n",
      "[Epoch 2/30] [Batch 390/938] [D loss: 0.386691] [G loss: 1.359901]\n",
      "[Epoch 2/30] [Batch 391/938] [D loss: 0.381077] [G loss: 0.987031]\n",
      "[Epoch 2/30] [Batch 392/938] [D loss: 0.377706] [G loss: 1.819868]\n",
      "[Epoch 2/30] [Batch 393/938] [D loss: 0.428964] [G loss: 0.702202]\n",
      "[Epoch 2/30] [Batch 394/938] [D loss: 0.551239] [G loss: 2.508082]\n",
      "[Epoch 2/30] [Batch 395/938] [D loss: 0.724266] [G loss: 0.303211]\n",
      "[Epoch 2/30] [Batch 396/938] [D loss: 0.698396] [G loss: 3.308297]\n",
      "[Epoch 2/30] [Batch 397/938] [D loss: 0.468408] [G loss: 0.672495]\n",
      "[Epoch 2/30] [Batch 398/938] [D loss: 0.314472] [G loss: 1.699179]\n",
      "[Epoch 2/30] [Batch 399/938] [D loss: 0.317347] [G loss: 1.546712]\n",
      "[Epoch 2/30] [Batch 400/938] [D loss: 0.368690] [G loss: 1.035767]\n",
      "[Epoch 2/30] [Batch 401/938] [D loss: 0.366675] [G loss: 1.582159]\n",
      "[Epoch 2/30] [Batch 402/938] [D loss: 0.411669] [G loss: 0.888628]\n",
      "[Epoch 2/30] [Batch 403/938] [D loss: 0.401956] [G loss: 1.627970]\n",
      "[Epoch 2/30] [Batch 404/938] [D loss: 0.463180] [G loss: 0.777667]\n",
      "[Epoch 2/30] [Batch 405/938] [D loss: 0.474367] [G loss: 1.897660]\n",
      "[Epoch 2/30] [Batch 406/938] [D loss: 0.563464] [G loss: 0.538891]\n",
      "[Epoch 2/30] [Batch 407/938] [D loss: 0.502085] [G loss: 2.378034]\n",
      "[Epoch 2/30] [Batch 408/938] [D loss: 0.507872] [G loss: 0.642720]\n",
      "[Epoch 2/30] [Batch 409/938] [D loss: 0.424519] [G loss: 1.722714]\n",
      "[Epoch 2/30] [Batch 410/938] [D loss: 0.391718] [G loss: 0.808564]\n",
      "[Epoch 2/30] [Batch 411/938] [D loss: 0.416778] [G loss: 2.227378]\n",
      "[Epoch 2/30] [Batch 412/938] [D loss: 0.407151] [G loss: 0.744324]\n",
      "[Epoch 2/30] [Batch 413/938] [D loss: 0.373608] [G loss: 2.152267]\n",
      "[Epoch 2/30] [Batch 414/938] [D loss: 0.372455] [G loss: 0.911890]\n",
      "[Epoch 2/30] [Batch 415/938] [D loss: 0.383195] [G loss: 1.679834]\n",
      "[Epoch 2/30] [Batch 416/938] [D loss: 0.415214] [G loss: 0.814298]\n",
      "[Epoch 2/30] [Batch 417/938] [D loss: 0.367209] [G loss: 2.028386]\n",
      "[Epoch 2/30] [Batch 418/938] [D loss: 0.375095] [G loss: 0.909014]\n",
      "[Epoch 2/30] [Batch 419/938] [D loss: 0.381572] [G loss: 1.788393]\n",
      "[Epoch 2/30] [Batch 420/938] [D loss: 0.397838] [G loss: 0.970924]\n",
      "[Epoch 2/30] [Batch 421/938] [D loss: 0.395065] [G loss: 1.412167]\n",
      "[Epoch 2/30] [Batch 422/938] [D loss: 0.374700] [G loss: 1.172412]\n",
      "[Epoch 2/30] [Batch 423/938] [D loss: 0.384107] [G loss: 1.285455]\n",
      "[Epoch 2/30] [Batch 424/938] [D loss: 0.412781] [G loss: 1.194267]\n",
      "[Epoch 2/30] [Batch 425/938] [D loss: 0.349513] [G loss: 1.217071]\n",
      "[Epoch 2/30] [Batch 426/938] [D loss: 0.330626] [G loss: 1.361619]\n",
      "[Epoch 2/30] [Batch 427/938] [D loss: 0.376533] [G loss: 1.467805]\n",
      "[Epoch 2/30] [Batch 428/938] [D loss: 0.438029] [G loss: 0.774094]\n",
      "[Epoch 2/30] [Batch 429/938] [D loss: 0.456674] [G loss: 2.355445]\n",
      "[Epoch 2/30] [Batch 430/938] [D loss: 0.542230] [G loss: 0.538394]\n",
      "[Epoch 2/30] [Batch 431/938] [D loss: 0.416935] [G loss: 2.351758]\n",
      "[Epoch 2/30] [Batch 432/938] [D loss: 0.362638] [G loss: 0.866387]\n",
      "[Epoch 2/30] [Batch 433/938] [D loss: 0.367683] [G loss: 1.900255]\n",
      "[Epoch 2/30] [Batch 434/938] [D loss: 0.377838] [G loss: 0.962804]\n",
      "[Epoch 2/30] [Batch 435/938] [D loss: 0.297325] [G loss: 1.730179]\n",
      "[Epoch 2/30] [Batch 436/938] [D loss: 0.328872] [G loss: 1.145550]\n",
      "[Epoch 2/30] [Batch 437/938] [D loss: 0.293523] [G loss: 1.641898]\n",
      "[Epoch 2/30] [Batch 438/938] [D loss: 0.346356] [G loss: 1.207675]\n",
      "[Epoch 2/30] [Batch 439/938] [D loss: 0.420718] [G loss: 1.305618]\n",
      "[Epoch 2/30] [Batch 440/938] [D loss: 0.392685] [G loss: 0.948707]\n",
      "[Epoch 2/30] [Batch 441/938] [D loss: 0.406635] [G loss: 1.884604]\n",
      "[Epoch 2/30] [Batch 442/938] [D loss: 0.480378] [G loss: 0.614393]\n",
      "[Epoch 2/30] [Batch 443/938] [D loss: 0.584786] [G loss: 2.568579]\n",
      "[Epoch 2/30] [Batch 444/938] [D loss: 0.612256] [G loss: 0.412966]\n",
      "[Epoch 2/30] [Batch 445/938] [D loss: 0.636132] [G loss: 2.667945]\n",
      "[Epoch 2/30] [Batch 446/938] [D loss: 0.564274] [G loss: 0.504289]\n",
      "[Epoch 2/30] [Batch 447/938] [D loss: 0.387721] [G loss: 2.381107]\n",
      "[Epoch 2/30] [Batch 448/938] [D loss: 0.355657] [G loss: 1.151823]\n",
      "[Epoch 2/30] [Batch 449/938] [D loss: 0.346711] [G loss: 1.323837]\n",
      "[Epoch 2/30] [Batch 450/938] [D loss: 0.364715] [G loss: 1.607499]\n",
      "[Epoch 2/30] [Batch 451/938] [D loss: 0.404378] [G loss: 1.083467]\n",
      "[Epoch 2/30] [Batch 452/938] [D loss: 0.399433] [G loss: 1.507828]\n",
      "[Epoch 2/30] [Batch 453/938] [D loss: 0.440347] [G loss: 1.040581]\n",
      "[Epoch 2/30] [Batch 454/938] [D loss: 0.423645] [G loss: 1.286111]\n",
      "[Epoch 2/30] [Batch 455/938] [D loss: 0.469158] [G loss: 1.255337]\n",
      "[Epoch 2/30] [Batch 456/938] [D loss: 0.492422] [G loss: 0.778650]\n",
      "[Epoch 2/30] [Batch 457/938] [D loss: 0.476350] [G loss: 2.084080]\n",
      "[Epoch 2/30] [Batch 458/938] [D loss: 0.511668] [G loss: 0.634007]\n",
      "[Epoch 2/30] [Batch 459/938] [D loss: 0.520030] [G loss: 2.009869]\n",
      "[Epoch 2/30] [Batch 460/938] [D loss: 0.521279] [G loss: 0.590007]\n",
      "[Epoch 2/30] [Batch 461/938] [D loss: 0.580768] [G loss: 2.254328]\n",
      "[Epoch 2/30] [Batch 462/938] [D loss: 0.512625] [G loss: 0.591428]\n",
      "[Epoch 2/30] [Batch 463/938] [D loss: 0.445543] [G loss: 2.153892]\n",
      "[Epoch 2/30] [Batch 464/938] [D loss: 0.380352] [G loss: 0.822479]\n",
      "[Epoch 2/30] [Batch 465/938] [D loss: 0.327523] [G loss: 2.007033]\n",
      "[Epoch 2/30] [Batch 466/938] [D loss: 0.286442] [G loss: 1.293278]\n",
      "[Epoch 2/30] [Batch 467/938] [D loss: 0.332340] [G loss: 1.487187]\n",
      "[Epoch 2/30] [Batch 468/938] [D loss: 0.345338] [G loss: 1.132433]\n",
      "[Epoch 2/30] [Batch 469/938] [D loss: 0.330500] [G loss: 1.461405]\n",
      "[Epoch 2/30] [Batch 470/938] [D loss: 0.337162] [G loss: 1.304560]\n",
      "[Epoch 2/30] [Batch 471/938] [D loss: 0.400701] [G loss: 1.203744]\n",
      "[Epoch 2/30] [Batch 472/938] [D loss: 0.373948] [G loss: 1.145968]\n",
      "[Epoch 2/30] [Batch 473/938] [D loss: 0.399043] [G loss: 1.466018]\n",
      "[Epoch 2/30] [Batch 474/938] [D loss: 0.457445] [G loss: 0.781262]\n",
      "[Epoch 2/30] [Batch 475/938] [D loss: 0.415069] [G loss: 1.955738]\n",
      "[Epoch 2/30] [Batch 476/938] [D loss: 0.427429] [G loss: 0.732828]\n",
      "[Epoch 2/30] [Batch 477/938] [D loss: 0.408054] [G loss: 2.104769]\n",
      "[Epoch 2/30] [Batch 478/938] [D loss: 0.413259] [G loss: 0.751304]\n",
      "[Epoch 2/30] [Batch 479/938] [D loss: 0.366356] [G loss: 1.999945]\n",
      "[Epoch 2/30] [Batch 480/938] [D loss: 0.350574] [G loss: 1.201731]\n",
      "[Epoch 2/30] [Batch 481/938] [D loss: 0.357559] [G loss: 1.088273]\n",
      "[Epoch 2/30] [Batch 482/938] [D loss: 0.377070] [G loss: 1.671780]\n",
      "[Epoch 2/30] [Batch 483/938] [D loss: 0.400183] [G loss: 0.879706]\n",
      "[Epoch 2/30] [Batch 484/938] [D loss: 0.402840] [G loss: 1.785369]\n",
      "[Epoch 2/30] [Batch 485/938] [D loss: 0.469275] [G loss: 0.786858]\n",
      "[Epoch 2/30] [Batch 486/938] [D loss: 0.438519] [G loss: 1.619215]\n",
      "[Epoch 2/30] [Batch 487/938] [D loss: 0.425567] [G loss: 0.878890]\n",
      "[Epoch 2/30] [Batch 488/938] [D loss: 0.380034] [G loss: 1.572230]\n",
      "[Epoch 2/30] [Batch 489/938] [D loss: 0.370450] [G loss: 1.167598]\n",
      "[Epoch 2/30] [Batch 490/938] [D loss: 0.370228] [G loss: 1.196867]\n",
      "[Epoch 2/30] [Batch 491/938] [D loss: 0.326672] [G loss: 1.175397]\n",
      "[Epoch 2/30] [Batch 492/938] [D loss: 0.374672] [G loss: 1.603787]\n",
      "[Epoch 2/30] [Batch 493/938] [D loss: 0.389759] [G loss: 0.883767]\n",
      "[Epoch 2/30] [Batch 494/938] [D loss: 0.452191] [G loss: 1.858978]\n",
      "[Epoch 2/30] [Batch 495/938] [D loss: 0.501026] [G loss: 0.587640]\n",
      "[Epoch 2/30] [Batch 496/938] [D loss: 0.471610] [G loss: 2.123561]\n",
      "[Epoch 2/30] [Batch 497/938] [D loss: 0.431318] [G loss: 0.757008]\n",
      "[Epoch 2/30] [Batch 498/938] [D loss: 0.397560] [G loss: 1.827509]\n",
      "[Epoch 2/30] [Batch 499/938] [D loss: 0.341930] [G loss: 0.920313]\n",
      "[Epoch 2/30] [Batch 500/938] [D loss: 0.401147] [G loss: 1.914152]\n",
      "[Epoch 2/30] [Batch 501/938] [D loss: 0.394588] [G loss: 0.836829]\n",
      "[Epoch 2/30] [Batch 502/938] [D loss: 0.403175] [G loss: 1.871631]\n",
      "[Epoch 2/30] [Batch 503/938] [D loss: 0.447561] [G loss: 0.786084]\n",
      "[Epoch 2/30] [Batch 504/938] [D loss: 0.341914] [G loss: 1.609028]\n",
      "[Epoch 2/30] [Batch 505/938] [D loss: 0.380107] [G loss: 1.328514]\n",
      "[Epoch 2/30] [Batch 506/938] [D loss: 0.367923] [G loss: 0.948382]\n",
      "[Epoch 2/30] [Batch 507/938] [D loss: 0.364261] [G loss: 1.832998]\n",
      "[Epoch 2/30] [Batch 508/938] [D loss: 0.407092] [G loss: 0.871921]\n",
      "[Epoch 2/30] [Batch 509/938] [D loss: 0.312923] [G loss: 1.639142]\n",
      "[Epoch 2/30] [Batch 510/938] [D loss: 0.322207] [G loss: 1.420022]\n",
      "[Epoch 2/30] [Batch 511/938] [D loss: 0.314296] [G loss: 1.163882]\n",
      "[Epoch 2/30] [Batch 512/938] [D loss: 0.416719] [G loss: 1.660248]\n",
      "[Epoch 2/30] [Batch 513/938] [D loss: 0.451804] [G loss: 0.663934]\n",
      "[Epoch 2/30] [Batch 514/938] [D loss: 0.581934] [G loss: 2.231420]\n",
      "[Epoch 2/30] [Batch 515/938] [D loss: 0.616661] [G loss: 0.453362]\n",
      "[Epoch 2/30] [Batch 516/938] [D loss: 0.396963] [G loss: 2.266279]\n",
      "[Epoch 2/30] [Batch 517/938] [D loss: 0.350597] [G loss: 1.098095]\n",
      "[Epoch 2/30] [Batch 518/938] [D loss: 0.339024] [G loss: 1.136831]\n",
      "[Epoch 2/30] [Batch 519/938] [D loss: 0.347018] [G loss: 1.633429]\n",
      "[Epoch 2/30] [Batch 520/938] [D loss: 0.365312] [G loss: 0.944294]\n",
      "[Epoch 2/30] [Batch 521/938] [D loss: 0.325602] [G loss: 1.695601]\n",
      "[Epoch 2/30] [Batch 522/938] [D loss: 0.401474] [G loss: 0.946288]\n",
      "[Epoch 2/30] [Batch 523/938] [D loss: 0.384409] [G loss: 1.422158]\n",
      "[Epoch 2/30] [Batch 524/938] [D loss: 0.449927] [G loss: 0.912546]\n",
      "[Epoch 2/30] [Batch 525/938] [D loss: 0.400429] [G loss: 1.304855]\n",
      "[Epoch 2/30] [Batch 526/938] [D loss: 0.380747] [G loss: 1.041476]\n",
      "[Epoch 2/30] [Batch 527/938] [D loss: 0.372212] [G loss: 1.457752]\n",
      "[Epoch 2/30] [Batch 528/938] [D loss: 0.429481] [G loss: 0.952279]\n",
      "[Epoch 2/30] [Batch 529/938] [D loss: 0.397743] [G loss: 1.450999]\n",
      "[Epoch 2/30] [Batch 530/938] [D loss: 0.419807] [G loss: 0.903889]\n",
      "[Epoch 2/30] [Batch 531/938] [D loss: 0.405093] [G loss: 1.465787]\n",
      "[Epoch 2/30] [Batch 532/938] [D loss: 0.395324] [G loss: 0.884340]\n",
      "[Epoch 2/30] [Batch 533/938] [D loss: 0.360724] [G loss: 1.935451]\n",
      "[Epoch 2/30] [Batch 534/938] [D loss: 0.413730] [G loss: 0.798038]\n",
      "[Epoch 2/30] [Batch 535/938] [D loss: 0.394048] [G loss: 1.922329]\n",
      "[Epoch 2/30] [Batch 536/938] [D loss: 0.385175] [G loss: 0.849301]\n",
      "[Epoch 2/30] [Batch 537/938] [D loss: 0.360454] [G loss: 1.904868]\n",
      "[Epoch 2/30] [Batch 538/938] [D loss: 0.387396] [G loss: 0.893168]\n",
      "[Epoch 2/30] [Batch 539/938] [D loss: 0.315643] [G loss: 1.684587]\n",
      "[Epoch 2/30] [Batch 540/938] [D loss: 0.352818] [G loss: 1.198415]\n",
      "[Epoch 2/30] [Batch 541/938] [D loss: 0.360107] [G loss: 1.105938]\n",
      "[Epoch 2/30] [Batch 542/938] [D loss: 0.383253] [G loss: 1.587011]\n",
      "[Epoch 2/30] [Batch 543/938] [D loss: 0.426477] [G loss: 0.706874]\n",
      "[Epoch 2/30] [Batch 544/938] [D loss: 0.487114] [G loss: 2.429514]\n",
      "[Epoch 2/30] [Batch 545/938] [D loss: 0.464547] [G loss: 0.620999]\n",
      "[Epoch 2/30] [Batch 546/938] [D loss: 0.383803] [G loss: 2.217499]\n",
      "[Epoch 2/30] [Batch 547/938] [D loss: 0.381702] [G loss: 0.921041]\n",
      "[Epoch 2/30] [Batch 548/938] [D loss: 0.333663] [G loss: 1.562295]\n",
      "[Epoch 2/30] [Batch 549/938] [D loss: 0.364532] [G loss: 1.115897]\n",
      "[Epoch 2/30] [Batch 550/938] [D loss: 0.344039] [G loss: 1.479435]\n",
      "[Epoch 2/30] [Batch 551/938] [D loss: 0.350134] [G loss: 1.066305]\n",
      "[Epoch 2/30] [Batch 552/938] [D loss: 0.385015] [G loss: 1.692840]\n",
      "[Epoch 2/30] [Batch 553/938] [D loss: 0.359377] [G loss: 0.935452]\n",
      "[Epoch 2/30] [Batch 554/938] [D loss: 0.391792] [G loss: 1.877483]\n",
      "[Epoch 2/30] [Batch 555/938] [D loss: 0.391626] [G loss: 0.772764]\n",
      "[Epoch 2/30] [Batch 556/938] [D loss: 0.453591] [G loss: 2.394633]\n",
      "[Epoch 2/30] [Batch 557/938] [D loss: 0.349097] [G loss: 0.884989]\n",
      "[Epoch 2/30] [Batch 558/938] [D loss: 0.337515] [G loss: 1.777468]\n",
      "[Epoch 2/30] [Batch 559/938] [D loss: 0.336353] [G loss: 1.230826]\n",
      "[Epoch 2/30] [Batch 560/938] [D loss: 0.326902] [G loss: 1.184342]\n",
      "[Epoch 2/30] [Batch 561/938] [D loss: 0.334580] [G loss: 1.715957]\n",
      "[Epoch 2/30] [Batch 562/938] [D loss: 0.396936] [G loss: 1.006501]\n",
      "[Epoch 2/30] [Batch 563/938] [D loss: 0.317954] [G loss: 1.429262]\n",
      "[Epoch 2/30] [Batch 564/938] [D loss: 0.376936] [G loss: 1.469893]\n",
      "[Epoch 2/30] [Batch 565/938] [D loss: 0.454313] [G loss: 0.867337]\n",
      "[Epoch 2/30] [Batch 566/938] [D loss: 0.325293] [G loss: 1.730862]\n",
      "[Epoch 2/30] [Batch 567/938] [D loss: 0.388042] [G loss: 1.084927]\n",
      "[Epoch 2/30] [Batch 568/938] [D loss: 0.396562] [G loss: 1.370351]\n",
      "[Epoch 2/30] [Batch 569/938] [D loss: 0.377800] [G loss: 0.935947]\n",
      "[Epoch 2/30] [Batch 570/938] [D loss: 0.441137] [G loss: 2.168066]\n",
      "[Epoch 2/30] [Batch 571/938] [D loss: 0.541550] [G loss: 0.504083]\n",
      "[Epoch 2/30] [Batch 572/938] [D loss: 0.485274] [G loss: 3.027692]\n",
      "[Epoch 2/30] [Batch 573/938] [D loss: 0.412803] [G loss: 0.798908]\n",
      "[Epoch 2/30] [Batch 574/938] [D loss: 0.348189] [G loss: 1.715608]\n",
      "[Epoch 2/30] [Batch 575/938] [D loss: 0.402261] [G loss: 1.122463]\n",
      "[Epoch 2/30] [Batch 576/938] [D loss: 0.356636] [G loss: 1.189274]\n",
      "[Epoch 2/30] [Batch 577/938] [D loss: 0.367098] [G loss: 1.507128]\n",
      "[Epoch 2/30] [Batch 578/938] [D loss: 0.413176] [G loss: 1.024509]\n",
      "[Epoch 2/30] [Batch 579/938] [D loss: 0.355379] [G loss: 1.376609]\n",
      "[Epoch 2/30] [Batch 580/938] [D loss: 0.380249] [G loss: 1.403689]\n",
      "[Epoch 2/30] [Batch 581/938] [D loss: 0.421479] [G loss: 0.936480]\n",
      "[Epoch 2/30] [Batch 582/938] [D loss: 0.520718] [G loss: 1.880284]\n",
      "[Epoch 2/30] [Batch 583/938] [D loss: 0.712859] [G loss: 0.385151]\n",
      "[Epoch 2/30] [Batch 584/938] [D loss: 0.811199] [G loss: 3.015264]\n",
      "[Epoch 2/30] [Batch 585/938] [D loss: 0.843711] [G loss: 0.250525]\n",
      "[Epoch 2/30] [Batch 586/938] [D loss: 0.764559] [G loss: 3.004131]\n",
      "[Epoch 2/30] [Batch 587/938] [D loss: 0.554227] [G loss: 0.509749]\n",
      "[Epoch 2/30] [Batch 588/938] [D loss: 0.379150] [G loss: 2.267631]\n",
      "[Epoch 2/30] [Batch 589/938] [D loss: 0.354939] [G loss: 1.323119]\n",
      "[Epoch 2/30] [Batch 590/938] [D loss: 0.422579] [G loss: 0.832317]\n",
      "[Epoch 2/30] [Batch 591/938] [D loss: 0.393560] [G loss: 2.002449]\n",
      "[Epoch 2/30] [Batch 592/938] [D loss: 0.447234] [G loss: 0.750854]\n",
      "[Epoch 2/30] [Batch 593/938] [D loss: 0.421630] [G loss: 1.819746]\n",
      "[Epoch 2/30] [Batch 594/938] [D loss: 0.434633] [G loss: 0.841350]\n",
      "[Epoch 2/30] [Batch 595/938] [D loss: 0.402827] [G loss: 1.582358]\n",
      "[Epoch 2/30] [Batch 596/938] [D loss: 0.452381] [G loss: 0.855207]\n",
      "[Epoch 2/30] [Batch 597/938] [D loss: 0.439967] [G loss: 1.627059]\n",
      "[Epoch 2/30] [Batch 598/938] [D loss: 0.507815] [G loss: 0.662027]\n",
      "[Epoch 2/30] [Batch 599/938] [D loss: 0.518847] [G loss: 2.150390]\n",
      "[Epoch 2/30] [Batch 600/938] [D loss: 0.552593] [G loss: 0.497806]\n",
      "[Epoch 2/30] [Batch 601/938] [D loss: 0.674530] [G loss: 2.532907]\n",
      "[Epoch 2/30] [Batch 602/938] [D loss: 0.586686] [G loss: 0.453947]\n",
      "[Epoch 2/30] [Batch 603/938] [D loss: 0.474678] [G loss: 2.338788]\n",
      "[Epoch 2/30] [Batch 604/938] [D loss: 0.385649] [G loss: 0.872414]\n",
      "[Epoch 2/30] [Batch 605/938] [D loss: 0.350535] [G loss: 1.513080]\n",
      "[Epoch 2/30] [Batch 606/938] [D loss: 0.373348] [G loss: 1.344271]\n",
      "[Epoch 2/30] [Batch 607/938] [D loss: 0.466127] [G loss: 0.955423]\n",
      "[Epoch 2/30] [Batch 608/938] [D loss: 0.418653] [G loss: 1.701290]\n",
      "[Epoch 2/30] [Batch 609/938] [D loss: 0.447044] [G loss: 0.732006]\n",
      "[Epoch 2/30] [Batch 610/938] [D loss: 0.506653] [G loss: 2.095681]\n",
      "[Epoch 2/30] [Batch 611/938] [D loss: 0.595012] [G loss: 0.534119]\n",
      "[Epoch 2/30] [Batch 612/938] [D loss: 0.405089] [G loss: 2.093999]\n",
      "[Epoch 2/30] [Batch 613/938] [D loss: 0.395036] [G loss: 1.028601]\n",
      "[Epoch 2/30] [Batch 614/938] [D loss: 0.386276] [G loss: 1.275500]\n",
      "[Epoch 2/30] [Batch 615/938] [D loss: 0.411446] [G loss: 1.175369]\n",
      "[Epoch 2/30] [Batch 616/938] [D loss: 0.368993] [G loss: 1.232506]\n",
      "[Epoch 2/30] [Batch 617/938] [D loss: 0.419941] [G loss: 1.274644]\n",
      "[Epoch 2/30] [Batch 618/938] [D loss: 0.439414] [G loss: 1.102650]\n",
      "[Epoch 2/30] [Batch 619/938] [D loss: 0.397742] [G loss: 1.028471]\n",
      "[Epoch 2/30] [Batch 620/938] [D loss: 0.355831] [G loss: 1.649247]\n",
      "[Epoch 2/30] [Batch 621/938] [D loss: 0.366996] [G loss: 1.043991]\n",
      "[Epoch 2/30] [Batch 622/938] [D loss: 0.355079] [G loss: 1.464100]\n",
      "[Epoch 2/30] [Batch 623/938] [D loss: 0.311247] [G loss: 1.226969]\n",
      "[Epoch 2/30] [Batch 624/938] [D loss: 0.378784] [G loss: 1.572365]\n",
      "[Epoch 2/30] [Batch 625/938] [D loss: 0.399428] [G loss: 0.959526]\n",
      "[Epoch 2/30] [Batch 626/938] [D loss: 0.334104] [G loss: 1.795739]\n",
      "[Epoch 2/30] [Batch 627/938] [D loss: 0.318741] [G loss: 1.063449]\n",
      "[Epoch 2/30] [Batch 628/938] [D loss: 0.307043] [G loss: 1.748247]\n",
      "[Epoch 2/30] [Batch 629/938] [D loss: 0.346840] [G loss: 1.274378]\n",
      "[Epoch 2/30] [Batch 630/938] [D loss: 0.352945] [G loss: 1.124242]\n",
      "[Epoch 2/30] [Batch 631/938] [D loss: 0.366458] [G loss: 1.658564]\n",
      "[Epoch 2/30] [Batch 632/938] [D loss: 0.390300] [G loss: 0.934213]\n",
      "[Epoch 2/30] [Batch 633/938] [D loss: 0.371027] [G loss: 1.887407]\n",
      "[Epoch 2/30] [Batch 634/938] [D loss: 0.453420] [G loss: 0.832690]\n",
      "[Epoch 2/30] [Batch 635/938] [D loss: 0.359332] [G loss: 1.745872]\n",
      "[Epoch 2/30] [Batch 636/938] [D loss: 0.410459] [G loss: 0.828133]\n",
      "[Epoch 2/30] [Batch 637/938] [D loss: 0.443938] [G loss: 2.258053]\n",
      "[Epoch 2/30] [Batch 638/938] [D loss: 0.531152] [G loss: 0.595311]\n",
      "[Epoch 2/30] [Batch 639/938] [D loss: 0.412534] [G loss: 2.394211]\n",
      "[Epoch 2/30] [Batch 640/938] [D loss: 0.434788] [G loss: 0.751570]\n",
      "[Epoch 2/30] [Batch 641/938] [D loss: 0.387780] [G loss: 1.984743]\n",
      "[Epoch 2/30] [Batch 642/938] [D loss: 0.416094] [G loss: 0.809811]\n",
      "[Epoch 2/30] [Batch 643/938] [D loss: 0.505888] [G loss: 2.091711]\n",
      "[Epoch 2/30] [Batch 644/938] [D loss: 0.580110] [G loss: 0.507694]\n",
      "[Epoch 2/30] [Batch 645/938] [D loss: 0.587259] [G loss: 2.568574]\n",
      "[Epoch 2/30] [Batch 646/938] [D loss: 0.647699] [G loss: 0.389219]\n",
      "[Epoch 2/30] [Batch 647/938] [D loss: 0.537076] [G loss: 2.559451]\n",
      "[Epoch 2/30] [Batch 648/938] [D loss: 0.468861] [G loss: 0.622565]\n",
      "[Epoch 2/30] [Batch 649/938] [D loss: 0.409281] [G loss: 2.145191]\n",
      "[Epoch 2/30] [Batch 650/938] [D loss: 0.409664] [G loss: 0.805564]\n",
      "[Epoch 2/30] [Batch 651/938] [D loss: 0.399190] [G loss: 1.827784]\n",
      "[Epoch 2/30] [Batch 652/938] [D loss: 0.456251] [G loss: 0.739336]\n",
      "[Epoch 2/30] [Batch 653/938] [D loss: 0.429017] [G loss: 1.782188]\n",
      "[Epoch 2/30] [Batch 654/938] [D loss: 0.446401] [G loss: 0.751016]\n",
      "[Epoch 2/30] [Batch 655/938] [D loss: 0.412587] [G loss: 1.848868]\n",
      "[Epoch 2/30] [Batch 656/938] [D loss: 0.457715] [G loss: 0.808608]\n",
      "[Epoch 2/30] [Batch 657/938] [D loss: 0.380053] [G loss: 1.399869]\n",
      "[Epoch 2/30] [Batch 658/938] [D loss: 0.350194] [G loss: 1.121177]\n",
      "[Epoch 2/30] [Batch 659/938] [D loss: 0.326587] [G loss: 1.557050]\n",
      "[Epoch 2/30] [Batch 660/938] [D loss: 0.355243] [G loss: 1.031632]\n",
      "[Epoch 2/30] [Batch 661/938] [D loss: 0.416714] [G loss: 1.577813]\n",
      "[Epoch 2/30] [Batch 662/938] [D loss: 0.420197] [G loss: 0.785010]\n",
      "[Epoch 2/30] [Batch 663/938] [D loss: 0.385675] [G loss: 1.901035]\n",
      "[Epoch 2/30] [Batch 664/938] [D loss: 0.416333] [G loss: 0.824781]\n",
      "[Epoch 2/30] [Batch 665/938] [D loss: 0.355673] [G loss: 1.537781]\n",
      "[Epoch 2/30] [Batch 666/938] [D loss: 0.339745] [G loss: 1.121971]\n",
      "[Epoch 2/30] [Batch 667/938] [D loss: 0.375449] [G loss: 1.303567]\n",
      "[Epoch 2/30] [Batch 668/938] [D loss: 0.325261] [G loss: 1.221747]\n",
      "[Epoch 2/30] [Batch 669/938] [D loss: 0.363556] [G loss: 1.381322]\n",
      "[Epoch 2/30] [Batch 670/938] [D loss: 0.362011] [G loss: 1.062897]\n",
      "[Epoch 2/30] [Batch 671/938] [D loss: 0.373342] [G loss: 1.390539]\n",
      "[Epoch 2/30] [Batch 672/938] [D loss: 0.370795] [G loss: 0.937066]\n",
      "[Epoch 2/30] [Batch 673/938] [D loss: 0.378836] [G loss: 1.765239]\n",
      "[Epoch 2/30] [Batch 674/938] [D loss: 0.405784] [G loss: 0.812637]\n",
      "[Epoch 2/30] [Batch 675/938] [D loss: 0.429702] [G loss: 1.978601]\n",
      "[Epoch 2/30] [Batch 676/938] [D loss: 0.464774] [G loss: 0.724430]\n",
      "[Epoch 2/30] [Batch 677/938] [D loss: 0.358575] [G loss: 1.723869]\n",
      "[Epoch 2/30] [Batch 678/938] [D loss: 0.339935] [G loss: 1.115085]\n",
      "[Epoch 2/30] [Batch 679/938] [D loss: 0.338201] [G loss: 1.344862]\n",
      "[Epoch 2/30] [Batch 680/938] [D loss: 0.308406] [G loss: 1.370545]\n",
      "[Epoch 2/30] [Batch 681/938] [D loss: 0.350670] [G loss: 1.299497]\n",
      "[Epoch 2/30] [Batch 682/938] [D loss: 0.337133] [G loss: 1.241432]\n",
      "[Epoch 2/30] [Batch 683/938] [D loss: 0.327011] [G loss: 1.237453]\n",
      "[Epoch 2/30] [Batch 684/938] [D loss: 0.343064] [G loss: 1.393135]\n",
      "[Epoch 2/30] [Batch 685/938] [D loss: 0.412318] [G loss: 1.057108]\n",
      "[Epoch 2/30] [Batch 686/938] [D loss: 0.317485] [G loss: 1.287858]\n",
      "[Epoch 2/30] [Batch 687/938] [D loss: 0.352938] [G loss: 1.375009]\n",
      "[Epoch 2/30] [Batch 688/938] [D loss: 0.347106] [G loss: 1.072999]\n",
      "[Epoch 2/30] [Batch 689/938] [D loss: 0.294549] [G loss: 1.542067]\n",
      "[Epoch 2/30] [Batch 690/938] [D loss: 0.342920] [G loss: 1.363864]\n",
      "[Epoch 2/30] [Batch 691/938] [D loss: 0.334122] [G loss: 0.983937]\n",
      "[Epoch 2/30] [Batch 692/938] [D loss: 0.346467] [G loss: 2.049723]\n",
      "[Epoch 2/30] [Batch 693/938] [D loss: 0.384306] [G loss: 0.894508]\n",
      "[Epoch 2/30] [Batch 694/938] [D loss: 0.355852] [G loss: 1.535566]\n",
      "[Epoch 2/30] [Batch 695/938] [D loss: 0.311967] [G loss: 1.123492]\n",
      "[Epoch 2/30] [Batch 696/938] [D loss: 0.326081] [G loss: 1.789398]\n",
      "[Epoch 2/30] [Batch 697/938] [D loss: 0.394921] [G loss: 0.867516]\n",
      "[Epoch 2/30] [Batch 698/938] [D loss: 0.326990] [G loss: 1.824621]\n",
      "[Epoch 2/30] [Batch 699/938] [D loss: 0.357124] [G loss: 0.977148]\n",
      "[Epoch 2/30] [Batch 700/938] [D loss: 0.349091] [G loss: 1.600600]\n",
      "[Epoch 2/30] [Batch 701/938] [D loss: 0.412814] [G loss: 0.873084]\n",
      "[Epoch 2/30] [Batch 702/938] [D loss: 0.390620] [G loss: 1.760713]\n",
      "[Epoch 2/30] [Batch 703/938] [D loss: 0.400882] [G loss: 0.848547]\n",
      "[Epoch 2/30] [Batch 704/938] [D loss: 0.373628] [G loss: 1.578446]\n",
      "[Epoch 2/30] [Batch 705/938] [D loss: 0.424760] [G loss: 0.891935]\n",
      "[Epoch 2/30] [Batch 706/938] [D loss: 0.341560] [G loss: 1.502850]\n",
      "[Epoch 2/30] [Batch 707/938] [D loss: 0.425246] [G loss: 0.976276]\n",
      "[Epoch 2/30] [Batch 708/938] [D loss: 0.377319] [G loss: 1.334825]\n",
      "[Epoch 2/30] [Batch 709/938] [D loss: 0.422661] [G loss: 0.927350]\n",
      "[Epoch 2/30] [Batch 710/938] [D loss: 0.425990] [G loss: 1.520572]\n",
      "[Epoch 2/30] [Batch 711/938] [D loss: 0.466251] [G loss: 0.717157]\n",
      "[Epoch 2/30] [Batch 712/938] [D loss: 0.555120] [G loss: 2.202125]\n",
      "[Epoch 2/30] [Batch 713/938] [D loss: 0.775499] [G loss: 0.290425]\n",
      "[Epoch 2/30] [Batch 714/938] [D loss: 0.904892] [G loss: 3.148074]\n",
      "[Epoch 2/30] [Batch 715/938] [D loss: 0.744678] [G loss: 0.302516]\n",
      "[Epoch 2/30] [Batch 716/938] [D loss: 0.500291] [G loss: 2.524784]\n",
      "[Epoch 2/30] [Batch 717/938] [D loss: 0.363748] [G loss: 0.897402]\n",
      "[Epoch 2/30] [Batch 718/938] [D loss: 0.327383] [G loss: 1.501983]\n",
      "[Epoch 2/30] [Batch 719/938] [D loss: 0.293601] [G loss: 1.290786]\n",
      "[Epoch 2/30] [Batch 720/938] [D loss: 0.363275] [G loss: 1.474435]\n",
      "[Epoch 2/30] [Batch 721/938] [D loss: 0.427559] [G loss: 1.042942]\n",
      "[Epoch 2/30] [Batch 722/938] [D loss: 0.404683] [G loss: 1.038731]\n",
      "[Epoch 2/30] [Batch 723/938] [D loss: 0.373946] [G loss: 1.734809]\n",
      "[Epoch 2/30] [Batch 724/938] [D loss: 0.448694] [G loss: 0.706797]\n",
      "[Epoch 2/30] [Batch 725/938] [D loss: 0.482678] [G loss: 2.432518]\n",
      "[Epoch 2/30] [Batch 726/938] [D loss: 0.573917] [G loss: 0.506605]\n",
      "[Epoch 2/30] [Batch 727/938] [D loss: 0.522757] [G loss: 2.440119]\n",
      "[Epoch 2/30] [Batch 728/938] [D loss: 0.494854] [G loss: 0.602396]\n",
      "[Epoch 2/30] [Batch 729/938] [D loss: 0.391107] [G loss: 2.167830]\n",
      "[Epoch 2/30] [Batch 730/938] [D loss: 0.346645] [G loss: 0.928040]\n",
      "[Epoch 2/30] [Batch 731/938] [D loss: 0.288239] [G loss: 1.862293]\n",
      "[Epoch 2/30] [Batch 732/938] [D loss: 0.325760] [G loss: 1.209559]\n",
      "[Epoch 2/30] [Batch 733/938] [D loss: 0.353708] [G loss: 1.441936]\n",
      "[Epoch 2/30] [Batch 734/938] [D loss: 0.365454] [G loss: 0.949313]\n",
      "[Epoch 2/30] [Batch 735/938] [D loss: 0.412693] [G loss: 2.113196]\n",
      "[Epoch 2/30] [Batch 736/938] [D loss: 0.531522] [G loss: 0.525043]\n",
      "[Epoch 2/30] [Batch 737/938] [D loss: 0.687874] [G loss: 2.796995]\n",
      "[Epoch 2/30] [Batch 738/938] [D loss: 0.762193] [G loss: 0.281328]\n",
      "[Epoch 2/30] [Batch 739/938] [D loss: 0.615842] [G loss: 2.911850]\n",
      "[Epoch 2/30] [Batch 740/938] [D loss: 0.409695] [G loss: 0.759647]\n",
      "[Epoch 2/30] [Batch 741/938] [D loss: 0.352134] [G loss: 1.615860]\n",
      "[Epoch 2/30] [Batch 742/938] [D loss: 0.295078] [G loss: 1.438132]\n",
      "[Epoch 2/30] [Batch 743/938] [D loss: 0.337925] [G loss: 1.145168]\n",
      "[Epoch 2/30] [Batch 744/938] [D loss: 0.377225] [G loss: 1.631419]\n",
      "[Epoch 2/30] [Batch 745/938] [D loss: 0.442824] [G loss: 0.716274]\n",
      "[Epoch 2/30] [Batch 746/938] [D loss: 0.705131] [G loss: 2.321965]\n",
      "[Epoch 2/30] [Batch 747/938] [D loss: 0.900631] [G loss: 0.215643]\n",
      "[Epoch 2/30] [Batch 748/938] [D loss: 0.680930] [G loss: 3.102913]\n",
      "[Epoch 2/30] [Batch 749/938] [D loss: 0.477945] [G loss: 0.737088]\n",
      "[Epoch 2/30] [Batch 750/938] [D loss: 0.403664] [G loss: 1.356032]\n",
      "[Epoch 2/30] [Batch 751/938] [D loss: 0.347026] [G loss: 1.189645]\n",
      "[Epoch 2/30] [Batch 752/938] [D loss: 0.408794] [G loss: 1.372009]\n",
      "[Epoch 2/30] [Batch 753/938] [D loss: 0.387507] [G loss: 0.862856]\n",
      "[Epoch 2/30] [Batch 754/938] [D loss: 0.443679] [G loss: 2.045312]\n",
      "[Epoch 2/30] [Batch 755/938] [D loss: 0.577875] [G loss: 0.530615]\n",
      "[Epoch 2/30] [Batch 756/938] [D loss: 0.577345] [G loss: 2.217981]\n",
      "[Epoch 2/30] [Batch 757/938] [D loss: 0.618250] [G loss: 0.413702]\n",
      "[Epoch 2/30] [Batch 758/938] [D loss: 0.578653] [G loss: 2.651545]\n",
      "[Epoch 2/30] [Batch 759/938] [D loss: 0.468272] [G loss: 0.612821]\n",
      "[Epoch 2/30] [Batch 760/938] [D loss: 0.453517] [G loss: 2.074493]\n",
      "[Epoch 2/30] [Batch 761/938] [D loss: 0.431401] [G loss: 0.849173]\n",
      "[Epoch 2/30] [Batch 762/938] [D loss: 0.411448] [G loss: 1.479432]\n",
      "[Epoch 2/30] [Batch 763/938] [D loss: 0.400947] [G loss: 1.093158]\n",
      "[Epoch 2/30] [Batch 764/938] [D loss: 0.410195] [G loss: 1.328233]\n",
      "[Epoch 2/30] [Batch 765/938] [D loss: 0.452944] [G loss: 1.227647]\n",
      "[Epoch 2/30] [Batch 766/938] [D loss: 0.483445] [G loss: 0.728212]\n",
      "[Epoch 2/30] [Batch 767/938] [D loss: 0.727595] [G loss: 2.260172]\n",
      "[Epoch 2/30] [Batch 768/938] [D loss: 0.905951] [G loss: 0.233400]\n",
      "[Epoch 2/30] [Batch 769/938] [D loss: 0.636565] [G loss: 2.594101]\n",
      "[Epoch 2/30] [Batch 770/938] [D loss: 0.451222] [G loss: 0.807432]\n",
      "[Epoch 2/30] [Batch 771/938] [D loss: 0.366874] [G loss: 1.653874]\n",
      "[Epoch 2/30] [Batch 772/938] [D loss: 0.415994] [G loss: 1.280412]\n",
      "[Epoch 2/30] [Batch 773/938] [D loss: 0.396653] [G loss: 0.936438]\n",
      "[Epoch 2/30] [Batch 774/938] [D loss: 0.515445] [G loss: 1.850929]\n",
      "[Epoch 2/30] [Batch 775/938] [D loss: 0.548808] [G loss: 0.492880]\n",
      "[Epoch 2/30] [Batch 776/938] [D loss: 0.535307] [G loss: 2.571895]\n",
      "[Epoch 2/30] [Batch 777/938] [D loss: 0.450089] [G loss: 0.798178]\n",
      "[Epoch 2/30] [Batch 778/938] [D loss: 0.425146] [G loss: 1.373799]\n",
      "[Epoch 2/30] [Batch 779/938] [D loss: 0.382173] [G loss: 1.331487]\n",
      "[Epoch 2/30] [Batch 780/938] [D loss: 0.450263] [G loss: 1.110940]\n",
      "[Epoch 2/30] [Batch 781/938] [D loss: 0.432761] [G loss: 1.039411]\n",
      "[Epoch 2/30] [Batch 782/938] [D loss: 0.440758] [G loss: 1.467369]\n",
      "[Epoch 2/30] [Batch 783/938] [D loss: 0.438046] [G loss: 0.788281]\n",
      "[Epoch 2/30] [Batch 784/938] [D loss: 0.535798] [G loss: 1.836631]\n",
      "[Epoch 2/30] [Batch 785/938] [D loss: 0.581930] [G loss: 0.487495]\n",
      "[Epoch 2/30] [Batch 786/938] [D loss: 0.591008] [G loss: 2.349792]\n",
      "[Epoch 2/30] [Batch 787/938] [D loss: 0.509704] [G loss: 0.648456]\n",
      "[Epoch 2/30] [Batch 788/938] [D loss: 0.489688] [G loss: 1.682300]\n",
      "[Epoch 2/30] [Batch 789/938] [D loss: 0.526923] [G loss: 0.830695]\n",
      "[Epoch 2/30] [Batch 790/938] [D loss: 0.424355] [G loss: 1.180032]\n",
      "[Epoch 2/30] [Batch 791/938] [D loss: 0.475384] [G loss: 1.336810]\n",
      "[Epoch 2/30] [Batch 792/938] [D loss: 0.525571] [G loss: 0.660761]\n",
      "[Epoch 2/30] [Batch 793/938] [D loss: 0.450449] [G loss: 2.224777]\n",
      "[Epoch 2/30] [Batch 794/938] [D loss: 0.461582] [G loss: 0.751037]\n",
      "[Epoch 2/30] [Batch 795/938] [D loss: 0.436181] [G loss: 1.613077]\n",
      "[Epoch 2/30] [Batch 796/938] [D loss: 0.461313] [G loss: 0.965430]\n",
      "[Epoch 2/30] [Batch 797/938] [D loss: 0.458178] [G loss: 1.177567]\n",
      "[Epoch 2/30] [Batch 798/938] [D loss: 0.474885] [G loss: 1.121508]\n",
      "[Epoch 2/30] [Batch 799/938] [D loss: 0.465009] [G loss: 1.000186]\n",
      "[Epoch 2/30] [Batch 800/938] [D loss: 0.464652] [G loss: 1.251554]\n",
      "[Epoch 2/30] [Batch 801/938] [D loss: 0.457174] [G loss: 0.992930]\n",
      "[Epoch 2/30] [Batch 802/938] [D loss: 0.381072] [G loss: 1.342120]\n",
      "[Epoch 2/30] [Batch 803/938] [D loss: 0.467748] [G loss: 1.081261]\n",
      "[Epoch 2/30] [Batch 804/938] [D loss: 0.410341] [G loss: 1.010112]\n",
      "[Epoch 2/30] [Batch 805/938] [D loss: 0.425594] [G loss: 1.479889]\n",
      "[Epoch 2/30] [Batch 806/938] [D loss: 0.509224] [G loss: 0.806989]\n",
      "[Epoch 2/30] [Batch 807/938] [D loss: 0.387110] [G loss: 1.314245]\n",
      "[Epoch 2/30] [Batch 808/938] [D loss: 0.410194] [G loss: 1.226868]\n",
      "[Epoch 2/30] [Batch 809/938] [D loss: 0.371808] [G loss: 1.053447]\n",
      "[Epoch 2/30] [Batch 810/938] [D loss: 0.470999] [G loss: 1.405641]\n",
      "[Epoch 2/30] [Batch 811/938] [D loss: 0.411322] [G loss: 0.801165]\n",
      "[Epoch 2/30] [Batch 812/938] [D loss: 0.417088] [G loss: 1.759568]\n",
      "[Epoch 2/30] [Batch 813/938] [D loss: 0.404229] [G loss: 1.024506]\n",
      "[Epoch 2/30] [Batch 814/938] [D loss: 0.384925] [G loss: 1.041403]\n",
      "[Epoch 2/30] [Batch 815/938] [D loss: 0.426817] [G loss: 1.560571]\n",
      "[Epoch 2/30] [Batch 816/938] [D loss: 0.449139] [G loss: 0.767549]\n",
      "[Epoch 2/30] [Batch 817/938] [D loss: 0.509765] [G loss: 1.759998]\n",
      "[Epoch 2/30] [Batch 818/938] [D loss: 0.537833] [G loss: 0.546202]\n",
      "[Epoch 2/30] [Batch 819/938] [D loss: 0.492990] [G loss: 2.026196]\n",
      "[Epoch 2/30] [Batch 820/938] [D loss: 0.412434] [G loss: 0.855092]\n",
      "[Epoch 2/30] [Batch 821/938] [D loss: 0.434764] [G loss: 1.337144]\n",
      "[Epoch 2/30] [Batch 822/938] [D loss: 0.367534] [G loss: 0.997027]\n",
      "[Epoch 2/30] [Batch 823/938] [D loss: 0.338500] [G loss: 1.479373]\n",
      "[Epoch 2/30] [Batch 824/938] [D loss: 0.369030] [G loss: 1.293619]\n",
      "[Epoch 2/30] [Batch 825/938] [D loss: 0.421184] [G loss: 0.928181]\n",
      "[Epoch 2/30] [Batch 826/938] [D loss: 0.371220] [G loss: 1.488885]\n",
      "[Epoch 2/30] [Batch 827/938] [D loss: 0.387207] [G loss: 1.040511]\n",
      "[Epoch 2/30] [Batch 828/938] [D loss: 0.408034] [G loss: 1.336133]\n",
      "[Epoch 2/30] [Batch 829/938] [D loss: 0.401042] [G loss: 0.928692]\n",
      "[Epoch 2/30] [Batch 830/938] [D loss: 0.322258] [G loss: 1.518163]\n",
      "[Epoch 2/30] [Batch 831/938] [D loss: 0.394346] [G loss: 1.219026]\n",
      "[Epoch 2/30] [Batch 832/938] [D loss: 0.429099] [G loss: 1.041251]\n",
      "[Epoch 2/30] [Batch 833/938] [D loss: 0.403754] [G loss: 1.188121]\n",
      "[Epoch 2/30] [Batch 834/938] [D loss: 0.378431] [G loss: 1.140625]\n",
      "[Epoch 2/30] [Batch 835/938] [D loss: 0.416908] [G loss: 1.228855]\n",
      "[Epoch 2/30] [Batch 836/938] [D loss: 0.393425] [G loss: 0.995744]\n",
      "[Epoch 2/30] [Batch 837/938] [D loss: 0.385683] [G loss: 1.479398]\n",
      "[Epoch 2/30] [Batch 838/938] [D loss: 0.426408] [G loss: 0.821465]\n",
      "[Epoch 2/30] [Batch 839/938] [D loss: 0.442722] [G loss: 1.777426]\n",
      "[Epoch 2/30] [Batch 840/938] [D loss: 0.476637] [G loss: 0.675587]\n",
      "[Epoch 2/30] [Batch 841/938] [D loss: 0.417528] [G loss: 1.864777]\n",
      "[Epoch 2/30] [Batch 842/938] [D loss: 0.387350] [G loss: 0.868392]\n",
      "[Epoch 2/30] [Batch 843/938] [D loss: 0.379804] [G loss: 1.515512]\n",
      "[Epoch 2/30] [Batch 844/938] [D loss: 0.360459] [G loss: 0.970843]\n",
      "[Epoch 2/30] [Batch 845/938] [D loss: 0.406032] [G loss: 1.779064]\n",
      "[Epoch 2/30] [Batch 846/938] [D loss: 0.420878] [G loss: 0.804888]\n",
      "[Epoch 2/30] [Batch 847/938] [D loss: 0.370757] [G loss: 1.754413]\n",
      "[Epoch 2/30] [Batch 848/938] [D loss: 0.358182] [G loss: 1.010552]\n",
      "[Epoch 2/30] [Batch 849/938] [D loss: 0.305871] [G loss: 1.516720]\n",
      "[Epoch 2/30] [Batch 850/938] [D loss: 0.345510] [G loss: 1.364889]\n",
      "[Epoch 2/30] [Batch 851/938] [D loss: 0.370926] [G loss: 1.124841]\n",
      "[Epoch 2/30] [Batch 852/938] [D loss: 0.299376] [G loss: 1.380854]\n",
      "[Epoch 2/30] [Batch 853/938] [D loss: 0.390049] [G loss: 1.464289]\n",
      "[Epoch 2/30] [Batch 854/938] [D loss: 0.400656] [G loss: 0.947271]\n",
      "[Epoch 2/30] [Batch 855/938] [D loss: 0.357164] [G loss: 1.642765]\n",
      "[Epoch 2/30] [Batch 856/938] [D loss: 0.372847] [G loss: 0.972991]\n",
      "[Epoch 2/30] [Batch 857/938] [D loss: 0.360893] [G loss: 1.578891]\n",
      "[Epoch 2/30] [Batch 858/938] [D loss: 0.346994] [G loss: 1.082995]\n",
      "[Epoch 2/30] [Batch 859/938] [D loss: 0.387893] [G loss: 1.611145]\n",
      "[Epoch 2/30] [Batch 860/938] [D loss: 0.391415] [G loss: 0.852287]\n",
      "[Epoch 2/30] [Batch 861/938] [D loss: 0.432960] [G loss: 2.026051]\n",
      "[Epoch 2/30] [Batch 862/938] [D loss: 0.466864] [G loss: 0.645826]\n",
      "[Epoch 2/30] [Batch 863/938] [D loss: 0.469086] [G loss: 2.376026]\n",
      "[Epoch 2/30] [Batch 864/938] [D loss: 0.496625] [G loss: 0.571458]\n",
      "[Epoch 2/30] [Batch 865/938] [D loss: 0.391781] [G loss: 2.401895]\n",
      "[Epoch 2/30] [Batch 866/938] [D loss: 0.338926] [G loss: 1.049663]\n",
      "[Epoch 2/30] [Batch 867/938] [D loss: 0.323987] [G loss: 1.394942]\n",
      "[Epoch 2/30] [Batch 868/938] [D loss: 0.311256] [G loss: 1.593094]\n",
      "[Epoch 2/30] [Batch 869/938] [D loss: 0.315859] [G loss: 1.276489]\n",
      "[Epoch 2/30] [Batch 870/938] [D loss: 0.329587] [G loss: 1.468539]\n",
      "[Epoch 2/30] [Batch 871/938] [D loss: 0.369636] [G loss: 1.203347]\n",
      "[Epoch 2/30] [Batch 872/938] [D loss: 0.350272] [G loss: 1.424647]\n",
      "[Epoch 2/30] [Batch 873/938] [D loss: 0.362203] [G loss: 1.135957]\n",
      "[Epoch 2/30] [Batch 874/938] [D loss: 0.348950] [G loss: 1.482240]\n",
      "[Epoch 2/30] [Batch 875/938] [D loss: 0.335919] [G loss: 1.107504]\n",
      "[Epoch 2/30] [Batch 876/938] [D loss: 0.391913] [G loss: 1.728732]\n",
      "[Epoch 2/30] [Batch 877/938] [D loss: 0.458694] [G loss: 0.680020]\n",
      "[Epoch 2/30] [Batch 878/938] [D loss: 0.536977] [G loss: 2.500940]\n",
      "[Epoch 2/30] [Batch 879/938] [D loss: 0.532880] [G loss: 0.530203]\n",
      "[Epoch 2/30] [Batch 880/938] [D loss: 0.509602] [G loss: 2.381725]\n",
      "[Epoch 2/30] [Batch 881/938] [D loss: 0.478937] [G loss: 0.611008]\n",
      "[Epoch 2/30] [Batch 882/938] [D loss: 0.374264] [G loss: 2.285116]\n",
      "[Epoch 2/30] [Batch 883/938] [D loss: 0.329958] [G loss: 1.008322]\n",
      "[Epoch 2/30] [Batch 884/938] [D loss: 0.346468] [G loss: 1.678014]\n",
      "[Epoch 2/30] [Batch 885/938] [D loss: 0.327155] [G loss: 1.092785]\n",
      "[Epoch 2/30] [Batch 886/938] [D loss: 0.383666] [G loss: 1.791153]\n",
      "[Epoch 2/30] [Batch 887/938] [D loss: 0.391242] [G loss: 0.895553]\n",
      "[Epoch 2/30] [Batch 888/938] [D loss: 0.358165] [G loss: 1.688753]\n",
      "[Epoch 2/30] [Batch 889/938] [D loss: 0.340800] [G loss: 1.051467]\n",
      "[Epoch 2/30] [Batch 890/938] [D loss: 0.310955] [G loss: 1.701448]\n",
      "[Epoch 2/30] [Batch 891/938] [D loss: 0.315404] [G loss: 1.273548]\n",
      "[Epoch 2/30] [Batch 892/938] [D loss: 0.319049] [G loss: 1.372268]\n",
      "[Epoch 2/30] [Batch 893/938] [D loss: 0.380544] [G loss: 1.393505]\n",
      "[Epoch 2/30] [Batch 894/938] [D loss: 0.416387] [G loss: 0.938778]\n",
      "[Epoch 2/30] [Batch 895/938] [D loss: 0.420185] [G loss: 1.796553]\n",
      "[Epoch 2/30] [Batch 896/938] [D loss: 0.500942] [G loss: 0.705710]\n",
      "[Epoch 2/30] [Batch 897/938] [D loss: 0.499075] [G loss: 1.981897]\n",
      "[Epoch 2/30] [Batch 898/938] [D loss: 0.620352] [G loss: 0.409714]\n",
      "[Epoch 2/30] [Batch 899/938] [D loss: 0.735888] [G loss: 3.262524]\n",
      "[Epoch 2/30] [Batch 900/938] [D loss: 0.607241] [G loss: 0.440438]\n",
      "[Epoch 2/30] [Batch 901/938] [D loss: 0.435462] [G loss: 2.073036]\n",
      "[Epoch 2/30] [Batch 902/938] [D loss: 0.392038] [G loss: 0.848600]\n",
      "[Epoch 2/30] [Batch 903/938] [D loss: 0.422121] [G loss: 1.855700]\n",
      "[Epoch 2/30] [Batch 904/938] [D loss: 0.451074] [G loss: 0.725953]\n",
      "[Epoch 2/30] [Batch 905/938] [D loss: 0.573194] [G loss: 2.133696]\n",
      "[Epoch 2/30] [Batch 906/938] [D loss: 0.611878] [G loss: 0.469708]\n",
      "[Epoch 2/30] [Batch 907/938] [D loss: 0.473893] [G loss: 2.335535]\n",
      "[Epoch 2/30] [Batch 908/938] [D loss: 0.438288] [G loss: 0.778898]\n",
      "[Epoch 2/30] [Batch 909/938] [D loss: 0.402197] [G loss: 1.842819]\n",
      "[Epoch 2/30] [Batch 910/938] [D loss: 0.459689] [G loss: 0.904654]\n",
      "[Epoch 2/30] [Batch 911/938] [D loss: 0.371262] [G loss: 1.214449]\n",
      "[Epoch 2/30] [Batch 912/938] [D loss: 0.426968] [G loss: 1.457871]\n",
      "[Epoch 2/30] [Batch 913/938] [D loss: 0.453707] [G loss: 0.662421]\n",
      "[Epoch 2/30] [Batch 914/938] [D loss: 0.539193] [G loss: 2.487171]\n",
      "[Epoch 2/30] [Batch 915/938] [D loss: 0.572457] [G loss: 0.482263]\n",
      "[Epoch 2/30] [Batch 916/938] [D loss: 0.439180] [G loss: 2.301091]\n",
      "[Epoch 2/30] [Batch 917/938] [D loss: 0.404367] [G loss: 0.848347]\n",
      "[Epoch 2/30] [Batch 918/938] [D loss: 0.317328] [G loss: 1.690404]\n",
      "[Epoch 2/30] [Batch 919/938] [D loss: 0.344700] [G loss: 1.305404]\n",
      "[Epoch 2/30] [Batch 920/938] [D loss: 0.365301] [G loss: 1.085079]\n",
      "[Epoch 2/30] [Batch 921/938] [D loss: 0.378922] [G loss: 1.496444]\n",
      "[Epoch 2/30] [Batch 922/938] [D loss: 0.394007] [G loss: 0.960211]\n",
      "[Epoch 2/30] [Batch 923/938] [D loss: 0.394098] [G loss: 1.646116]\n",
      "[Epoch 2/30] [Batch 924/938] [D loss: 0.378276] [G loss: 0.846453]\n",
      "[Epoch 2/30] [Batch 925/938] [D loss: 0.385312] [G loss: 2.083243]\n",
      "[Epoch 2/30] [Batch 926/938] [D loss: 0.399720] [G loss: 0.790442]\n",
      "[Epoch 2/30] [Batch 927/938] [D loss: 0.381314] [G loss: 2.058732]\n",
      "[Epoch 2/30] [Batch 928/938] [D loss: 0.400561] [G loss: 0.781264]\n",
      "[Epoch 2/30] [Batch 929/938] [D loss: 0.415627] [G loss: 2.059439]\n",
      "[Epoch 2/30] [Batch 930/938] [D loss: 0.452951] [G loss: 0.674397]\n",
      "[Epoch 2/30] [Batch 931/938] [D loss: 0.473053] [G loss: 2.268944]\n",
      "[Epoch 2/30] [Batch 932/938] [D loss: 0.493122] [G loss: 0.599813]\n",
      "[Epoch 2/30] [Batch 933/938] [D loss: 0.511332] [G loss: 2.313212]\n",
      "[Epoch 2/30] [Batch 934/938] [D loss: 0.494134] [G loss: 0.593697]\n",
      "[Epoch 2/30] [Batch 935/938] [D loss: 0.452858] [G loss: 2.407096]\n",
      "[Epoch 2/30] [Batch 936/938] [D loss: 0.411943] [G loss: 0.757805]\n",
      "[Epoch 2/30] [Batch 937/938] [D loss: 0.380229] [G loss: 1.941045]\n",
      "[Epoch 3/30] [Batch 0/938] [D loss: 0.351882] [G loss: 0.891929]\n",
      "[Epoch 3/30] [Batch 1/938] [D loss: 0.324551] [G loss: 2.014153]\n",
      "[Epoch 3/30] [Batch 2/938] [D loss: 0.336559] [G loss: 1.231889]\n",
      "[Epoch 3/30] [Batch 3/938] [D loss: 0.324727] [G loss: 1.084260]\n",
      "[Epoch 3/30] [Batch 4/938] [D loss: 0.284320] [G loss: 1.897930]\n",
      "[Epoch 3/30] [Batch 5/938] [D loss: 0.385491] [G loss: 1.172169]\n",
      "[Epoch 3/30] [Batch 6/938] [D loss: 0.362219] [G loss: 1.128746]\n",
      "[Epoch 3/30] [Batch 7/938] [D loss: 0.361834] [G loss: 1.572440]\n",
      "[Epoch 3/30] [Batch 8/938] [D loss: 0.370674] [G loss: 0.983947]\n",
      "[Epoch 3/30] [Batch 9/938] [D loss: 0.350467] [G loss: 1.738326]\n",
      "[Epoch 3/30] [Batch 10/938] [D loss: 0.372545] [G loss: 1.082808]\n",
      "[Epoch 3/30] [Batch 11/938] [D loss: 0.374032] [G loss: 1.334938]\n",
      "[Epoch 3/30] [Batch 12/938] [D loss: 0.374233] [G loss: 1.267172]\n",
      "[Epoch 3/30] [Batch 13/938] [D loss: 0.352668] [G loss: 1.212245]\n",
      "[Epoch 3/30] [Batch 14/938] [D loss: 0.372687] [G loss: 1.430896]\n",
      "[Epoch 3/30] [Batch 15/938] [D loss: 0.419507] [G loss: 0.929367]\n",
      "[Epoch 3/30] [Batch 16/938] [D loss: 0.404096] [G loss: 1.597360]\n",
      "[Epoch 3/30] [Batch 17/938] [D loss: 0.436860] [G loss: 0.797168]\n",
      "[Epoch 3/30] [Batch 18/938] [D loss: 0.431022] [G loss: 1.946432]\n",
      "[Epoch 3/30] [Batch 19/938] [D loss: 0.460209] [G loss: 0.698001]\n",
      "[Epoch 3/30] [Batch 20/938] [D loss: 0.403531] [G loss: 2.161319]\n",
      "[Epoch 3/30] [Batch 21/938] [D loss: 0.390051] [G loss: 0.786099]\n",
      "[Epoch 3/30] [Batch 22/938] [D loss: 0.456914] [G loss: 2.181572]\n",
      "[Epoch 3/30] [Batch 23/938] [D loss: 0.473325] [G loss: 0.655836]\n",
      "[Epoch 3/30] [Batch 24/938] [D loss: 0.321007] [G loss: 2.171308]\n",
      "[Epoch 3/30] [Batch 25/938] [D loss: 0.341560] [G loss: 1.220100]\n",
      "[Epoch 3/30] [Batch 26/938] [D loss: 0.337582] [G loss: 1.107570]\n",
      "[Epoch 3/30] [Batch 27/938] [D loss: 0.372608] [G loss: 1.759903]\n",
      "[Epoch 3/30] [Batch 28/938] [D loss: 0.375629] [G loss: 0.915191]\n",
      "[Epoch 3/30] [Batch 29/938] [D loss: 0.389700] [G loss: 1.809606]\n",
      "[Epoch 3/30] [Batch 30/938] [D loss: 0.375496] [G loss: 0.872649]\n",
      "[Epoch 3/30] [Batch 31/938] [D loss: 0.343397] [G loss: 1.919197]\n",
      "[Epoch 3/30] [Batch 32/938] [D loss: 0.355439] [G loss: 1.132004]\n",
      "[Epoch 3/30] [Batch 33/938] [D loss: 0.305783] [G loss: 1.172519]\n",
      "[Epoch 3/30] [Batch 34/938] [D loss: 0.425890] [G loss: 2.117769]\n",
      "[Epoch 3/30] [Batch 35/938] [D loss: 0.493418] [G loss: 0.548243]\n",
      "[Epoch 3/30] [Batch 36/938] [D loss: 0.523301] [G loss: 2.780985]\n",
      "[Epoch 3/30] [Batch 37/938] [D loss: 0.353639] [G loss: 0.917293]\n",
      "[Epoch 3/30] [Batch 38/938] [D loss: 0.248395] [G loss: 1.517103]\n",
      "[Epoch 3/30] [Batch 39/938] [D loss: 0.378839] [G loss: 1.960722]\n",
      "[Epoch 3/30] [Batch 40/938] [D loss: 0.412525] [G loss: 0.773969]\n",
      "[Epoch 3/30] [Batch 41/938] [D loss: 0.383627] [G loss: 1.983736]\n",
      "[Epoch 3/30] [Batch 42/938] [D loss: 0.407949] [G loss: 1.044511]\n",
      "[Epoch 3/30] [Batch 43/938] [D loss: 0.329613] [G loss: 1.240363]\n",
      "[Epoch 3/30] [Batch 44/938] [D loss: 0.300381] [G loss: 1.638202]\n",
      "[Epoch 3/30] [Batch 45/938] [D loss: 0.326285] [G loss: 1.209074]\n",
      "[Epoch 3/30] [Batch 46/938] [D loss: 0.306768] [G loss: 1.537827]\n",
      "[Epoch 3/30] [Batch 47/938] [D loss: 0.343409] [G loss: 1.213414]\n",
      "[Epoch 3/30] [Batch 48/938] [D loss: 0.355663] [G loss: 1.554683]\n",
      "[Epoch 3/30] [Batch 49/938] [D loss: 0.428581] [G loss: 0.919872]\n",
      "[Epoch 3/30] [Batch 50/938] [D loss: 0.334482] [G loss: 1.614464]\n",
      "[Epoch 3/30] [Batch 51/938] [D loss: 0.415443] [G loss: 1.166875]\n",
      "[Epoch 3/30] [Batch 52/938] [D loss: 0.403865] [G loss: 0.924042]\n",
      "[Epoch 3/30] [Batch 53/938] [D loss: 0.440634] [G loss: 1.952655]\n",
      "[Epoch 3/30] [Batch 54/938] [D loss: 0.456103] [G loss: 0.639939]\n",
      "[Epoch 3/30] [Batch 55/938] [D loss: 0.489355] [G loss: 2.534574]\n",
      "[Epoch 3/30] [Batch 56/938] [D loss: 0.436727] [G loss: 0.733437]\n",
      "[Epoch 3/30] [Batch 57/938] [D loss: 0.343075] [G loss: 1.722543]\n",
      "[Epoch 3/30] [Batch 58/938] [D loss: 0.353474] [G loss: 1.177911]\n",
      "[Epoch 3/30] [Batch 59/938] [D loss: 0.381847] [G loss: 1.269009]\n",
      "[Epoch 3/30] [Batch 60/938] [D loss: 0.383459] [G loss: 1.184464]\n",
      "[Epoch 3/30] [Batch 61/938] [D loss: 0.358504] [G loss: 1.233753]\n",
      "[Epoch 3/30] [Batch 62/938] [D loss: 0.350460] [G loss: 1.429312]\n",
      "[Epoch 3/30] [Batch 63/938] [D loss: 0.377404] [G loss: 1.065359]\n",
      "[Epoch 3/30] [Batch 64/938] [D loss: 0.404446] [G loss: 1.324468]\n",
      "[Epoch 3/30] [Batch 65/938] [D loss: 0.387828] [G loss: 1.101426]\n",
      "[Epoch 3/30] [Batch 66/938] [D loss: 0.410750] [G loss: 1.203633]\n",
      "[Epoch 3/30] [Batch 67/938] [D loss: 0.394434] [G loss: 1.123845]\n",
      "[Epoch 3/30] [Batch 68/938] [D loss: 0.365005] [G loss: 1.424656]\n",
      "[Epoch 3/30] [Batch 69/938] [D loss: 0.419671] [G loss: 1.024861]\n",
      "[Epoch 3/30] [Batch 70/938] [D loss: 0.387155] [G loss: 1.303683]\n",
      "[Epoch 3/30] [Batch 71/938] [D loss: 0.360818] [G loss: 1.205466]\n",
      "[Epoch 3/30] [Batch 72/938] [D loss: 0.343708] [G loss: 1.240278]\n",
      "[Epoch 3/30] [Batch 73/938] [D loss: 0.380570] [G loss: 1.304299]\n",
      "[Epoch 3/30] [Batch 74/938] [D loss: 0.405511] [G loss: 0.948872]\n",
      "[Epoch 3/30] [Batch 75/938] [D loss: 0.412784] [G loss: 1.755982]\n",
      "[Epoch 3/30] [Batch 76/938] [D loss: 0.487820] [G loss: 0.627754]\n",
      "[Epoch 3/30] [Batch 77/938] [D loss: 0.620141] [G loss: 2.548332]\n",
      "[Epoch 3/30] [Batch 78/938] [D loss: 0.768668] [G loss: 0.298584]\n",
      "[Epoch 3/30] [Batch 79/938] [D loss: 0.585830] [G loss: 2.873250]\n",
      "[Epoch 3/30] [Batch 80/938] [D loss: 0.393384] [G loss: 0.774506]\n",
      "[Epoch 3/30] [Batch 81/938] [D loss: 0.322244] [G loss: 1.990306]\n",
      "[Epoch 3/30] [Batch 82/938] [D loss: 0.294111] [G loss: 1.244529]\n",
      "[Epoch 3/30] [Batch 83/938] [D loss: 0.313906] [G loss: 1.494295]\n",
      "[Epoch 3/30] [Batch 84/938] [D loss: 0.346712] [G loss: 1.179416]\n",
      "[Epoch 3/30] [Batch 85/938] [D loss: 0.318916] [G loss: 1.281728]\n",
      "[Epoch 3/30] [Batch 86/938] [D loss: 0.352310] [G loss: 1.534052]\n",
      "[Epoch 3/30] [Batch 87/938] [D loss: 0.386317] [G loss: 0.895345]\n",
      "[Epoch 3/30] [Batch 88/938] [D loss: 0.447064] [G loss: 1.764065]\n",
      "[Epoch 3/30] [Batch 89/938] [D loss: 0.456645] [G loss: 0.680011]\n",
      "[Epoch 3/30] [Batch 90/938] [D loss: 0.387588] [G loss: 2.217548]\n",
      "[Epoch 3/30] [Batch 91/938] [D loss: 0.397272] [G loss: 0.830162]\n",
      "[Epoch 3/30] [Batch 92/938] [D loss: 0.357656] [G loss: 1.607989]\n",
      "[Epoch 3/30] [Batch 93/938] [D loss: 0.316186] [G loss: 1.086337]\n",
      "[Epoch 3/30] [Batch 94/938] [D loss: 0.373097] [G loss: 1.712076]\n",
      "[Epoch 3/30] [Batch 95/938] [D loss: 0.402876] [G loss: 0.878929]\n",
      "[Epoch 3/30] [Batch 96/938] [D loss: 0.424721] [G loss: 1.788158]\n",
      "[Epoch 3/30] [Batch 97/938] [D loss: 0.503174] [G loss: 0.579760]\n",
      "[Epoch 3/30] [Batch 98/938] [D loss: 0.515663] [G loss: 2.735070]\n",
      "[Epoch 3/30] [Batch 99/938] [D loss: 0.500447] [G loss: 0.588611]\n",
      "[Epoch 3/30] [Batch 100/938] [D loss: 0.424140] [G loss: 2.246167]\n",
      "[Epoch 3/30] [Batch 101/938] [D loss: 0.388337] [G loss: 0.856414]\n",
      "[Epoch 3/30] [Batch 102/938] [D loss: 0.376490] [G loss: 1.962861]\n",
      "[Epoch 3/30] [Batch 103/938] [D loss: 0.413214] [G loss: 0.817104]\n",
      "[Epoch 3/30] [Batch 104/938] [D loss: 0.349639] [G loss: 1.824658]\n",
      "[Epoch 3/30] [Batch 105/938] [D loss: 0.326058] [G loss: 1.076585]\n",
      "[Epoch 3/30] [Batch 106/938] [D loss: 0.384940] [G loss: 1.667417]\n",
      "[Epoch 3/30] [Batch 107/938] [D loss: 0.411202] [G loss: 0.733582]\n",
      "[Epoch 3/30] [Batch 108/938] [D loss: 0.512273] [G loss: 2.661695]\n",
      "[Epoch 3/30] [Batch 109/938] [D loss: 0.522183] [G loss: 0.565255]\n",
      "[Epoch 3/30] [Batch 110/938] [D loss: 0.436902] [G loss: 2.268504]\n",
      "[Epoch 3/30] [Batch 111/938] [D loss: 0.478787] [G loss: 0.672219]\n",
      "[Epoch 3/30] [Batch 112/938] [D loss: 0.437663] [G loss: 2.191196]\n",
      "[Epoch 3/30] [Batch 113/938] [D loss: 0.467348] [G loss: 0.654144]\n",
      "[Epoch 3/30] [Batch 114/938] [D loss: 0.471812] [G loss: 2.580898]\n",
      "[Epoch 3/30] [Batch 115/938] [D loss: 0.427235] [G loss: 0.690597]\n",
      "[Epoch 3/30] [Batch 116/938] [D loss: 0.431255] [G loss: 2.367728]\n",
      "[Epoch 3/30] [Batch 117/938] [D loss: 0.476624] [G loss: 0.668237]\n",
      "[Epoch 3/30] [Batch 118/938] [D loss: 0.379641] [G loss: 2.072933]\n",
      "[Epoch 3/30] [Batch 119/938] [D loss: 0.442600] [G loss: 1.010064]\n",
      "[Epoch 3/30] [Batch 120/938] [D loss: 0.322472] [G loss: 1.277558]\n",
      "[Epoch 3/30] [Batch 121/938] [D loss: 0.366150] [G loss: 1.755184]\n",
      "[Epoch 3/30] [Batch 122/938] [D loss: 0.401138] [G loss: 0.879142]\n",
      "[Epoch 3/30] [Batch 123/938] [D loss: 0.442593] [G loss: 1.841557]\n",
      "[Epoch 3/30] [Batch 124/938] [D loss: 0.495579] [G loss: 0.609681]\n",
      "[Epoch 3/30] [Batch 125/938] [D loss: 0.617167] [G loss: 2.651531]\n",
      "[Epoch 3/30] [Batch 126/938] [D loss: 0.727161] [G loss: 0.305020]\n",
      "[Epoch 3/30] [Batch 127/938] [D loss: 0.672103] [G loss: 3.201060]\n",
      "[Epoch 3/30] [Batch 128/938] [D loss: 0.491466] [G loss: 0.597680]\n",
      "[Epoch 3/30] [Batch 129/938] [D loss: 0.340720] [G loss: 2.252133]\n",
      "[Epoch 3/30] [Batch 130/938] [D loss: 0.321971] [G loss: 1.170154]\n",
      "[Epoch 3/30] [Batch 131/938] [D loss: 0.298122] [G loss: 1.493697]\n",
      "[Epoch 3/30] [Batch 132/938] [D loss: 0.320368] [G loss: 1.497319]\n",
      "[Epoch 3/30] [Batch 133/938] [D loss: 0.322436] [G loss: 1.296301]\n",
      "[Epoch 3/30] [Batch 134/938] [D loss: 0.328715] [G loss: 1.342210]\n",
      "[Epoch 3/30] [Batch 135/938] [D loss: 0.369485] [G loss: 1.358056]\n",
      "[Epoch 3/30] [Batch 136/938] [D loss: 0.369971] [G loss: 1.055417]\n",
      "[Epoch 3/30] [Batch 137/938] [D loss: 0.412882] [G loss: 1.732532]\n",
      "[Epoch 3/30] [Batch 138/938] [D loss: 0.484049] [G loss: 0.733805]\n",
      "[Epoch 3/30] [Batch 139/938] [D loss: 0.481933] [G loss: 1.975871]\n",
      "[Epoch 3/30] [Batch 140/938] [D loss: 0.502856] [G loss: 0.573735]\n",
      "[Epoch 3/30] [Batch 141/938] [D loss: 0.582819] [G loss: 2.995537]\n",
      "[Epoch 3/30] [Batch 142/938] [D loss: 0.583211] [G loss: 0.487032]\n",
      "[Epoch 3/30] [Batch 143/938] [D loss: 0.494053] [G loss: 2.566326]\n",
      "[Epoch 3/30] [Batch 144/938] [D loss: 0.380711] [G loss: 0.893830]\n",
      "[Epoch 3/30] [Batch 145/938] [D loss: 0.302742] [G loss: 1.734158]\n",
      "[Epoch 3/30] [Batch 146/938] [D loss: 0.317267] [G loss: 1.355429]\n",
      "[Epoch 3/30] [Batch 147/938] [D loss: 0.351656] [G loss: 1.327469]\n",
      "[Epoch 3/30] [Batch 148/938] [D loss: 0.345446] [G loss: 1.305081]\n",
      "[Epoch 3/30] [Batch 149/938] [D loss: 0.335559] [G loss: 1.427023]\n",
      "[Epoch 3/30] [Batch 150/938] [D loss: 0.330480] [G loss: 1.297903]\n",
      "[Epoch 3/30] [Batch 151/938] [D loss: 0.366718] [G loss: 1.502685]\n",
      "[Epoch 3/30] [Batch 152/938] [D loss: 0.390879] [G loss: 1.026527]\n",
      "[Epoch 3/30] [Batch 153/938] [D loss: 0.403586] [G loss: 1.711814]\n",
      "[Epoch 3/30] [Batch 154/938] [D loss: 0.439185] [G loss: 0.876326]\n",
      "[Epoch 3/30] [Batch 155/938] [D loss: 0.525283] [G loss: 1.995114]\n",
      "[Epoch 3/30] [Batch 156/938] [D loss: 0.681342] [G loss: 0.373080]\n",
      "[Epoch 3/30] [Batch 157/938] [D loss: 0.829827] [G loss: 3.678995]\n",
      "[Epoch 3/30] [Batch 158/938] [D loss: 0.598219] [G loss: 0.461598]\n",
      "[Epoch 3/30] [Batch 159/938] [D loss: 0.545234] [G loss: 2.918656]\n",
      "[Epoch 3/30] [Batch 160/938] [D loss: 0.361057] [G loss: 0.897020]\n",
      "[Epoch 3/30] [Batch 161/938] [D loss: 0.377470] [G loss: 2.260277]\n",
      "[Epoch 3/30] [Batch 162/938] [D loss: 0.347097] [G loss: 0.962815]\n",
      "[Epoch 3/30] [Batch 163/938] [D loss: 0.325684] [G loss: 2.003556]\n",
      "[Epoch 3/30] [Batch 164/938] [D loss: 0.325418] [G loss: 1.183994]\n",
      "[Epoch 3/30] [Batch 165/938] [D loss: 0.377453] [G loss: 1.532716]\n",
      "[Epoch 3/30] [Batch 166/938] [D loss: 0.371969] [G loss: 1.177284]\n",
      "[Epoch 3/30] [Batch 167/938] [D loss: 0.385593] [G loss: 1.584393]\n",
      "[Epoch 3/30] [Batch 168/938] [D loss: 0.382748] [G loss: 0.885128]\n",
      "[Epoch 3/30] [Batch 169/938] [D loss: 0.484807] [G loss: 2.362334]\n",
      "[Epoch 3/30] [Batch 170/938] [D loss: 0.521276] [G loss: 0.613704]\n",
      "[Epoch 3/30] [Batch 171/938] [D loss: 0.478260] [G loss: 2.191459]\n",
      "[Epoch 3/30] [Batch 172/938] [D loss: 0.571825] [G loss: 0.491976]\n",
      "[Epoch 3/30] [Batch 173/938] [D loss: 0.630937] [G loss: 2.853841]\n",
      "[Epoch 3/30] [Batch 174/938] [D loss: 0.551498] [G loss: 0.509715]\n",
      "[Epoch 3/30] [Batch 175/938] [D loss: 0.575683] [G loss: 2.419247]\n",
      "[Epoch 3/30] [Batch 176/938] [D loss: 0.489225] [G loss: 0.606588]\n",
      "[Epoch 3/30] [Batch 177/938] [D loss: 0.456922] [G loss: 2.380187]\n",
      "[Epoch 3/30] [Batch 178/938] [D loss: 0.427889] [G loss: 0.795915]\n",
      "[Epoch 3/30] [Batch 179/938] [D loss: 0.328508] [G loss: 1.836026]\n",
      "[Epoch 3/30] [Batch 180/938] [D loss: 0.337073] [G loss: 1.215984]\n",
      "[Epoch 3/30] [Batch 181/938] [D loss: 0.368699] [G loss: 1.275146]\n",
      "[Epoch 3/30] [Batch 182/938] [D loss: 0.317234] [G loss: 1.350648]\n",
      "[Epoch 3/30] [Batch 183/938] [D loss: 0.399358] [G loss: 1.514382]\n",
      "[Epoch 3/30] [Batch 184/938] [D loss: 0.416862] [G loss: 0.766009]\n",
      "[Epoch 3/30] [Batch 185/938] [D loss: 0.591990] [G loss: 2.516016]\n",
      "[Epoch 3/30] [Batch 186/938] [D loss: 0.619021] [G loss: 0.458593]\n",
      "[Epoch 3/30] [Batch 187/938] [D loss: 0.500296] [G loss: 2.626110]\n",
      "[Epoch 3/30] [Batch 188/938] [D loss: 0.391001] [G loss: 0.961087]\n",
      "[Epoch 3/30] [Batch 189/938] [D loss: 0.415385] [G loss: 1.234188]\n",
      "[Epoch 3/30] [Batch 190/938] [D loss: 0.381597] [G loss: 1.303820]\n",
      "[Epoch 3/30] [Batch 191/938] [D loss: 0.351121] [G loss: 1.239693]\n",
      "[Epoch 3/30] [Batch 192/938] [D loss: 0.339834] [G loss: 1.477350]\n",
      "[Epoch 3/30] [Batch 193/938] [D loss: 0.353310] [G loss: 1.220316]\n",
      "[Epoch 3/30] [Batch 194/938] [D loss: 0.421422] [G loss: 1.336797]\n",
      "[Epoch 3/30] [Batch 195/938] [D loss: 0.414546] [G loss: 1.046375]\n",
      "[Epoch 3/30] [Batch 196/938] [D loss: 0.376989] [G loss: 1.622289]\n",
      "[Epoch 3/30] [Batch 197/938] [D loss: 0.457203] [G loss: 0.950845]\n",
      "[Epoch 3/30] [Batch 198/938] [D loss: 0.443394] [G loss: 1.438649]\n",
      "[Epoch 3/30] [Batch 199/938] [D loss: 0.388983] [G loss: 1.025599]\n",
      "[Epoch 3/30] [Batch 200/938] [D loss: 0.442900] [G loss: 1.633820]\n",
      "[Epoch 3/30] [Batch 201/938] [D loss: 0.459533] [G loss: 0.743778]\n",
      "[Epoch 3/30] [Batch 202/938] [D loss: 0.421446] [G loss: 2.215750]\n",
      "[Epoch 3/30] [Batch 203/938] [D loss: 0.422580] [G loss: 0.823881]\n",
      "[Epoch 3/30] [Batch 204/938] [D loss: 0.379480] [G loss: 1.871995]\n",
      "[Epoch 3/30] [Batch 205/938] [D loss: 0.430752] [G loss: 0.908568]\n",
      "[Epoch 3/30] [Batch 206/938] [D loss: 0.319129] [G loss: 1.724825]\n",
      "[Epoch 3/30] [Batch 207/938] [D loss: 0.340420] [G loss: 1.229887]\n",
      "[Epoch 3/30] [Batch 208/938] [D loss: 0.350047] [G loss: 1.308156]\n",
      "[Epoch 3/30] [Batch 209/938] [D loss: 0.346917] [G loss: 1.543952]\n",
      "[Epoch 3/30] [Batch 210/938] [D loss: 0.397507] [G loss: 0.856466]\n",
      "[Epoch 3/30] [Batch 211/938] [D loss: 0.536738] [G loss: 2.230849]\n",
      "[Epoch 3/30] [Batch 212/938] [D loss: 0.705785] [G loss: 0.320522]\n",
      "[Epoch 3/30] [Batch 213/938] [D loss: 0.737746] [G loss: 3.613864]\n",
      "[Epoch 3/30] [Batch 214/938] [D loss: 0.480233] [G loss: 0.603560]\n",
      "[Epoch 3/30] [Batch 215/938] [D loss: 0.356805] [G loss: 2.111712]\n",
      "[Epoch 3/30] [Batch 216/938] [D loss: 0.295588] [G loss: 1.134578]\n",
      "[Epoch 3/30] [Batch 217/938] [D loss: 0.279243] [G loss: 1.744847]\n",
      "[Epoch 3/30] [Batch 218/938] [D loss: 0.312680] [G loss: 1.403280]\n",
      "[Epoch 3/30] [Batch 219/938] [D loss: 0.338667] [G loss: 1.180275]\n",
      "[Epoch 3/30] [Batch 220/938] [D loss: 0.320579] [G loss: 1.582133]\n",
      "[Epoch 3/30] [Batch 221/938] [D loss: 0.410004] [G loss: 1.058019]\n",
      "[Epoch 3/30] [Batch 222/938] [D loss: 0.390963] [G loss: 1.360141]\n",
      "[Epoch 3/30] [Batch 223/938] [D loss: 0.386096] [G loss: 1.170590]\n",
      "[Epoch 3/30] [Batch 224/938] [D loss: 0.350135] [G loss: 1.218091]\n",
      "[Epoch 3/30] [Batch 225/938] [D loss: 0.446753] [G loss: 1.649420]\n",
      "[Epoch 3/30] [Batch 226/938] [D loss: 0.509232] [G loss: 0.566600]\n",
      "[Epoch 3/30] [Batch 227/938] [D loss: 0.700034] [G loss: 2.994956]\n",
      "[Epoch 3/30] [Batch 228/938] [D loss: 0.640726] [G loss: 0.379624]\n",
      "[Epoch 3/30] [Batch 229/938] [D loss: 0.570128] [G loss: 2.871752]\n",
      "[Epoch 3/30] [Batch 230/938] [D loss: 0.423220] [G loss: 0.705337]\n",
      "[Epoch 3/30] [Batch 231/938] [D loss: 0.411106] [G loss: 1.945099]\n",
      "[Epoch 3/30] [Batch 232/938] [D loss: 0.399822] [G loss: 0.783503]\n",
      "[Epoch 3/30] [Batch 233/938] [D loss: 0.375527] [G loss: 2.058310]\n",
      "[Epoch 3/30] [Batch 234/938] [D loss: 0.370675] [G loss: 0.797899]\n",
      "[Epoch 3/30] [Batch 235/938] [D loss: 0.325948] [G loss: 2.104911]\n",
      "[Epoch 3/30] [Batch 236/938] [D loss: 0.346873] [G loss: 1.066736]\n",
      "[Epoch 3/30] [Batch 237/938] [D loss: 0.341996] [G loss: 1.239202]\n",
      "[Epoch 3/30] [Batch 238/938] [D loss: 0.319905] [G loss: 1.539101]\n",
      "[Epoch 3/30] [Batch 239/938] [D loss: 0.409753] [G loss: 0.998431]\n",
      "[Epoch 3/30] [Batch 240/938] [D loss: 0.410150] [G loss: 1.290871]\n",
      "[Epoch 3/30] [Batch 241/938] [D loss: 0.398201] [G loss: 1.035981]\n",
      "[Epoch 3/30] [Batch 242/938] [D loss: 0.450107] [G loss: 1.453843]\n",
      "[Epoch 3/30] [Batch 243/938] [D loss: 0.523082] [G loss: 0.621549]\n",
      "[Epoch 3/30] [Batch 244/938] [D loss: 0.521963] [G loss: 2.264741]\n",
      "[Epoch 3/30] [Batch 245/938] [D loss: 0.635317] [G loss: 0.421937]\n",
      "[Epoch 3/30] [Batch 246/938] [D loss: 0.692172] [G loss: 2.794243]\n",
      "[Epoch 3/30] [Batch 247/938] [D loss: 0.629102] [G loss: 0.443796]\n",
      "[Epoch 3/30] [Batch 248/938] [D loss: 0.541622] [G loss: 2.352070]\n",
      "[Epoch 3/30] [Batch 249/938] [D loss: 0.463289] [G loss: 0.709029]\n",
      "[Epoch 3/30] [Batch 250/938] [D loss: 0.401519] [G loss: 1.984815]\n",
      "[Epoch 3/30] [Batch 251/938] [D loss: 0.412158] [G loss: 0.942588]\n",
      "[Epoch 3/30] [Batch 252/938] [D loss: 0.377132] [G loss: 1.445848]\n",
      "[Epoch 3/30] [Batch 253/938] [D loss: 0.362862] [G loss: 1.169163]\n",
      "[Epoch 3/30] [Batch 254/938] [D loss: 0.388751] [G loss: 1.519779]\n",
      "[Epoch 3/30] [Batch 255/938] [D loss: 0.440748] [G loss: 0.911059]\n",
      "[Epoch 3/30] [Batch 256/938] [D loss: 0.426759] [G loss: 1.584132]\n",
      "[Epoch 3/30] [Batch 257/938] [D loss: 0.461625] [G loss: 0.789642]\n",
      "[Epoch 3/30] [Batch 258/938] [D loss: 0.340735] [G loss: 1.766648]\n",
      "[Epoch 3/30] [Batch 259/938] [D loss: 0.390359] [G loss: 1.087532]\n",
      "[Epoch 3/30] [Batch 260/938] [D loss: 0.444629] [G loss: 1.175002]\n",
      "[Epoch 3/30] [Batch 261/938] [D loss: 0.435383] [G loss: 1.122292]\n",
      "[Epoch 3/30] [Batch 262/938] [D loss: 0.419214] [G loss: 1.087913]\n",
      "[Epoch 3/30] [Batch 263/938] [D loss: 0.372749] [G loss: 1.359255]\n",
      "[Epoch 3/30] [Batch 264/938] [D loss: 0.440726] [G loss: 1.138272]\n",
      "[Epoch 3/30] [Batch 265/938] [D loss: 0.344116] [G loss: 1.311594]\n",
      "[Epoch 3/30] [Batch 266/938] [D loss: 0.359159] [G loss: 1.405682]\n",
      "[Epoch 3/30] [Batch 267/938] [D loss: 0.330630] [G loss: 1.312753]\n",
      "[Epoch 3/30] [Batch 268/938] [D loss: 0.349042] [G loss: 1.446725]\n",
      "[Epoch 3/30] [Batch 269/938] [D loss: 0.330423] [G loss: 1.112484]\n",
      "[Epoch 3/30] [Batch 270/938] [D loss: 0.384503] [G loss: 1.689860]\n",
      "[Epoch 3/30] [Batch 271/938] [D loss: 0.385453] [G loss: 0.962829]\n",
      "[Epoch 3/30] [Batch 272/938] [D loss: 0.371202] [G loss: 1.832008]\n",
      "[Epoch 3/30] [Batch 273/938] [D loss: 0.426814] [G loss: 0.966653]\n",
      "[Epoch 3/30] [Batch 274/938] [D loss: 0.331853] [G loss: 1.444039]\n",
      "[Epoch 3/30] [Batch 275/938] [D loss: 0.385898] [G loss: 1.746666]\n",
      "[Epoch 3/30] [Batch 276/938] [D loss: 0.495501] [G loss: 0.605134]\n",
      "[Epoch 3/30] [Batch 277/938] [D loss: 0.571617] [G loss: 2.904270]\n",
      "[Epoch 3/30] [Batch 278/938] [D loss: 0.515271] [G loss: 0.560360]\n",
      "[Epoch 3/30] [Batch 279/938] [D loss: 0.386780] [G loss: 2.627683]\n",
      "[Epoch 3/30] [Batch 280/938] [D loss: 0.352796] [G loss: 0.915063]\n",
      "[Epoch 3/30] [Batch 281/938] [D loss: 0.340813] [G loss: 2.001938]\n",
      "[Epoch 3/30] [Batch 282/938] [D loss: 0.361782] [G loss: 1.003788]\n",
      "[Epoch 3/30] [Batch 283/938] [D loss: 0.332588] [G loss: 1.892734]\n",
      "[Epoch 3/30] [Batch 284/938] [D loss: 0.374523] [G loss: 1.012613]\n",
      "[Epoch 3/30] [Batch 285/938] [D loss: 0.317188] [G loss: 1.642746]\n",
      "[Epoch 3/30] [Batch 286/938] [D loss: 0.353298] [G loss: 1.245953]\n",
      "[Epoch 3/30] [Batch 287/938] [D loss: 0.326768] [G loss: 1.323743]\n",
      "[Epoch 3/30] [Batch 288/938] [D loss: 0.277189] [G loss: 1.585065]\n",
      "[Epoch 3/30] [Batch 289/938] [D loss: 0.368029] [G loss: 1.296899]\n",
      "[Epoch 3/30] [Batch 290/938] [D loss: 0.376779] [G loss: 1.029210]\n",
      "[Epoch 3/30] [Batch 291/938] [D loss: 0.448581] [G loss: 1.782452]\n",
      "[Epoch 3/30] [Batch 292/938] [D loss: 0.551113] [G loss: 0.481923]\n",
      "[Epoch 3/30] [Batch 293/938] [D loss: 0.899519] [G loss: 3.502596]\n",
      "[Epoch 3/30] [Batch 294/938] [D loss: 0.814135] [G loss: 0.249631]\n",
      "[Epoch 3/30] [Batch 295/938] [D loss: 0.679629] [G loss: 3.087218]\n",
      "[Epoch 3/30] [Batch 296/938] [D loss: 0.452970] [G loss: 0.661623]\n",
      "[Epoch 3/30] [Batch 297/938] [D loss: 0.313043] [G loss: 1.878049]\n",
      "[Epoch 3/30] [Batch 298/938] [D loss: 0.286347] [G loss: 1.576557]\n",
      "[Epoch 3/30] [Batch 299/938] [D loss: 0.316625] [G loss: 1.065129]\n",
      "[Epoch 3/30] [Batch 300/938] [D loss: 0.352291] [G loss: 2.030179]\n",
      "[Epoch 3/30] [Batch 301/938] [D loss: 0.360631] [G loss: 0.877112]\n",
      "[Epoch 3/30] [Batch 302/938] [D loss: 0.324404] [G loss: 1.965031]\n",
      "[Epoch 3/30] [Batch 303/938] [D loss: 0.310241] [G loss: 1.100020]\n",
      "[Epoch 3/30] [Batch 304/938] [D loss: 0.308780] [G loss: 1.667803]\n",
      "[Epoch 3/30] [Batch 305/938] [D loss: 0.391478] [G loss: 1.173835]\n",
      "[Epoch 3/30] [Batch 306/938] [D loss: 0.346825] [G loss: 1.098454]\n",
      "[Epoch 3/30] [Batch 307/938] [D loss: 0.403756] [G loss: 1.810865]\n",
      "[Epoch 3/30] [Batch 308/938] [D loss: 0.493653] [G loss: 0.628527]\n",
      "[Epoch 3/30] [Batch 309/938] [D loss: 0.524646] [G loss: 2.499802]\n",
      "[Epoch 3/30] [Batch 310/938] [D loss: 0.619237] [G loss: 0.432364]\n",
      "[Epoch 3/30] [Batch 311/938] [D loss: 0.574848] [G loss: 2.674591]\n",
      "[Epoch 3/30] [Batch 312/938] [D loss: 0.531805] [G loss: 0.536345]\n",
      "[Epoch 3/30] [Batch 313/938] [D loss: 0.418117] [G loss: 2.397418]\n",
      "[Epoch 3/30] [Batch 314/938] [D loss: 0.345038] [G loss: 0.917731]\n",
      "[Epoch 3/30] [Batch 315/938] [D loss: 0.379014] [G loss: 1.905031]\n",
      "[Epoch 3/30] [Batch 316/938] [D loss: 0.362464] [G loss: 0.893410]\n",
      "[Epoch 3/30] [Batch 317/938] [D loss: 0.359935] [G loss: 1.992712]\n",
      "[Epoch 3/30] [Batch 318/938] [D loss: 0.352202] [G loss: 0.954693]\n",
      "[Epoch 3/30] [Batch 319/938] [D loss: 0.335451] [G loss: 1.873672]\n",
      "[Epoch 3/30] [Batch 320/938] [D loss: 0.338192] [G loss: 1.147503]\n",
      "[Epoch 3/30] [Batch 321/938] [D loss: 0.377984] [G loss: 1.484092]\n",
      "[Epoch 3/30] [Batch 322/938] [D loss: 0.373065] [G loss: 1.016013]\n",
      "[Epoch 3/30] [Batch 323/938] [D loss: 0.389087] [G loss: 1.910628]\n",
      "[Epoch 3/30] [Batch 324/938] [D loss: 0.439215] [G loss: 0.696724]\n",
      "[Epoch 3/30] [Batch 325/938] [D loss: 0.447134] [G loss: 2.567556]\n",
      "[Epoch 3/30] [Batch 326/938] [D loss: 0.471669] [G loss: 0.652338]\n",
      "[Epoch 3/30] [Batch 327/938] [D loss: 0.392816] [G loss: 2.138897]\n",
      "[Epoch 3/30] [Batch 328/938] [D loss: 0.390645] [G loss: 0.931749]\n",
      "[Epoch 3/30] [Batch 329/938] [D loss: 0.317390] [G loss: 1.633372]\n",
      "[Epoch 3/30] [Batch 330/938] [D loss: 0.358126] [G loss: 1.264491]\n",
      "[Epoch 3/30] [Batch 331/938] [D loss: 0.379398] [G loss: 1.154908]\n",
      "[Epoch 3/30] [Batch 332/938] [D loss: 0.325408] [G loss: 1.469715]\n",
      "[Epoch 3/30] [Batch 333/938] [D loss: 0.348124] [G loss: 1.260772]\n",
      "[Epoch 3/30] [Batch 334/938] [D loss: 0.353343] [G loss: 1.243651]\n",
      "[Epoch 3/30] [Batch 335/938] [D loss: 0.356428] [G loss: 1.480271]\n",
      "[Epoch 3/30] [Batch 336/938] [D loss: 0.340467] [G loss: 1.078158]\n",
      "[Epoch 3/30] [Batch 337/938] [D loss: 0.326932] [G loss: 1.748626]\n",
      "[Epoch 3/30] [Batch 338/938] [D loss: 0.348654] [G loss: 1.047791]\n",
      "[Epoch 3/30] [Batch 339/938] [D loss: 0.301909] [G loss: 1.878808]\n",
      "[Epoch 3/30] [Batch 340/938] [D loss: 0.335801] [G loss: 1.083712]\n",
      "[Epoch 3/30] [Batch 341/938] [D loss: 0.449154] [G loss: 1.843237]\n",
      "[Epoch 3/30] [Batch 342/938] [D loss: 0.590567] [G loss: 0.436812]\n",
      "[Epoch 3/30] [Batch 343/938] [D loss: 0.748308] [G loss: 3.726111]\n",
      "[Epoch 3/30] [Batch 344/938] [D loss: 0.490692] [G loss: 0.551955]\n",
      "[Epoch 3/30] [Batch 345/938] [D loss: 0.355860] [G loss: 2.747161]\n",
      "[Epoch 3/30] [Batch 346/938] [D loss: 0.299345] [G loss: 1.133686]\n",
      "[Epoch 3/30] [Batch 347/938] [D loss: 0.259233] [G loss: 1.552749]\n",
      "[Epoch 3/30] [Batch 348/938] [D loss: 0.291602] [G loss: 1.727588]\n",
      "[Epoch 3/30] [Batch 349/938] [D loss: 0.323663] [G loss: 1.042944]\n",
      "[Epoch 3/30] [Batch 350/938] [D loss: 0.323150] [G loss: 2.117010]\n",
      "[Epoch 3/30] [Batch 351/938] [D loss: 0.337915] [G loss: 1.051799]\n",
      "[Epoch 3/30] [Batch 352/938] [D loss: 0.304074] [G loss: 1.765312]\n",
      "[Epoch 3/30] [Batch 353/938] [D loss: 0.360938] [G loss: 1.231941]\n",
      "[Epoch 3/30] [Batch 354/938] [D loss: 0.343261] [G loss: 1.357667]\n",
      "[Epoch 3/30] [Batch 355/938] [D loss: 0.365002] [G loss: 1.413914]\n",
      "[Epoch 3/30] [Batch 356/938] [D loss: 0.399298] [G loss: 1.242750]\n",
      "[Epoch 3/30] [Batch 357/938] [D loss: 0.438130] [G loss: 1.037945]\n",
      "[Epoch 3/30] [Batch 358/938] [D loss: 0.407815] [G loss: 1.586870]\n",
      "[Epoch 3/30] [Batch 359/938] [D loss: 0.476141] [G loss: 0.700551]\n",
      "[Epoch 3/30] [Batch 360/938] [D loss: 0.560180] [G loss: 2.809915]\n",
      "[Epoch 3/30] [Batch 361/938] [D loss: 0.675287] [G loss: 0.352072]\n",
      "[Epoch 3/30] [Batch 362/938] [D loss: 0.718087] [G loss: 3.661102]\n",
      "[Epoch 3/30] [Batch 363/938] [D loss: 0.464077] [G loss: 0.645627]\n",
      "[Epoch 3/30] [Batch 364/938] [D loss: 0.316617] [G loss: 2.136333]\n",
      "[Epoch 3/30] [Batch 365/938] [D loss: 0.328934] [G loss: 1.281140]\n",
      "[Epoch 3/30] [Batch 366/938] [D loss: 0.320603] [G loss: 1.273673]\n",
      "[Epoch 3/30] [Batch 367/938] [D loss: 0.358237] [G loss: 1.877053]\n",
      "[Epoch 3/30] [Batch 368/938] [D loss: 0.396971] [G loss: 0.915976]\n",
      "[Epoch 3/30] [Batch 369/938] [D loss: 0.333089] [G loss: 1.829741]\n",
      "[Epoch 3/30] [Batch 370/938] [D loss: 0.428437] [G loss: 1.216058]\n",
      "[Epoch 3/30] [Batch 371/938] [D loss: 0.524996] [G loss: 0.872282]\n",
      "[Epoch 3/30] [Batch 372/938] [D loss: 0.378437] [G loss: 1.615574]\n",
      "[Epoch 3/30] [Batch 373/938] [D loss: 0.412341] [G loss: 1.019410]\n",
      "[Epoch 3/30] [Batch 374/938] [D loss: 0.430995] [G loss: 1.562959]\n",
      "[Epoch 3/30] [Batch 375/938] [D loss: 0.534024] [G loss: 0.678815]\n",
      "[Epoch 3/30] [Batch 376/938] [D loss: 0.534661] [G loss: 2.272970]\n",
      "[Epoch 3/30] [Batch 377/938] [D loss: 0.640028] [G loss: 0.422223]\n",
      "[Epoch 3/30] [Batch 378/938] [D loss: 0.820335] [G loss: 3.239282]\n",
      "[Epoch 3/30] [Batch 379/938] [D loss: 0.628085] [G loss: 0.426372]\n",
      "[Epoch 3/30] [Batch 380/938] [D loss: 0.575537] [G loss: 2.629047]\n",
      "[Epoch 3/30] [Batch 381/938] [D loss: 0.540188] [G loss: 0.613330]\n",
      "[Epoch 3/30] [Batch 382/938] [D loss: 0.403140] [G loss: 1.872732]\n",
      "[Epoch 3/30] [Batch 383/938] [D loss: 0.395882] [G loss: 1.062985]\n",
      "[Epoch 3/30] [Batch 384/938] [D loss: 0.390154] [G loss: 1.294578]\n",
      "[Epoch 3/30] [Batch 385/938] [D loss: 0.346255] [G loss: 1.274515]\n",
      "[Epoch 3/30] [Batch 386/938] [D loss: 0.343039] [G loss: 1.429443]\n",
      "[Epoch 3/30] [Batch 387/938] [D loss: 0.395777] [G loss: 1.390956]\n",
      "[Epoch 3/30] [Batch 388/938] [D loss: 0.426147] [G loss: 1.115890]\n",
      "[Epoch 3/30] [Batch 389/938] [D loss: 0.368290] [G loss: 1.313727]\n",
      "[Epoch 3/30] [Batch 390/938] [D loss: 0.484955] [G loss: 1.351717]\n",
      "[Epoch 3/30] [Batch 391/938] [D loss: 0.485460] [G loss: 0.723259]\n",
      "[Epoch 3/30] [Batch 392/938] [D loss: 0.412600] [G loss: 2.000477]\n",
      "[Epoch 3/30] [Batch 393/938] [D loss: 0.430496] [G loss: 0.854349]\n",
      "[Epoch 3/30] [Batch 394/938] [D loss: 0.395645] [G loss: 1.569685]\n",
      "[Epoch 3/30] [Batch 395/938] [D loss: 0.395019] [G loss: 0.902182]\n",
      "[Epoch 3/30] [Batch 396/938] [D loss: 0.513185] [G loss: 1.908622]\n",
      "[Epoch 3/30] [Batch 397/938] [D loss: 0.647081] [G loss: 0.424019]\n",
      "[Epoch 3/30] [Batch 398/938] [D loss: 0.627741] [G loss: 2.721960]\n",
      "[Epoch 3/30] [Batch 399/938] [D loss: 0.491621] [G loss: 0.614943]\n",
      "[Epoch 3/30] [Batch 400/938] [D loss: 0.435707] [G loss: 1.901674]\n",
      "[Epoch 3/30] [Batch 401/938] [D loss: 0.414789] [G loss: 0.898707]\n",
      "[Epoch 3/30] [Batch 402/938] [D loss: 0.304566] [G loss: 1.471792]\n",
      "[Epoch 3/30] [Batch 403/938] [D loss: 0.338742] [G loss: 1.542679]\n",
      "[Epoch 3/30] [Batch 404/938] [D loss: 0.469455] [G loss: 0.841897]\n",
      "[Epoch 3/30] [Batch 405/938] [D loss: 0.437760] [G loss: 1.627384]\n",
      "[Epoch 3/30] [Batch 406/938] [D loss: 0.397531] [G loss: 0.905049]\n",
      "[Epoch 3/30] [Batch 407/938] [D loss: 0.383193] [G loss: 1.735662]\n",
      "[Epoch 3/30] [Batch 408/938] [D loss: 0.455334] [G loss: 0.792434]\n",
      "[Epoch 3/30] [Batch 409/938] [D loss: 0.387767] [G loss: 1.766764]\n",
      "[Epoch 3/30] [Batch 410/938] [D loss: 0.390850] [G loss: 1.064162]\n",
      "[Epoch 3/30] [Batch 411/938] [D loss: 0.478057] [G loss: 1.233741]\n",
      "[Epoch 3/30] [Batch 412/938] [D loss: 0.392991] [G loss: 1.019147]\n",
      "[Epoch 3/30] [Batch 413/938] [D loss: 0.353075] [G loss: 1.565490]\n",
      "[Epoch 3/30] [Batch 414/938] [D loss: 0.402305] [G loss: 1.005148]\n",
      "[Epoch 3/30] [Batch 415/938] [D loss: 0.381269] [G loss: 1.643543]\n",
      "[Epoch 3/30] [Batch 416/938] [D loss: 0.357992] [G loss: 1.023913]\n",
      "[Epoch 3/30] [Batch 417/938] [D loss: 0.327824] [G loss: 1.557830]\n",
      "[Epoch 3/30] [Batch 418/938] [D loss: 0.399007] [G loss: 1.414273]\n",
      "[Epoch 3/30] [Batch 419/938] [D loss: 0.474969] [G loss: 0.761765]\n",
      "[Epoch 3/30] [Batch 420/938] [D loss: 0.479623] [G loss: 2.250699]\n",
      "[Epoch 3/30] [Batch 421/938] [D loss: 0.473030] [G loss: 0.647662]\n",
      "[Epoch 3/30] [Batch 422/938] [D loss: 0.489419] [G loss: 2.453857]\n",
      "[Epoch 3/30] [Batch 423/938] [D loss: 0.428304] [G loss: 0.774035]\n",
      "[Epoch 3/30] [Batch 424/938] [D loss: 0.308615] [G loss: 1.881121]\n",
      "[Epoch 3/30] [Batch 425/938] [D loss: 0.332314] [G loss: 1.288981]\n",
      "[Epoch 3/30] [Batch 426/938] [D loss: 0.360074] [G loss: 1.415142]\n",
      "[Epoch 3/30] [Batch 427/938] [D loss: 0.345977] [G loss: 1.229857]\n",
      "[Epoch 3/30] [Batch 428/938] [D loss: 0.387169] [G loss: 1.483550]\n",
      "[Epoch 3/30] [Batch 429/938] [D loss: 0.366811] [G loss: 1.191893]\n",
      "[Epoch 3/30] [Batch 430/938] [D loss: 0.318837] [G loss: 1.431443]\n",
      "[Epoch 3/30] [Batch 431/938] [D loss: 0.338128] [G loss: 1.402503]\n",
      "[Epoch 3/30] [Batch 432/938] [D loss: 0.362518] [G loss: 1.237713]\n",
      "[Epoch 3/30] [Batch 433/938] [D loss: 0.287406] [G loss: 1.547378]\n",
      "[Epoch 3/30] [Batch 434/938] [D loss: 0.340823] [G loss: 1.375787]\n",
      "[Epoch 3/30] [Batch 435/938] [D loss: 0.362851] [G loss: 1.682380]\n",
      "[Epoch 3/30] [Batch 436/938] [D loss: 0.412154] [G loss: 0.833541]\n",
      "[Epoch 3/30] [Batch 437/938] [D loss: 0.420527] [G loss: 2.271402]\n",
      "[Epoch 3/30] [Batch 438/938] [D loss: 0.444534] [G loss: 0.763469]\n",
      "[Epoch 3/30] [Batch 439/938] [D loss: 0.475500] [G loss: 2.197538]\n",
      "[Epoch 3/30] [Batch 440/938] [D loss: 0.477062] [G loss: 0.623419]\n",
      "[Epoch 3/30] [Batch 441/938] [D loss: 0.401794] [G loss: 2.553355]\n",
      "[Epoch 3/30] [Batch 442/938] [D loss: 0.319276] [G loss: 1.084424]\n",
      "[Epoch 3/30] [Batch 443/938] [D loss: 0.260314] [G loss: 1.621990]\n",
      "[Epoch 3/30] [Batch 444/938] [D loss: 0.251893] [G loss: 1.707695]\n",
      "[Epoch 3/30] [Batch 445/938] [D loss: 0.333914] [G loss: 1.475098]\n",
      "[Epoch 3/30] [Batch 446/938] [D loss: 0.335296] [G loss: 1.052347]\n",
      "[Epoch 3/30] [Batch 447/938] [D loss: 0.339044] [G loss: 2.191071]\n",
      "[Epoch 3/30] [Batch 448/938] [D loss: 0.346692] [G loss: 1.016304]\n",
      "[Epoch 3/30] [Batch 449/938] [D loss: 0.348678] [G loss: 1.911653]\n",
      "[Epoch 3/30] [Batch 450/938] [D loss: 0.360816] [G loss: 1.182044]\n",
      "[Epoch 3/30] [Batch 451/938] [D loss: 0.365231] [G loss: 1.531825]\n",
      "[Epoch 3/30] [Batch 452/938] [D loss: 0.387381] [G loss: 1.045496]\n",
      "[Epoch 3/30] [Batch 453/938] [D loss: 0.414985] [G loss: 1.666131]\n",
      "[Epoch 3/30] [Batch 454/938] [D loss: 0.451349] [G loss: 0.772726]\n",
      "[Epoch 3/30] [Batch 455/938] [D loss: 0.476770] [G loss: 2.681336]\n",
      "[Epoch 3/30] [Batch 456/938] [D loss: 0.412103] [G loss: 0.831324]\n",
      "[Epoch 3/30] [Batch 457/938] [D loss: 0.370388] [G loss: 1.917401]\n",
      "[Epoch 3/30] [Batch 458/938] [D loss: 0.395848] [G loss: 1.014728]\n",
      "[Epoch 3/30] [Batch 459/938] [D loss: 0.373072] [G loss: 1.638977]\n",
      "[Epoch 3/30] [Batch 460/938] [D loss: 0.407402] [G loss: 1.086386]\n",
      "[Epoch 3/30] [Batch 461/938] [D loss: 0.400110] [G loss: 1.192496]\n",
      "[Epoch 3/30] [Batch 462/938] [D loss: 0.364360] [G loss: 1.482922]\n",
      "[Epoch 3/30] [Batch 463/938] [D loss: 0.405302] [G loss: 1.059516]\n",
      "[Epoch 3/30] [Batch 464/938] [D loss: 0.341264] [G loss: 1.336026]\n",
      "[Epoch 3/30] [Batch 465/938] [D loss: 0.392709] [G loss: 1.521664]\n",
      "[Epoch 3/30] [Batch 466/938] [D loss: 0.386641] [G loss: 0.985687]\n",
      "[Epoch 3/30] [Batch 467/938] [D loss: 0.388793] [G loss: 1.949513]\n",
      "[Epoch 3/30] [Batch 468/938] [D loss: 0.448465] [G loss: 0.871263]\n",
      "[Epoch 3/30] [Batch 469/938] [D loss: 0.422180] [G loss: 1.599550]\n",
      "[Epoch 3/30] [Batch 470/938] [D loss: 0.397339] [G loss: 0.942160]\n",
      "[Epoch 3/30] [Batch 471/938] [D loss: 0.321533] [G loss: 1.942994]\n",
      "[Epoch 3/30] [Batch 472/938] [D loss: 0.360111] [G loss: 1.227509]\n",
      "[Epoch 3/30] [Batch 473/938] [D loss: 0.414915] [G loss: 1.167420]\n",
      "[Epoch 3/30] [Batch 474/938] [D loss: 0.405095] [G loss: 1.328295]\n",
      "[Epoch 3/30] [Batch 475/938] [D loss: 0.364199] [G loss: 1.111665]\n",
      "[Epoch 3/30] [Batch 476/938] [D loss: 0.339839] [G loss: 1.784045]\n",
      "[Epoch 3/30] [Batch 477/938] [D loss: 0.335622] [G loss: 1.150997]\n",
      "[Epoch 3/30] [Batch 478/938] [D loss: 0.342077] [G loss: 1.510594]\n",
      "[Epoch 3/30] [Batch 479/938] [D loss: 0.308348] [G loss: 1.247885]\n",
      "[Epoch 3/30] [Batch 480/938] [D loss: 0.319281] [G loss: 1.801010]\n",
      "[Epoch 3/30] [Batch 481/938] [D loss: 0.420926] [G loss: 1.122384]\n",
      "[Epoch 3/30] [Batch 482/938] [D loss: 0.319842] [G loss: 1.343386]\n",
      "[Epoch 3/30] [Batch 483/938] [D loss: 0.336518] [G loss: 1.559777]\n",
      "[Epoch 3/30] [Batch 484/938] [D loss: 0.379329] [G loss: 0.901804]\n",
      "[Epoch 3/30] [Batch 485/938] [D loss: 0.438632] [G loss: 2.342592]\n",
      "[Epoch 3/30] [Batch 486/938] [D loss: 0.533065] [G loss: 0.534891]\n",
      "[Epoch 3/30] [Batch 487/938] [D loss: 0.581160] [G loss: 3.035653]\n",
      "[Epoch 3/30] [Batch 488/938] [D loss: 0.550368] [G loss: 0.605168]\n",
      "[Epoch 3/30] [Batch 489/938] [D loss: 0.332500] [G loss: 2.012318]\n",
      "[Epoch 3/30] [Batch 490/938] [D loss: 0.284444] [G loss: 1.379077]\n",
      "[Epoch 3/30] [Batch 491/938] [D loss: 0.340597] [G loss: 1.523420]\n",
      "[Epoch 3/30] [Batch 492/938] [D loss: 0.357207] [G loss: 1.101841]\n",
      "[Epoch 3/30] [Batch 493/938] [D loss: 0.369537] [G loss: 1.779915]\n",
      "[Epoch 3/30] [Batch 494/938] [D loss: 0.406752] [G loss: 0.843473]\n",
      "[Epoch 3/30] [Batch 495/938] [D loss: 0.448641] [G loss: 2.214890]\n",
      "[Epoch 3/30] [Batch 496/938] [D loss: 0.630567] [G loss: 0.474039]\n",
      "[Epoch 3/30] [Batch 497/938] [D loss: 0.596142] [G loss: 2.776832]\n",
      "[Epoch 3/30] [Batch 498/938] [D loss: 0.558461] [G loss: 0.540987]\n",
      "[Epoch 3/30] [Batch 499/938] [D loss: 0.354214] [G loss: 2.232196]\n",
      "[Epoch 3/30] [Batch 500/938] [D loss: 0.369428] [G loss: 1.091667]\n",
      "[Epoch 3/30] [Batch 501/938] [D loss: 0.345518] [G loss: 1.277984]\n",
      "[Epoch 3/30] [Batch 502/938] [D loss: 0.477369] [G loss: 1.627655]\n",
      "[Epoch 3/30] [Batch 503/938] [D loss: 0.514883] [G loss: 0.633531]\n",
      "[Epoch 3/30] [Batch 504/938] [D loss: 0.596675] [G loss: 2.687628]\n",
      "[Epoch 3/30] [Batch 505/938] [D loss: 0.605840] [G loss: 0.492556]\n",
      "[Epoch 3/30] [Batch 506/938] [D loss: 0.440873] [G loss: 2.432807]\n",
      "[Epoch 3/30] [Batch 507/938] [D loss: 0.416882] [G loss: 0.870511]\n",
      "[Epoch 3/30] [Batch 508/938] [D loss: 0.397564] [G loss: 1.675889]\n",
      "[Epoch 3/30] [Batch 509/938] [D loss: 0.412563] [G loss: 1.030232]\n",
      "[Epoch 3/30] [Batch 510/938] [D loss: 0.358978] [G loss: 1.392965]\n",
      "[Epoch 3/30] [Batch 511/938] [D loss: 0.367003] [G loss: 1.319698]\n",
      "[Epoch 3/30] [Batch 512/938] [D loss: 0.380721] [G loss: 1.298661]\n",
      "[Epoch 3/30] [Batch 513/938] [D loss: 0.354213] [G loss: 1.110510]\n",
      "[Epoch 3/30] [Batch 514/938] [D loss: 0.408440] [G loss: 1.883374]\n",
      "[Epoch 3/30] [Batch 515/938] [D loss: 0.534910] [G loss: 0.633623]\n",
      "[Epoch 3/30] [Batch 516/938] [D loss: 0.535198] [G loss: 2.382762]\n",
      "[Epoch 3/30] [Batch 517/938] [D loss: 0.683878] [G loss: 0.414083]\n",
      "[Epoch 3/30] [Batch 518/938] [D loss: 0.702819] [G loss: 2.804665]\n",
      "[Epoch 3/30] [Batch 519/938] [D loss: 0.661130] [G loss: 0.408150]\n",
      "[Epoch 3/30] [Batch 520/938] [D loss: 0.513748] [G loss: 3.116976]\n",
      "[Epoch 3/30] [Batch 521/938] [D loss: 0.343719] [G loss: 1.105344]\n",
      "[Epoch 3/30] [Batch 522/938] [D loss: 0.371596] [G loss: 1.355877]\n",
      "[Epoch 3/30] [Batch 523/938] [D loss: 0.344059] [G loss: 1.364474]\n",
      "[Epoch 3/30] [Batch 524/938] [D loss: 0.386467] [G loss: 1.695260]\n",
      "[Epoch 3/30] [Batch 525/938] [D loss: 0.414460] [G loss: 0.859184]\n",
      "[Epoch 3/30] [Batch 526/938] [D loss: 0.464088] [G loss: 2.240614]\n",
      "[Epoch 3/30] [Batch 527/938] [D loss: 0.525869] [G loss: 0.644678]\n",
      "[Epoch 3/30] [Batch 528/938] [D loss: 0.496934] [G loss: 2.326190]\n",
      "[Epoch 3/30] [Batch 529/938] [D loss: 0.506926] [G loss: 0.760820]\n",
      "[Epoch 3/30] [Batch 530/938] [D loss: 0.378550] [G loss: 1.620563]\n",
      "[Epoch 3/30] [Batch 531/938] [D loss: 0.429216] [G loss: 1.132541]\n",
      "[Epoch 3/30] [Batch 532/938] [D loss: 0.396974] [G loss: 1.185913]\n",
      "[Epoch 3/30] [Batch 533/938] [D loss: 0.332394] [G loss: 1.544523]\n",
      "[Epoch 3/30] [Batch 534/938] [D loss: 0.398640] [G loss: 1.299072]\n",
      "[Epoch 3/30] [Batch 535/938] [D loss: 0.407274] [G loss: 1.018634]\n",
      "[Epoch 3/30] [Batch 536/938] [D loss: 0.407687] [G loss: 1.773864]\n",
      "[Epoch 3/30] [Batch 537/938] [D loss: 0.421368] [G loss: 0.762839]\n",
      "[Epoch 3/30] [Batch 538/938] [D loss: 0.510052] [G loss: 2.374719]\n",
      "[Epoch 3/30] [Batch 539/938] [D loss: 0.500548] [G loss: 0.615532]\n",
      "[Epoch 3/30] [Batch 540/938] [D loss: 0.491301] [G loss: 2.431359]\n",
      "[Epoch 3/30] [Batch 541/938] [D loss: 0.532965] [G loss: 0.640217]\n",
      "[Epoch 3/30] [Batch 542/938] [D loss: 0.415725] [G loss: 1.971419]\n",
      "[Epoch 3/30] [Batch 543/938] [D loss: 0.420175] [G loss: 0.974090]\n",
      "[Epoch 3/30] [Batch 544/938] [D loss: 0.356955] [G loss: 1.247004]\n",
      "[Epoch 3/30] [Batch 545/938] [D loss: 0.392709] [G loss: 1.494967]\n",
      "[Epoch 3/30] [Batch 546/938] [D loss: 0.453302] [G loss: 0.779906]\n",
      "[Epoch 3/30] [Batch 547/938] [D loss: 0.487772] [G loss: 2.129947]\n",
      "[Epoch 3/30] [Batch 548/938] [D loss: 0.555101] [G loss: 0.499625]\n",
      "[Epoch 3/30] [Batch 549/938] [D loss: 0.738800] [G loss: 3.008666]\n",
      "[Epoch 3/30] [Batch 550/938] [D loss: 0.645942] [G loss: 0.398420]\n",
      "[Epoch 3/30] [Batch 551/938] [D loss: 0.526354] [G loss: 2.769134]\n",
      "[Epoch 3/30] [Batch 552/938] [D loss: 0.348942] [G loss: 0.936170]\n",
      "[Epoch 3/30] [Batch 553/938] [D loss: 0.369804] [G loss: 1.666344]\n",
      "[Epoch 3/30] [Batch 554/938] [D loss: 0.333993] [G loss: 0.987099]\n",
      "[Epoch 3/30] [Batch 555/938] [D loss: 0.400408] [G loss: 2.119479]\n",
      "[Epoch 3/30] [Batch 556/938] [D loss: 0.427871] [G loss: 0.762963]\n",
      "[Epoch 3/30] [Batch 557/938] [D loss: 0.360751] [G loss: 1.927899]\n",
      "[Epoch 3/30] [Batch 558/938] [D loss: 0.365326] [G loss: 1.235541]\n",
      "[Epoch 3/30] [Batch 559/938] [D loss: 0.348174] [G loss: 1.042335]\n",
      "[Epoch 3/30] [Batch 560/938] [D loss: 0.405152] [G loss: 1.764290]\n",
      "[Epoch 3/30] [Batch 561/938] [D loss: 0.474780] [G loss: 0.754098]\n",
      "[Epoch 3/30] [Batch 562/938] [D loss: 0.491348] [G loss: 1.921668]\n",
      "[Epoch 3/30] [Batch 563/938] [D loss: 0.475328] [G loss: 0.634962]\n",
      "[Epoch 3/30] [Batch 564/938] [D loss: 0.372995] [G loss: 2.506986]\n",
      "[Epoch 3/30] [Batch 565/938] [D loss: 0.366149] [G loss: 1.192731]\n",
      "[Epoch 3/30] [Batch 566/938] [D loss: 0.364555] [G loss: 0.987298]\n",
      "[Epoch 3/30] [Batch 567/938] [D loss: 0.435453] [G loss: 2.070286]\n",
      "[Epoch 3/30] [Batch 568/938] [D loss: 0.487761] [G loss: 0.701441]\n",
      "[Epoch 3/30] [Batch 569/938] [D loss: 0.328135] [G loss: 2.034660]\n",
      "[Epoch 3/30] [Batch 570/938] [D loss: 0.329273] [G loss: 1.180604]\n",
      "[Epoch 3/30] [Batch 571/938] [D loss: 0.382130] [G loss: 1.453276]\n",
      "[Epoch 3/30] [Batch 572/938] [D loss: 0.336637] [G loss: 1.096867]\n",
      "[Epoch 3/30] [Batch 573/938] [D loss: 0.327538] [G loss: 1.712009]\n",
      "[Epoch 3/30] [Batch 574/938] [D loss: 0.374733] [G loss: 1.288918]\n",
      "[Epoch 3/30] [Batch 575/938] [D loss: 0.339248] [G loss: 1.160085]\n",
      "[Epoch 3/30] [Batch 576/938] [D loss: 0.356852] [G loss: 1.864476]\n",
      "[Epoch 3/30] [Batch 577/938] [D loss: 0.408501] [G loss: 0.855979]\n",
      "[Epoch 3/30] [Batch 578/938] [D loss: 0.415342] [G loss: 2.171356]\n",
      "[Epoch 3/30] [Batch 579/938] [D loss: 0.464617] [G loss: 0.826172]\n",
      "[Epoch 3/30] [Batch 580/938] [D loss: 0.372089] [G loss: 1.815741]\n",
      "[Epoch 3/30] [Batch 581/938] [D loss: 0.407003] [G loss: 0.974970]\n",
      "[Epoch 3/30] [Batch 582/938] [D loss: 0.381962] [G loss: 2.122785]\n",
      "[Epoch 3/30] [Batch 583/938] [D loss: 0.492257] [G loss: 0.781426]\n",
      "[Epoch 3/30] [Batch 584/938] [D loss: 0.414265] [G loss: 2.014471]\n",
      "[Epoch 3/30] [Batch 585/938] [D loss: 0.380669] [G loss: 0.951068]\n",
      "[Epoch 3/30] [Batch 586/938] [D loss: 0.476420] [G loss: 2.022456]\n",
      "[Epoch 3/30] [Batch 587/938] [D loss: 0.559920] [G loss: 0.593011]\n",
      "[Epoch 3/30] [Batch 588/938] [D loss: 0.549885] [G loss: 2.574157]\n",
      "[Epoch 3/30] [Batch 589/938] [D loss: 0.655727] [G loss: 0.422662]\n",
      "[Epoch 3/30] [Batch 590/938] [D loss: 0.696514] [G loss: 3.064565]\n",
      "[Epoch 3/30] [Batch 591/938] [D loss: 0.563295] [G loss: 0.540219]\n",
      "[Epoch 3/30] [Batch 592/938] [D loss: 0.456846] [G loss: 2.368716]\n",
      "[Epoch 3/30] [Batch 593/938] [D loss: 0.406334] [G loss: 0.883512]\n",
      "[Epoch 3/30] [Batch 594/938] [D loss: 0.329103] [G loss: 1.610215]\n",
      "[Epoch 3/30] [Batch 595/938] [D loss: 0.311438] [G loss: 1.415059]\n",
      "[Epoch 3/30] [Batch 596/938] [D loss: 0.328030] [G loss: 1.341452]\n",
      "[Epoch 3/30] [Batch 597/938] [D loss: 0.316715] [G loss: 1.461273]\n",
      "[Epoch 3/30] [Batch 598/938] [D loss: 0.401835] [G loss: 1.405742]\n",
      "[Epoch 3/30] [Batch 599/938] [D loss: 0.367343] [G loss: 0.902534]\n",
      "[Epoch 3/30] [Batch 600/938] [D loss: 0.607024] [G loss: 2.404726]\n",
      "[Epoch 3/30] [Batch 601/938] [D loss: 0.918857] [G loss: 0.212125]\n",
      "[Epoch 3/30] [Batch 602/938] [D loss: 0.761118] [G loss: 3.553514]\n",
      "[Epoch 3/30] [Batch 603/938] [D loss: 0.377301] [G loss: 0.920838]\n",
      "[Epoch 3/30] [Batch 604/938] [D loss: 0.353393] [G loss: 1.177938]\n",
      "[Epoch 3/30] [Batch 605/938] [D loss: 0.341455] [G loss: 1.985742]\n",
      "[Epoch 3/30] [Batch 606/938] [D loss: 0.382906] [G loss: 1.162321]\n",
      "[Epoch 3/30] [Batch 607/938] [D loss: 0.383645] [G loss: 1.384162]\n",
      "[Epoch 3/30] [Batch 608/938] [D loss: 0.386925] [G loss: 1.158431]\n",
      "[Epoch 3/30] [Batch 609/938] [D loss: 0.374698] [G loss: 1.492361]\n",
      "[Epoch 3/30] [Batch 610/938] [D loss: 0.429866] [G loss: 0.929613]\n",
      "[Epoch 3/30] [Batch 611/938] [D loss: 0.345768] [G loss: 1.712388]\n",
      "[Epoch 3/30] [Batch 612/938] [D loss: 0.370918] [G loss: 1.091039]\n",
      "[Epoch 3/30] [Batch 613/938] [D loss: 0.472991] [G loss: 1.503715]\n",
      "[Epoch 3/30] [Batch 614/938] [D loss: 0.559898] [G loss: 0.574975]\n",
      "[Epoch 3/30] [Batch 615/938] [D loss: 0.695595] [G loss: 2.753847]\n",
      "[Epoch 3/30] [Batch 616/938] [D loss: 0.837352] [G loss: 0.240869]\n",
      "[Epoch 3/30] [Batch 617/938] [D loss: 0.783552] [G loss: 3.614495]\n",
      "[Epoch 3/30] [Batch 618/938] [D loss: 0.459493] [G loss: 0.702939]\n",
      "[Epoch 3/30] [Batch 619/938] [D loss: 0.311109] [G loss: 1.469641]\n",
      "[Epoch 3/30] [Batch 620/938] [D loss: 0.309258] [G loss: 1.766197]\n",
      "[Epoch 3/30] [Batch 621/938] [D loss: 0.372078] [G loss: 1.106146]\n",
      "[Epoch 3/30] [Batch 622/938] [D loss: 0.366073] [G loss: 1.513541]\n",
      "[Epoch 3/30] [Batch 623/938] [D loss: 0.339448] [G loss: 1.230946]\n",
      "[Epoch 3/30] [Batch 624/938] [D loss: 0.334979] [G loss: 1.477799]\n",
      "[Epoch 3/30] [Batch 625/938] [D loss: 0.384594] [G loss: 1.241580]\n",
      "[Epoch 3/30] [Batch 626/938] [D loss: 0.379744] [G loss: 1.281700]\n",
      "[Epoch 3/30] [Batch 627/938] [D loss: 0.462139] [G loss: 1.131422]\n",
      "[Epoch 3/30] [Batch 628/938] [D loss: 0.417557] [G loss: 1.072892]\n",
      "[Epoch 3/30] [Batch 629/938] [D loss: 0.420296] [G loss: 1.436497]\n",
      "[Epoch 3/30] [Batch 630/938] [D loss: 0.435703] [G loss: 0.979373]\n",
      "[Epoch 3/30] [Batch 631/938] [D loss: 0.477262] [G loss: 1.568381]\n",
      "[Epoch 3/30] [Batch 632/938] [D loss: 0.557563] [G loss: 0.519800]\n",
      "[Epoch 3/30] [Batch 633/938] [D loss: 0.834314] [G loss: 3.333977]\n",
      "[Epoch 3/30] [Batch 634/938] [D loss: 0.633849] [G loss: 0.437679]\n",
      "[Epoch 3/30] [Batch 635/938] [D loss: 0.625204] [G loss: 2.603882]\n",
      "[Epoch 3/30] [Batch 636/938] [D loss: 0.566704] [G loss: 0.507371]\n",
      "[Epoch 3/30] [Batch 637/938] [D loss: 0.541162] [G loss: 2.704218]\n",
      "[Epoch 3/30] [Batch 638/938] [D loss: 0.425309] [G loss: 0.760012]\n",
      "[Epoch 3/30] [Batch 639/938] [D loss: 0.298358] [G loss: 2.005173]\n",
      "[Epoch 3/30] [Batch 640/938] [D loss: 0.313631] [G loss: 1.392627]\n",
      "[Epoch 3/30] [Batch 641/938] [D loss: 0.355809] [G loss: 1.125784]\n",
      "[Epoch 3/30] [Batch 642/938] [D loss: 0.370513] [G loss: 1.746187]\n",
      "[Epoch 3/30] [Batch 643/938] [D loss: 0.353837] [G loss: 1.039866]\n",
      "[Epoch 3/30] [Batch 644/938] [D loss: 0.384144] [G loss: 1.734843]\n",
      "[Epoch 3/30] [Batch 645/938] [D loss: 0.411899] [G loss: 0.911660]\n",
      "[Epoch 3/30] [Batch 646/938] [D loss: 0.343578] [G loss: 1.726098]\n",
      "[Epoch 3/30] [Batch 647/938] [D loss: 0.366711] [G loss: 1.252129]\n",
      "[Epoch 3/30] [Batch 648/938] [D loss: 0.353229] [G loss: 1.133810]\n",
      "[Epoch 3/30] [Batch 649/938] [D loss: 0.352906] [G loss: 1.851152]\n",
      "[Epoch 3/30] [Batch 650/938] [D loss: 0.387267] [G loss: 0.857547]\n",
      "[Epoch 3/30] [Batch 651/938] [D loss: 0.506033] [G loss: 2.389196]\n",
      "[Epoch 3/30] [Batch 652/938] [D loss: 0.609499] [G loss: 0.406042]\n",
      "[Epoch 3/30] [Batch 653/938] [D loss: 0.579807] [G loss: 3.492457]\n",
      "[Epoch 3/30] [Batch 654/938] [D loss: 0.310051] [G loss: 1.235105]\n",
      "[Epoch 3/30] [Batch 655/938] [D loss: 0.405684] [G loss: 0.837667]\n",
      "[Epoch 3/30] [Batch 656/938] [D loss: 0.429024] [G loss: 2.350997]\n",
      "[Epoch 3/30] [Batch 657/938] [D loss: 0.421639] [G loss: 0.753152]\n",
      "[Epoch 3/30] [Batch 658/938] [D loss: 0.363104] [G loss: 2.177384]\n",
      "[Epoch 3/30] [Batch 659/938] [D loss: 0.377737] [G loss: 0.899946]\n",
      "[Epoch 3/30] [Batch 660/938] [D loss: 0.330454] [G loss: 1.885073]\n",
      "[Epoch 3/30] [Batch 661/938] [D loss: 0.352296] [G loss: 1.152037]\n",
      "[Epoch 3/30] [Batch 662/938] [D loss: 0.356813] [G loss: 1.367971]\n",
      "[Epoch 3/30] [Batch 663/938] [D loss: 0.421235] [G loss: 1.383740]\n",
      "[Epoch 3/30] [Batch 664/938] [D loss: 0.462881] [G loss: 0.758839]\n",
      "[Epoch 3/30] [Batch 665/938] [D loss: 0.487480] [G loss: 2.342770]\n",
      "[Epoch 3/30] [Batch 666/938] [D loss: 0.505372] [G loss: 0.596361]\n",
      "[Epoch 3/30] [Batch 667/938] [D loss: 0.470110] [G loss: 2.404255]\n",
      "[Epoch 3/30] [Batch 668/938] [D loss: 0.464535] [G loss: 0.643775]\n",
      "[Epoch 3/30] [Batch 669/938] [D loss: 0.441459] [G loss: 2.330611]\n",
      "[Epoch 3/30] [Batch 670/938] [D loss: 0.365910] [G loss: 0.934832]\n",
      "[Epoch 3/30] [Batch 671/938] [D loss: 0.446598] [G loss: 1.743173]\n",
      "[Epoch 3/30] [Batch 672/938] [D loss: 0.472200] [G loss: 0.687321]\n",
      "[Epoch 3/30] [Batch 673/938] [D loss: 0.482312] [G loss: 2.433448]\n",
      "[Epoch 3/30] [Batch 674/938] [D loss: 0.407904] [G loss: 0.804691]\n",
      "[Epoch 3/30] [Batch 675/938] [D loss: 0.374736] [G loss: 1.807945]\n",
      "[Epoch 3/30] [Batch 676/938] [D loss: 0.360689] [G loss: 1.154300]\n",
      "[Epoch 3/30] [Batch 677/938] [D loss: 0.337431] [G loss: 1.206433]\n",
      "[Epoch 3/30] [Batch 678/938] [D loss: 0.325190] [G loss: 1.691316]\n",
      "[Epoch 3/30] [Batch 679/938] [D loss: 0.355922] [G loss: 1.024544]\n",
      "[Epoch 3/30] [Batch 680/938] [D loss: 0.369690] [G loss: 1.824115]\n",
      "[Epoch 3/30] [Batch 681/938] [D loss: 0.407900] [G loss: 0.910171]\n",
      "[Epoch 3/30] [Batch 682/938] [D loss: 0.411715] [G loss: 1.684005]\n",
      "[Epoch 3/30] [Batch 683/938] [D loss: 0.399956] [G loss: 0.827776]\n",
      "[Epoch 3/30] [Batch 684/938] [D loss: 0.457373] [G loss: 2.121632]\n",
      "[Epoch 3/30] [Batch 685/938] [D loss: 0.480765] [G loss: 0.673616]\n",
      "[Epoch 3/30] [Batch 686/938] [D loss: 0.406149] [G loss: 2.050557]\n",
      "[Epoch 3/30] [Batch 687/938] [D loss: 0.396245] [G loss: 0.878855]\n",
      "[Epoch 3/30] [Batch 688/938] [D loss: 0.452911] [G loss: 1.723218]\n",
      "[Epoch 3/30] [Batch 689/938] [D loss: 0.414768] [G loss: 0.846208]\n",
      "[Epoch 3/30] [Batch 690/938] [D loss: 0.394685] [G loss: 1.796574]\n",
      "[Epoch 3/30] [Batch 691/938] [D loss: 0.408715] [G loss: 0.888816]\n",
      "[Epoch 3/30] [Batch 692/938] [D loss: 0.371593] [G loss: 1.763317]\n",
      "[Epoch 3/30] [Batch 693/938] [D loss: 0.413805] [G loss: 0.895037]\n",
      "[Epoch 3/30] [Batch 694/938] [D loss: 0.372942] [G loss: 1.949269]\n",
      "[Epoch 3/30] [Batch 695/938] [D loss: 0.360806] [G loss: 1.044622]\n",
      "[Epoch 3/30] [Batch 696/938] [D loss: 0.375291] [G loss: 1.348232]\n",
      "[Epoch 3/30] [Batch 697/938] [D loss: 0.366266] [G loss: 1.424275]\n",
      "[Epoch 3/30] [Batch 698/938] [D loss: 0.372586] [G loss: 1.211631]\n",
      "[Epoch 3/30] [Batch 699/938] [D loss: 0.388427] [G loss: 1.226017]\n",
      "[Epoch 3/30] [Batch 700/938] [D loss: 0.356287] [G loss: 1.132692]\n",
      "[Epoch 3/30] [Batch 701/938] [D loss: 0.417503] [G loss: 1.888213]\n",
      "[Epoch 3/30] [Batch 702/938] [D loss: 0.473495] [G loss: 0.641639]\n",
      "[Epoch 3/30] [Batch 703/938] [D loss: 0.463351] [G loss: 2.547097]\n",
      "[Epoch 3/30] [Batch 704/938] [D loss: 0.397626] [G loss: 0.814487]\n",
      "[Epoch 3/30] [Batch 705/938] [D loss: 0.331598] [G loss: 1.792344]\n",
      "[Epoch 3/30] [Batch 706/938] [D loss: 0.325000] [G loss: 1.106297]\n",
      "[Epoch 3/30] [Batch 707/938] [D loss: 0.282672] [G loss: 1.847600]\n",
      "[Epoch 3/30] [Batch 708/938] [D loss: 0.370753] [G loss: 1.366549]\n",
      "[Epoch 3/30] [Batch 709/938] [D loss: 0.385530] [G loss: 1.019670]\n",
      "[Epoch 3/30] [Batch 710/938] [D loss: 0.427370] [G loss: 1.852603]\n",
      "[Epoch 3/30] [Batch 711/938] [D loss: 0.553597] [G loss: 0.518112]\n",
      "[Epoch 3/30] [Batch 712/938] [D loss: 0.708014] [G loss: 2.892660]\n",
      "[Epoch 3/30] [Batch 713/938] [D loss: 0.599800] [G loss: 0.434082]\n",
      "[Epoch 3/30] [Batch 714/938] [D loss: 0.540092] [G loss: 2.747725]\n",
      "[Epoch 3/30] [Batch 715/938] [D loss: 0.420175] [G loss: 0.824307]\n",
      "[Epoch 3/30] [Batch 716/938] [D loss: 0.331247] [G loss: 1.424581]\n",
      "[Epoch 3/30] [Batch 717/938] [D loss: 0.380200] [G loss: 1.660154]\n",
      "[Epoch 3/30] [Batch 718/938] [D loss: 0.499051] [G loss: 0.639493]\n",
      "[Epoch 3/30] [Batch 719/938] [D loss: 0.661574] [G loss: 2.563175]\n",
      "[Epoch 3/30] [Batch 720/938] [D loss: 0.753082] [G loss: 0.297114]\n",
      "[Epoch 3/30] [Batch 721/938] [D loss: 0.668987] [G loss: 2.971844]\n",
      "[Epoch 3/30] [Batch 722/938] [D loss: 0.420094] [G loss: 0.767697]\n",
      "[Epoch 3/30] [Batch 723/938] [D loss: 0.282581] [G loss: 1.712982]\n",
      "[Epoch 3/30] [Batch 724/938] [D loss: 0.329965] [G loss: 1.700116]\n",
      "[Epoch 3/30] [Batch 725/938] [D loss: 0.394930] [G loss: 0.851309]\n",
      "[Epoch 3/30] [Batch 726/938] [D loss: 0.401650] [G loss: 1.975426]\n",
      "[Epoch 3/30] [Batch 727/938] [D loss: 0.420633] [G loss: 0.946093]\n",
      "[Epoch 3/30] [Batch 728/938] [D loss: 0.353015] [G loss: 1.354328]\n",
      "[Epoch 3/30] [Batch 729/938] [D loss: 0.386973] [G loss: 1.425948]\n",
      "[Epoch 3/30] [Batch 730/938] [D loss: 0.431150] [G loss: 0.837438]\n",
      "[Epoch 3/30] [Batch 731/938] [D loss: 0.487803] [G loss: 2.059280]\n",
      "[Epoch 3/30] [Batch 732/938] [D loss: 0.589191] [G loss: 0.468254]\n",
      "[Epoch 3/30] [Batch 733/938] [D loss: 0.575323] [G loss: 2.889414]\n",
      "[Epoch 3/30] [Batch 734/938] [D loss: 0.507732] [G loss: 0.577456]\n",
      "[Epoch 3/30] [Batch 735/938] [D loss: 0.408317] [G loss: 2.044376]\n",
      "[Epoch 3/30] [Batch 736/938] [D loss: 0.434036] [G loss: 0.988181]\n",
      "[Epoch 3/30] [Batch 737/938] [D loss: 0.403638] [G loss: 0.992469]\n",
      "[Epoch 3/30] [Batch 738/938] [D loss: 0.386456] [G loss: 1.892902]\n",
      "[Epoch 3/30] [Batch 739/938] [D loss: 0.429193] [G loss: 0.779441]\n",
      "[Epoch 3/30] [Batch 740/938] [D loss: 0.403829] [G loss: 1.823558]\n",
      "[Epoch 3/30] [Batch 741/938] [D loss: 0.434502] [G loss: 0.834072]\n",
      "[Epoch 3/30] [Batch 742/938] [D loss: 0.399865] [G loss: 1.576310]\n",
      "[Epoch 3/30] [Batch 743/938] [D loss: 0.444623] [G loss: 0.857012]\n",
      "[Epoch 3/30] [Batch 744/938] [D loss: 0.450319] [G loss: 1.469907]\n",
      "[Epoch 3/30] [Batch 745/938] [D loss: 0.474655] [G loss: 0.666687]\n",
      "[Epoch 3/30] [Batch 746/938] [D loss: 0.500229] [G loss: 2.478275]\n",
      "[Epoch 3/30] [Batch 747/938] [D loss: 0.521655] [G loss: 0.540081]\n",
      "[Epoch 3/30] [Batch 748/938] [D loss: 0.625286] [G loss: 2.596456]\n",
      "[Epoch 3/30] [Batch 749/938] [D loss: 0.670877] [G loss: 0.355866]\n",
      "[Epoch 3/30] [Batch 750/938] [D loss: 0.580676] [G loss: 2.963877]\n",
      "[Epoch 3/30] [Batch 751/938] [D loss: 0.423252] [G loss: 0.697389]\n",
      "[Epoch 3/30] [Batch 752/938] [D loss: 0.355096] [G loss: 2.023891]\n",
      "[Epoch 3/30] [Batch 753/938] [D loss: 0.347458] [G loss: 1.134402]\n",
      "[Epoch 3/30] [Batch 754/938] [D loss: 0.351494] [G loss: 1.359124]\n",
      "[Epoch 3/30] [Batch 755/938] [D loss: 0.334829] [G loss: 1.363837]\n",
      "[Epoch 3/30] [Batch 756/938] [D loss: 0.330689] [G loss: 1.324140]\n",
      "[Epoch 3/30] [Batch 757/938] [D loss: 0.410548] [G loss: 1.357794]\n",
      "[Epoch 3/30] [Batch 758/938] [D loss: 0.439618] [G loss: 0.795687]\n",
      "[Epoch 3/30] [Batch 759/938] [D loss: 0.500613] [G loss: 2.129014]\n",
      "[Epoch 3/30] [Batch 760/938] [D loss: 0.548179] [G loss: 0.545995]\n",
      "[Epoch 3/30] [Batch 761/938] [D loss: 0.511677] [G loss: 2.306254]\n",
      "[Epoch 3/30] [Batch 762/938] [D loss: 0.475436] [G loss: 0.651441]\n",
      "[Epoch 3/30] [Batch 763/938] [D loss: 0.417512] [G loss: 2.090815]\n",
      "[Epoch 3/30] [Batch 764/938] [D loss: 0.363478] [G loss: 1.116569]\n",
      "[Epoch 3/30] [Batch 765/938] [D loss: 0.356714] [G loss: 1.279332]\n",
      "[Epoch 3/30] [Batch 766/938] [D loss: 0.362408] [G loss: 1.470134]\n",
      "[Epoch 3/30] [Batch 767/938] [D loss: 0.355672] [G loss: 1.092761]\n",
      "[Epoch 3/30] [Batch 768/938] [D loss: 0.413829] [G loss: 1.640409]\n",
      "[Epoch 3/30] [Batch 769/938] [D loss: 0.438178] [G loss: 0.744175]\n",
      "[Epoch 3/30] [Batch 770/938] [D loss: 0.559921] [G loss: 2.123374]\n",
      "[Epoch 3/30] [Batch 771/938] [D loss: 0.599922] [G loss: 0.455766]\n",
      "[Epoch 3/30] [Batch 772/938] [D loss: 0.564571] [G loss: 2.416466]\n",
      "[Epoch 3/30] [Batch 773/938] [D loss: 0.477724] [G loss: 0.671592]\n",
      "[Epoch 3/30] [Batch 774/938] [D loss: 0.443262] [G loss: 1.932739]\n",
      "[Epoch 3/30] [Batch 775/938] [D loss: 0.427670] [G loss: 0.858092]\n",
      "[Epoch 3/30] [Batch 776/938] [D loss: 0.410528] [G loss: 1.472946]\n",
      "[Epoch 3/30] [Batch 777/938] [D loss: 0.423969] [G loss: 0.981956]\n",
      "[Epoch 3/30] [Batch 778/938] [D loss: 0.356315] [G loss: 1.382117]\n",
      "[Epoch 3/30] [Batch 779/938] [D loss: 0.371640] [G loss: 1.288389]\n",
      "[Epoch 3/30] [Batch 780/938] [D loss: 0.443167] [G loss: 1.099912]\n",
      "[Epoch 3/30] [Batch 781/938] [D loss: 0.425478] [G loss: 1.156001]\n",
      "[Epoch 3/30] [Batch 782/938] [D loss: 0.435295] [G loss: 1.124619]\n",
      "[Epoch 3/30] [Batch 783/938] [D loss: 0.463053] [G loss: 1.302900]\n",
      "[Epoch 3/30] [Batch 784/938] [D loss: 0.474486] [G loss: 0.779656]\n",
      "[Epoch 3/30] [Batch 785/938] [D loss: 0.509941] [G loss: 1.866349]\n",
      "[Epoch 3/30] [Batch 786/938] [D loss: 0.548736] [G loss: 0.524766]\n",
      "[Epoch 3/30] [Batch 787/938] [D loss: 0.593621] [G loss: 2.449603]\n",
      "[Epoch 3/30] [Batch 788/938] [D loss: 0.646554] [G loss: 0.403577]\n",
      "[Epoch 3/30] [Batch 789/938] [D loss: 0.640627] [G loss: 2.368517]\n",
      "[Epoch 3/30] [Batch 790/938] [D loss: 0.630706] [G loss: 0.438528]\n",
      "[Epoch 3/30] [Batch 791/938] [D loss: 0.549669] [G loss: 2.229958]\n",
      "[Epoch 3/30] [Batch 792/938] [D loss: 0.476648] [G loss: 0.629557]\n",
      "[Epoch 3/30] [Batch 793/938] [D loss: 0.526020] [G loss: 1.979180]\n",
      "[Epoch 3/30] [Batch 794/938] [D loss: 0.509723] [G loss: 0.609886]\n",
      "[Epoch 3/30] [Batch 795/938] [D loss: 0.461383] [G loss: 1.904195]\n",
      "[Epoch 3/30] [Batch 796/938] [D loss: 0.479166] [G loss: 0.692685]\n",
      "[Epoch 3/30] [Batch 797/938] [D loss: 0.438438] [G loss: 1.765860]\n",
      "[Epoch 3/30] [Batch 798/938] [D loss: 0.428102] [G loss: 0.867078]\n",
      "[Epoch 3/30] [Batch 799/938] [D loss: 0.404542] [G loss: 1.539677]\n",
      "[Epoch 3/30] [Batch 800/938] [D loss: 0.472426] [G loss: 0.935884]\n",
      "[Epoch 3/30] [Batch 801/938] [D loss: 0.410111] [G loss: 1.171729]\n",
      "[Epoch 3/30] [Batch 802/938] [D loss: 0.428436] [G loss: 1.374912]\n",
      "[Epoch 3/30] [Batch 803/938] [D loss: 0.497486] [G loss: 0.738772]\n",
      "[Epoch 3/30] [Batch 804/938] [D loss: 0.519602] [G loss: 1.641254]\n",
      "[Epoch 3/30] [Batch 805/938] [D loss: 0.563999] [G loss: 0.519449]\n",
      "[Epoch 3/30] [Batch 806/938] [D loss: 0.531176] [G loss: 2.338808]\n",
      "[Epoch 3/30] [Batch 807/938] [D loss: 0.500489] [G loss: 0.610479]\n",
      "[Epoch 3/30] [Batch 808/938] [D loss: 0.464606] [G loss: 1.942661]\n",
      "[Epoch 3/30] [Batch 809/938] [D loss: 0.447656] [G loss: 0.685831]\n",
      "[Epoch 3/30] [Batch 810/938] [D loss: 0.509815] [G loss: 2.082284]\n",
      "[Epoch 3/30] [Batch 811/938] [D loss: 0.484815] [G loss: 0.656285]\n",
      "[Epoch 3/30] [Batch 812/938] [D loss: 0.461248] [G loss: 1.970468]\n",
      "[Epoch 3/30] [Batch 813/938] [D loss: 0.431411] [G loss: 0.756322]\n",
      "[Epoch 3/30] [Batch 814/938] [D loss: 0.355028] [G loss: 1.817338]\n",
      "[Epoch 3/30] [Batch 815/938] [D loss: 0.380445] [G loss: 1.155762]\n",
      "[Epoch 3/30] [Batch 816/938] [D loss: 0.346773] [G loss: 1.163146]\n",
      "[Epoch 3/30] [Batch 817/938] [D loss: 0.385868] [G loss: 1.495870]\n",
      "[Epoch 3/30] [Batch 818/938] [D loss: 0.376319] [G loss: 1.047727]\n",
      "[Epoch 3/30] [Batch 819/938] [D loss: 0.331824] [G loss: 1.402070]\n",
      "[Epoch 3/30] [Batch 820/938] [D loss: 0.399829] [G loss: 1.439683]\n",
      "[Epoch 3/30] [Batch 821/938] [D loss: 0.424694] [G loss: 0.961774]\n",
      "[Epoch 3/30] [Batch 822/938] [D loss: 0.369892] [G loss: 1.447602]\n",
      "[Epoch 3/30] [Batch 823/938] [D loss: 0.374962] [G loss: 1.149882]\n",
      "[Epoch 3/30] [Batch 824/938] [D loss: 0.376106] [G loss: 1.456509]\n",
      "[Epoch 3/30] [Batch 825/938] [D loss: 0.406779] [G loss: 1.104669]\n",
      "[Epoch 3/30] [Batch 826/938] [D loss: 0.444505] [G loss: 1.307803]\n",
      "[Epoch 3/30] [Batch 827/938] [D loss: 0.409338] [G loss: 0.922536]\n",
      "[Epoch 3/30] [Batch 828/938] [D loss: 0.451693] [G loss: 1.914896]\n",
      "[Epoch 3/30] [Batch 829/938] [D loss: 0.478612] [G loss: 0.744903]\n",
      "[Epoch 3/30] [Batch 830/938] [D loss: 0.422977] [G loss: 1.990580]\n",
      "[Epoch 3/30] [Batch 831/938] [D loss: 0.423922] [G loss: 0.819995]\n",
      "[Epoch 3/30] [Batch 832/938] [D loss: 0.381373] [G loss: 1.983154]\n",
      "[Epoch 3/30] [Batch 833/938] [D loss: 0.352393] [G loss: 0.977274]\n",
      "[Epoch 3/30] [Batch 834/938] [D loss: 0.363622] [G loss: 1.840141]\n",
      "[Epoch 3/30] [Batch 835/938] [D loss: 0.389705] [G loss: 1.011114]\n",
      "[Epoch 3/30] [Batch 836/938] [D loss: 0.359822] [G loss: 1.499370]\n",
      "[Epoch 3/30] [Batch 837/938] [D loss: 0.406573] [G loss: 1.209991]\n",
      "[Epoch 3/30] [Batch 838/938] [D loss: 0.369568] [G loss: 1.194355]\n",
      "[Epoch 3/30] [Batch 839/938] [D loss: 0.316730] [G loss: 1.597026]\n",
      "[Epoch 3/30] [Batch 840/938] [D loss: 0.361037] [G loss: 1.085733]\n",
      "[Epoch 3/30] [Batch 841/938] [D loss: 0.352896] [G loss: 1.666891]\n",
      "[Epoch 3/30] [Batch 842/938] [D loss: 0.349892] [G loss: 1.209990]\n",
      "[Epoch 3/30] [Batch 843/938] [D loss: 0.353502] [G loss: 1.341541]\n",
      "[Epoch 3/30] [Batch 844/938] [D loss: 0.289205] [G loss: 1.564677]\n",
      "[Epoch 3/30] [Batch 845/938] [D loss: 0.412112] [G loss: 1.363839]\n",
      "[Epoch 3/30] [Batch 846/938] [D loss: 0.386930] [G loss: 0.929052]\n",
      "[Epoch 3/30] [Batch 847/938] [D loss: 0.393914] [G loss: 2.205208]\n",
      "[Epoch 3/30] [Batch 848/938] [D loss: 0.422189] [G loss: 0.891047]\n",
      "[Epoch 3/30] [Batch 849/938] [D loss: 0.432543] [G loss: 1.437595]\n",
      "[Epoch 3/30] [Batch 850/938] [D loss: 0.400174] [G loss: 1.005905]\n",
      "[Epoch 3/30] [Batch 851/938] [D loss: 0.338367] [G loss: 1.759490]\n",
      "[Epoch 3/30] [Batch 852/938] [D loss: 0.397089] [G loss: 0.970906]\n",
      "[Epoch 3/30] [Batch 853/938] [D loss: 0.373940] [G loss: 1.605606]\n",
      "[Epoch 3/30] [Batch 854/938] [D loss: 0.390663] [G loss: 1.042237]\n",
      "[Epoch 3/30] [Batch 855/938] [D loss: 0.335788] [G loss: 1.605423]\n",
      "[Epoch 3/30] [Batch 856/938] [D loss: 0.329048] [G loss: 1.167764]\n",
      "[Epoch 3/30] [Batch 857/938] [D loss: 0.397279] [G loss: 1.732177]\n",
      "[Epoch 3/30] [Batch 858/938] [D loss: 0.424290] [G loss: 0.725161]\n",
      "[Epoch 3/30] [Batch 859/938] [D loss: 0.535627] [G loss: 2.676692]\n",
      "[Epoch 3/30] [Batch 860/938] [D loss: 0.586381] [G loss: 0.443273]\n",
      "[Epoch 3/30] [Batch 861/938] [D loss: 0.492185] [G loss: 2.846741]\n",
      "[Epoch 3/30] [Batch 862/938] [D loss: 0.359831] [G loss: 0.980753]\n",
      "[Epoch 3/30] [Batch 863/938] [D loss: 0.323778] [G loss: 1.410977]\n",
      "[Epoch 3/30] [Batch 864/938] [D loss: 0.307053] [G loss: 1.634605]\n",
      "[Epoch 3/30] [Batch 865/938] [D loss: 0.296495] [G loss: 1.202809]\n",
      "[Epoch 3/30] [Batch 866/938] [D loss: 0.330795] [G loss: 1.798167]\n",
      "[Epoch 3/30] [Batch 867/938] [D loss: 0.387316] [G loss: 1.012501]\n",
      "[Epoch 3/30] [Batch 868/938] [D loss: 0.336619] [G loss: 1.588919]\n",
      "[Epoch 3/30] [Batch 869/938] [D loss: 0.358132] [G loss: 1.112651]\n",
      "[Epoch 3/30] [Batch 870/938] [D loss: 0.464499] [G loss: 1.664717]\n",
      "[Epoch 3/30] [Batch 871/938] [D loss: 0.553205] [G loss: 0.523323]\n",
      "[Epoch 3/30] [Batch 872/938] [D loss: 0.747269] [G loss: 3.319847]\n",
      "[Epoch 3/30] [Batch 873/938] [D loss: 0.655630] [G loss: 0.392948]\n",
      "[Epoch 3/30] [Batch 874/938] [D loss: 0.644433] [G loss: 2.735459]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/t4/vlfl8bvn5mqgcfzprpqf_zph0000gn/T/ipykernel_19997/1566301740.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'n_epochs'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0;31m# Adversarial ground truths\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mvalid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimgs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfill_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequires_grad\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    519\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 521\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    523\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    559\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    562\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 134\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    135\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, tensor)\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mNormalized\u001B[0m \u001B[0mTensor\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         \"\"\"\n\u001B[0;32m--> 226\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36mnormalize\u001B[0;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[1;32m    343\u001B[0m     \u001B[0mmean\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m     \u001B[0mstd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 345\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstd\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    346\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'std evaluated to zero after conversion to {}, leading to division by zero.'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mmean\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(config.get('n_epochs')):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # **Train Generator**\n",
    "        optimizer_G.zero_grad()\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], config.get('latent_dim')))))\n",
    "        # Generate a batch of images\n",
    "        # gen_imgs = model_gen.forward(z)\n",
    "        gen_imgs = model_gen(z)\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "                # pred = model_dis(gen_imgs)\n",
    "                # print(gen_imgs)\n",
    "        gen_loss = ad_loss(model_dis(gen_imgs), valid)\n",
    "\n",
    "        gen_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "        # **Train Discriminator**\n",
    "        optimizer_D.zero_grad()\n",
    "        # Measure discriminator's ability to classify real from generate samples\n",
    "        real_loss = ad_loss(model_dis(real_imgs), valid)\n",
    "        fake_loss = ad_loss(model_dis(gen_imgs.detach()), fake) # ??? why we use detach here\n",
    "        loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, config.get(\"n_epochs\"), i, len(dataloader), loss.item(), gen_loss.item())\n",
    "        )\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % config.get(\"sample_interval\") == 0:\n",
    "            save_image(gen_imgs.data[:25], \"../out_img/GAN_MNIST/%d.png\" % batches_done, nrow=5, normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
