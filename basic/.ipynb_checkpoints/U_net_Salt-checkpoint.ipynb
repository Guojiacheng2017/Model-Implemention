{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T17:39:37.649567Z",
     "start_time": "2023-04-06T17:39:37.641996Z"
    }
   },
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T16:21:46.227341Z",
     "start_time": "2023-04-06T16:21:46.214122Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import cv2\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "# from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:15:02.938842Z",
     "start_time": "2023-04-06T14:15:02.937354Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m momentum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m     11\u001b[0m weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[0;32m---> 13\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m save_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../rst/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# if not os.path.isdir(save_weight):\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     os.makedirs(save_weight)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "n_fold = 5  # ?\n",
    "pad_left = 0\n",
    "pad_right = 0\n",
    "fine_size = 202 # ?\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "snapshot = 6 # ? what for\n",
    "max_lr = 0.012\n",
    "min_lr = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "save_weight = '../rst/'\n",
    "\n",
    "# if not os.path.isdir(save_weight):\n",
    "#     os.makedirs(save_weight)\n",
    "weight_name = 'model_' + str(fine_size + pad_left + pad_right)\n",
    "\n",
    "train_image_path = './data/SaltDataset/train/images'\n",
    "train_mask_path = './data/SaltDataset/train/masks'\n",
    "test_image_path = './data/SaltDataset/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image --[GAN get latent]--> use the depth --[get feature map latent]-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:15:02.953314Z",
     "start_time": "2023-04-06T14:15:02.940154Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.encoder(img)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.img_shape = (((img_shape // 2) // 2) // 2) // 2\n",
    "        self.linear = nn.Linear(self.img_shape ^2 * 256, 128)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        rst = self.conv(img)\n",
    "        rst = rst.view(img.shape[0], -1)\n",
    "        rst = self.linear(rst)\n",
    "        rst = self.fc(rst)\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:36:26.775838Z",
     "start_time": "2023-04-05T20:36:20.894604Z"
    }
   },
   "outputs": [],
   "source": [
    "# depths = pd.read_csv('./data/SaltDataset/depths.csv')\n",
    "# depths.sort_values('z', inplace=True)\n",
    "# depths.drop('z', axis=1, inplace=True)\n",
    "# depths['fold'] = (list(range(0,5)) * depths.shape[0])[:depths.shape[0]]\n",
    "#\n",
    "# train_df = pd.read_csv('./data/SaltDataset/train.csv')\n",
    "# train_df = train_df.merge(depths)\n",
    "# dist = []\n",
    "# for id in train_df.id.values:\n",
    "#   img = cv2.imread(f'./data/SaltDataset/train/images/{id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "#   dist.append(np.unique(img).shape[0])\n",
    "# train_df['unique_pixels'] = dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:15:02.995872Z",
     "start_time": "2023-04-06T14:15:02.957246Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSaltDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_dir, mask_dir, train_file, depth_file, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir \u001b[38;5;241m=\u001b[39m img_dir\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class SaltDataset(Dataset):\n",
    "\n",
    "\n",
    "\n",
    "depths = pd.read_csv('./data/SaltDataset/depths.csv')\n",
    "train_df = pd.read_csv('./data/SaltDataset/train.csv')\n",
    "train_df = train_df.merge(depths)       # merge 就像数据库一样合并表，主键自动匹配\n",
    "# dist = []\n",
    "#\n",
    "# for id in train_df.id.values:\n",
    "#     img = cv2.imread(f'./data/SaltDataset/train/images/{id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "#     dist.append(np.unique(img).shape[0])\n",
    "#     # print(img.shape)\n",
    "#\n",
    "#\n",
    "# train_df['unique_pixels'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:15:03.000925Z",
     "start_time": "2023-04-06T14:15:02.996271Z"
    }
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "mask_list = []\n",
    "# for _, id in tqdm(enumerate(train_df.id.values), total=len(train_df)):\n",
    "#     # print(id)\n",
    "#     img = cv2.imread(f'./data/SaltDataset/train/images/{id}.png', cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "#     mask = cv2.imread(f'./data/SaltDataset/train/masks/{id}.png', cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "#     # print(img)\n",
    "#     img_list.append(img)\n",
    "#     mask_list.append(mask)\n",
    "#\n",
    "# print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:15:03.102041Z",
     "start_time": "2023-04-06T14:15:03.094510Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mask_list)\n",
    "# print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T15:52:42.562129Z",
     "start_time": "2023-04-06T15:52:42.548202Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:15:59.971205Z",
     "start_time": "2023-04-06T14:15:58.814983Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "# train_data = np.concatenate((img_list, mask_list), axis=0)\n",
    "# train_data = pd.DataFrame(data=img_list)\n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T14:16:01.445690Z",
     "start_time": "2023-04-06T14:16:01.442092Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(train_df)\n",
    "# print(train_df.id.values)\n",
    "# def datasampler(len, percentage):\n",
    "file_idx = list(range(train_df.shape[0]))\n",
    "train_idx, val_idx = train_test_split(file_idx, test_size=0.2, shuffle=True)\n",
    "# print(val_idx.shape)\n",
    "train_dl = DataLoader(train_df, batch_size=batch_size, sampler=train_idx)\n",
    "val_dl = DataLoader(train_df, batch_size=batch_size, sampler=val_idx)\n",
    "# train_mask_dl = DataLoader(train_df, batch_size=batch_size, sampler=train_idx)\n",
    "# print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T15:52:51.881392Z",
     "start_time": "2023-04-06T15:52:51.873773Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T15:52:57.346758Z",
     "start_time": "2023-04-06T15:52:57.337617Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (image_id, _, depths) in enumerate(train_dl):\n",
    "        print(image_id, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:27:23.139663Z",
     "start_time": "2023-04-05T20:27:23.120288Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_kaggle_metric(predict,truth, threshold=0.5):\n",
    "\n",
    "    N = len(predict)\n",
    "    predict = predict.reshape(N,-1)\n",
    "    truth   = truth.reshape(N,-1)\n",
    "\n",
    "    predict = predict>threshold\n",
    "    truth   = truth>0.5\n",
    "    intersection = truth & predict\n",
    "    union        = truth | predict\n",
    "    iou = intersection.sum(1)/(union.sum(1)+1e-8)\n",
    "\n",
    "    #-------------------------------------------\n",
    "    result = []\n",
    "    precision = []\n",
    "    is_empty_truth   = (truth.sum(1)==0)\n",
    "    is_empty_predict = (predict.sum(1)==0)\n",
    "\n",
    "    threshold = np.array([0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95])\n",
    "    for t in threshold:\n",
    "        p = iou>=t\n",
    "\n",
    "        tp  = (~is_empty_truth)  & (~is_empty_predict) & (iou> t)\n",
    "        fp  = (~is_empty_truth)  & (~is_empty_predict) & (iou<=t)\n",
    "        fn  = (~is_empty_truth)  & ( is_empty_predict)\n",
    "        fp_empty = ( is_empty_truth)  & (~is_empty_predict)\n",
    "        tn_empty = ( is_empty_truth)  & ( is_empty_predict)\n",
    "\n",
    "        p = (tp + tn_empty) / (tp + tn_empty + fp + fp_empty + fn)\n",
    "\n",
    "        result.append( np.column_stack((tp,fp,fn,tn_empty,fp_empty)) )\n",
    "        precision.append(p)\n",
    "\n",
    "    result = np.array(result).transpose(1,2,0)\n",
    "    precision = np.column_stack(precision)\n",
    "    precision = precision.mean(1)\n",
    "\n",
    "    return precision, result, threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
